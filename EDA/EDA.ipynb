{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### ✅ **Complete List of EDA Topics for Machine Learning**\n",
    "\n",
    "*(Organized step-by-step, from raw data to insights)*\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧹 1. **Data Cleaning**\n",
    "\n",
    "* Handling missing values (imputation, removal)\n",
    "* Handling duplicates\n",
    "* Handling outliers\n",
    "* Type conversions (e.g., object to float)\n",
    "* Dealing with inconsistent formats (dates, currencies, etc.)\n",
    "* String trimming and standardization\n",
    "\n",
    "---\n",
    "\n",
    "#### 📏 2. **Data Type Identification & Conversion**\n",
    "\n",
    "* Numerical vs Categorical\n",
    "* Ordinal vs Nominal\n",
    "* Datetime parsing\n",
    "* Encoding (Label, One-hot, Ordinal)\n",
    "\n",
    "---\n",
    "\n",
    "#### 📊 3. **Univariate Analysis**\n",
    "\n",
    "* Summary statistics (mean, median, mode, std, IQR)\n",
    "* Frequency distribution\n",
    "* Value counts\n",
    "* Distribution plots (histogram, KDE, boxplot)\n",
    "* Detecting skewness and kurtosis\n",
    "\n",
    "---\n",
    "\n",
    "#### 📈 4. **Bivariate Analysis**\n",
    "\n",
    "* Correlation matrix (Pearson, Spearman)\n",
    "* Scatter plots\n",
    "* Heatmaps\n",
    "* Pair plots\n",
    "* Groupby analysis\n",
    "* Cross-tabulation\n",
    "* Boxplots/grouped boxplots\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔁 5. **Multivariate Analysis**\n",
    "\n",
    "* Multivariate correlation\n",
    "* Pairplots (Seaborn)\n",
    "* FacetGrid analysis\n",
    "* PCA for visualization\n",
    "* Bubble charts\n",
    "\n",
    "---\n",
    "\n",
    "#### 📉 6. **Outlier Detection**\n",
    "\n",
    "* Z-score\n",
    "* IQR method\n",
    "* Boxplot visual method\n",
    "* Isolation Forest (optional ML method)\n",
    "* Mahalanobis distance\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧬 7. **Feature Distribution Analysis**\n",
    "\n",
    "* Normal vs non-normal distribution\n",
    "* Skewness correction (log, sqrt, Box-Cox)\n",
    "* Visualization: histogram, distplot, violin plot\n",
    "\n",
    "---\n",
    "\n",
    "#### 📆 8. **Time Series EDA**\n",
    "\n",
    "* Time-based decomposition\n",
    "* Rolling statistics\n",
    "* Seasonal trends\n",
    "* Lag analysis\n",
    "* Autocorrelation/Partial Autocorrelation\n",
    "\n",
    "---\n",
    "\n",
    "#### 📂 9. **Categorical Variable Analysis**\n",
    "\n",
    "* Frequency tables\n",
    "* Bar plots / Count plots\n",
    "* Pie charts (use sparingly)\n",
    "* Stacked bar charts\n",
    "* Chi-square test (for association)\n",
    "\n",
    "---\n",
    "\n",
    "#### 📊 10. **Numerical Variable Analysis**\n",
    "\n",
    "* Distribution shape\n",
    "* Mean/median comparison\n",
    "* Boxplots by category\n",
    "* Violin plots\n",
    "* ANOVA or t-tests\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔀 11. **Encoding Categorical Data**\n",
    "\n",
    "* Label Encoding\n",
    "* One-Hot Encoding\n",
    "* Target/Mean Encoding\n",
    "* Frequency Encoding\n",
    "\n",
    "---\n",
    "\n",
    "#### 📉 12. **Correlation Analysis**\n",
    "\n",
    "* Pearson, Spearman, Kendall coefficients\n",
    "* Heatmaps\n",
    "* Variance Inflation Factor (VIF) for multicollinearity\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧪 13. **Missing Value Treatment**\n",
    "\n",
    "* Count and percentage of missing values\n",
    "* Missingness pattern visualization\n",
    "* Imputation techniques:\n",
    "\n",
    "  * Mean/median/mode\n",
    "  * Forward/backward fill\n",
    "  * KNN imputation\n",
    "  * Regression imputation\n",
    "\n",
    "---\n",
    "\n",
    "#### 🧮 14. **Feature Engineering (EDA-Aided)**\n",
    "\n",
    "* Polynomial features\n",
    "* Interaction terms\n",
    "* Date parts (year, month, weekday, etc.)\n",
    "* Binning (equal-width, equal-frequency, quantile-based)\n",
    "\n",
    "---\n",
    "\n",
    "#### ⚖️ 15. **Target Variable Analysis**\n",
    "\n",
    "* Class imbalance (binary/multiclass)\n",
    "* Distribution of target vs features\n",
    "* Use of stratification for classification\n",
    "* SMOTE or undersampling techniques (if applied)\n",
    "\n",
    "---\n",
    "\n",
    "#### 📈 16. **Visualization Techniques**\n",
    "\n",
    "* Seaborn, Matplotlib, Plotly\n",
    "* Histograms, KDE, Boxplots\n",
    "* Count plots, Pie charts, Bar charts\n",
    "* Heatmaps, Correlation plots\n",
    "* Joint plots, Pair plots, Violin plots\n",
    "* Time series plots\n",
    "* Missing value matrix (e.g., `msno.matrix()`)\n",
    "\n",
    "---\n",
    "\n",
    "#### 📋 17. **EDA Reporting**\n",
    "\n",
    "* Pandas Profiling\n",
    "* Sweetviz\n",
    "* D-Tale\n",
    "* Autoviz\n",
    "* Lux\n",
    "\n",
    "---\n",
    "\n",
    "#### 🛑 18. **EDA Red Flags**\n",
    "\n",
    "* Data leakage detection\n",
    "* Target leakage in features\n",
    "* High multicollinearity\n",
    "* Dominant class in target\n",
    "\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Complete EDA Guide for Machine Learning (All-in-One)\n",
    "\n",
    "---\n",
    "\n",
    "## 🧹 1. Data Cleaning\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Data cleaning is the process of detecting and correcting (or removing) corrupt or inaccurate records from a dataset.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `df.isnull()` – Detects missing values\n",
    "* `df.dropna()` – Removes missing values\n",
    "* `df.fillna()` – Fills missing values\n",
    "* `df.duplicated()` – Detects duplicate rows\n",
    "* `df.drop_duplicates()` – Removes duplicate rows\n",
    "* `pd.to_numeric()` – Converts data types\n",
    "* `df.replace()` – Replaces specific values\n",
    "* `df.astype()` – Type conversion\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, np.nan, 4],\n",
    "    'B': ['  text', 'text', 'Text', 'text'],\n",
    "    'C': [1, 1, 1, 1]\n",
    "})\n",
    "\n",
    "# Remove missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(df_cleaned)\n",
    "# Output:\n",
    "#      A     B  C\n",
    "# 0  1.0   text  1\n",
    "# 1  2.0   text  1\n",
    "# 3  4.0   text  1\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* At the beginning of any ML project\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When you need to preserve raw data for auditing\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Over-cleaning may lead to loss of important information\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. How do you handle missing values in a dataset?\n",
    "2. What is the difference between `dropna()` and `fillna()`?\n",
    "3. How can you detect outliers during data cleaning?\n",
    "\n",
    "---\n",
    "\n",
    "## 📏 2. Data Type Identification & Conversion\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Identifying and converting data into appropriate formats such as numerical, categorical, or datetime for proper analysis.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `df.dtypes` – Shows data types\n",
    "* `df.astype()` – Converts type\n",
    "* `pd.to_datetime()` – Parses datetime\n",
    "* `pd.get_dummies()` – One-hot encoding\n",
    "* `LabelEncoder()` – Label encoding\n",
    "* `OrdinalEncoder()` – Ordinal encoding\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.DataFrame({'Gender': ['Male', 'Female', 'Female']})\n",
    "le = LabelEncoder()\n",
    "df['Gender_encoded'] = le.fit_transform(df['Gender'])\n",
    "print(df)\n",
    "# Output:\n",
    "#   Gender  Gender_encoded\n",
    "# 0   Male               1\n",
    "# 1 Female               0\n",
    "# 2 Female               0\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* Before applying ML models\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When working on raw EDA before preprocessing\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Incorrect encoding can mislead models\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. Difference between One-hot and Label encoding?\n",
    "2. What are ordinal variables and how do you handle them?\n",
    "3. How do you convert a column to datetime format?\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 3. Univariate Analysis\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Analyzing one variable at a time to understand its distribution and characteristics.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `df.describe()` – Summary statistics\n",
    "* `df.value_counts()` – Frequency of values\n",
    "* `df['col'].plot(kind='hist')` – Histogram\n",
    "* `sns.boxplot()` – Boxplot\n",
    "* `sns.kdeplot()` – Kernel Density Estimate\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.boxplot(data=df, x='A')\n",
    "plt.show()\n",
    "# Output: Boxplot visualization\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* To understand distribution, outliers, central tendency\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When analyzing interaction between features\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Can’t show relationships with other variables\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What are summary statistics?\n",
    "2. How do you detect skewness and kurtosis?\n",
    "3. Why is univariate analysis important?\n",
    "\n",
    "---\n",
    "\n",
    "## 📈 4. Bivariate Analysis\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Analyzing the relationship between two variables.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `df.corr()` – Correlation\n",
    "* `pd.crosstab()` – Cross tabulation\n",
    "* `df.groupby()` – Group-wise analysis\n",
    "* `sns.scatterplot()` – Scatter plot\n",
    "* `sns.heatmap()` – Heatmap\n",
    "* `sns.boxplot(x, y)` – Grouped boxplot\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "sns.scatterplot(data=df, x='A', y='C')\n",
    "plt.show()\n",
    "# Output: Scatter plot\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* To identify linear/non-linear relationships\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When one or both variables are not meaningful together\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Only works on two variables at a time\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What is the use of scatter plots?\n",
    "2. What is a heatmap and when is it used?\n",
    "3. How can correlation mislead in non-linear cases?\n",
    "\n",
    "---\n",
    "\n",
    "(## 🔁 5. Multivariate Analysis\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Analyzing relationships among more than two variables simultaneously.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `sns.pairplot()` – Pairwise plots\n",
    "* `sns.FacetGrid()` – Multi-variable faceted plots\n",
    "* `PCA()` – Dimensionality reduction\n",
    "* `sns.scatterplot()` with `hue` – Colored multivariable scatter\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "sns.pairplot(df, hue='Gender')\n",
    "plt.show()\n",
    "# Output: Multiple scatter plots based on each pair of variables\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* When studying combined effects of features\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* With too many variables (can be noisy)\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Hard to visualize beyond 3 dimensions\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What is multivariate analysis?\n",
    "2. When would you use PCA in EDA?\n",
    "3. Difference between pairplot and FacetGrid?\n",
    "\n",
    "---\n",
    "\n",
    "## 📉 6. Outlier Detection\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Finding data points that are significantly different from others.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `zscore()` – Z-score method\n",
    "* `IQR` logic with `quantile()`\n",
    "* `sns.boxplot()` – Boxplot for visual detection\n",
    "* `IsolationForest()` – Tree-based outlier detection\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "Q1 = df['A'].quantile(0.25)\n",
    "Q3 = df['A'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = df[(df['A'] < Q1 - 1.5*IQR) | (df['A'] > Q3 + 1.5*IQR)]\n",
    "print(outliers)\n",
    "# Output: Rows considered as outliers\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* Before modeling, to improve accuracy\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* In naturally long-tailed distributions\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* May remove valid rare events\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What is IQR and how is it used?\n",
    "2. How does Isolation Forest detect outliers?\n",
    "3. Why are outliers important in ML?\n",
    "\n",
    "---\n",
    "\n",
    "## 🧬 7. Feature Distribution Analysis\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Examining the distribution shape of individual features.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `sns.histplot()` – Histogram\n",
    "* `sns.kdeplot()` – KDE plot\n",
    "* `sns.violinplot()` – Violin plot\n",
    "* `np.log()`, `np.sqrt()` – Skewness correction\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "sns.violinplot(x='Gender', y='A', data=df)\n",
    "plt.show()\n",
    "# Output: Violin plot showing distribution by Gender\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* When verifying data assumptions like normality\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When shape is irrelevant to analysis/model\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Misleading if outliers not handled\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What’s the use of KDE plot?\n",
    "2. How do you handle skewed features?\n",
    "3. When do you apply log transformation?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s the continuation in your specified format for the next EDA topics:\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 8. Feature Engineering\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Feature engineering is the process of creating new features or modifying existing ones to improve model performance.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `df['new'] = df['col1'] + df['col2']` – Create new features\n",
    "* `df['col'].apply()` – Apply custom transformations\n",
    "* `pd.cut()` – Bin numerical values\n",
    "* `pd.qcut()` – Quantile binning\n",
    "* `np.log()`, `np.sqrt()` – Transform features\n",
    "* `PolynomialFeatures()` – Generate polynomial terms\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "df['log_A'] = np.log(df['A'] + 1)\n",
    "print(df[['A', 'log_A']])\n",
    "# Output: Original and log-transformed column\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* To expose hidden patterns to ML algorithms\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* When raw features are already well-optimized\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Over-engineering can cause overfitting\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What is feature engineering?\n",
    "2. How does feature transformation affect ML models?\n",
    "3. Difference between `pd.cut()` and `pd.qcut()`?\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 9. Feature Selection\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Selecting the most relevant features that contribute to the model and removing irrelevant ones.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `SelectKBest()` – Top K features\n",
    "* `RFE()` – Recursive Feature Elimination\n",
    "* `VarianceThreshold()` – Low variance filter\n",
    "* `df.corr()` – Correlation-based filtering\n",
    "* `model.feature_importances_` – From tree models\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "df_selected = selector.fit_transform(df[['A', 'C']])\n",
    "print(df_selected)\n",
    "# Output: Selected features array\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* To reduce overfitting and improve model performance\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* On small datasets where all features are essential\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Risk of removing informative features\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. Why is feature selection important?\n",
    "2. What’s the difference between filter and wrapper methods?\n",
    "3. How do tree models help in feature selection?\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 10. Handling Imbalanced Data\n",
    "\n",
    "### 📘 Definition:\n",
    "\n",
    "Techniques used to address datasets where the target class distribution is skewed.\n",
    "\n",
    "### 🔧 Built-in Functions:\n",
    "\n",
    "* `value_counts()` – View imbalance\n",
    "* `resample()` – Over/undersampling\n",
    "* `SMOTE()` – Synthetic Minority Over-sampling\n",
    "* `class_weight='balanced'` – Adjust model training\n",
    "* `confusion_matrix()` – Evaluate imbalance impact\n",
    "\n",
    "### 🧪 Example:\n",
    "\n",
    "```python\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = df[df['target'] == 0]\n",
    "df_minority = df[df['target'] == 1]\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])\n",
    "print(df_balanced['target'].value_counts())\n",
    "# Output: Balanced class counts\n",
    "```\n",
    "\n",
    "### ✅ When to Use:\n",
    "\n",
    "* When classification accuracy is biased toward majority class\n",
    "\n",
    "### ❌ When Not to Use:\n",
    "\n",
    "* On already balanced data\n",
    "\n",
    "### ⚠️ Limitations:\n",
    "\n",
    "* Over/undersampling may introduce noise or remove useful data\n",
    "\n",
    "### 🎯 Interview Questions:\n",
    "\n",
    "1. What is SMOTE and how does it work?\n",
    "2. What are some metrics better than accuracy in imbalanced datasets?\n",
    "3. How do you detect and fix imbalanced datasets?\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
