{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD4eWfa3cGB6JtTRdpDP97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mukeshrock7897/Data-Analysis/blob/main/pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What is Pandas?**\n",
        "* Pandas is a Python library used for working with data sets.\n",
        "* It has functions for cleaning, analyzing, exploring, and manipulating data.\n",
        "* The name \"Pandas\" has a reference to both \"Panel Data\", and \"Python Data Analysis\"\n",
        "* Pandas created by Wes McKinney in 2008."
      ],
      "metadata": {
        "id": "h8gt9cK4uz3a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dukpctaXw7JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Why Use Pandas?**\n",
        "\n",
        "**1. Efficient Data Structures:**\n",
        "\n",
        "- **Series:** A one-dimensional labeled array capable of holding any data type (integers, floats, strings, objects).\n",
        "- **DataFrame:** A two-dimensional labeled data structure with columns that can hold different data types, similar to a spreadsheet.\n",
        "- **Index:** A unique identifier for each row or column, allowing for efficient data access and manipulation.\n",
        "\n",
        "**2. Data Manipulation:**\n",
        "\n",
        "- **Selection and Filtering:** Easily select specific rows, columns, or subsets of data based on conditions.\n",
        "- **Aggregation:** Calculate summary statistics like mean, median, standard deviation, and more.\n",
        "- **Grouping:** Group data by specific columns and perform calculations on each group.\n",
        "- **Joining and Merging:** Combine data from multiple DataFrames based on shared columns or indexes.\n",
        "- **Reshaping:** Transform data into different formats, such as pivoting or stacking.\n",
        "\n",
        "**3. Data Cleaning and Preparation:**\n",
        "\n",
        "- **Handling Missing Values:** Fill missing values, drop rows or columns with missing data, or interpolate values.\n",
        "- **Data Formatting:** Convert data types, normalize data, and handle outliers.\n",
        "- **Text Processing:** Extract information from text data using regular expressions and other techniques.\n",
        "\n",
        "**4. Integration with Other Libraries:**\n",
        "\n",
        "- **Seaborn:** Create visually appealing statistical plots.\n",
        "- **Matplotlib:** Customize visualizations in more detail.\n",
        "- **Scikit-learn:** Build machine learning models using Pandas-prepared data.\n",
        "- **Statsmodels:** Perform statistical tests and modeling.\n",
        "\n",
        "**5. Large Datasets:**\n",
        "\n",
        "- **Efficient Handling:** Pandas is optimized for working with large datasets, providing efficient memory management and operations.\n",
        "- **Performance:** Leverage Pandas's optimized algorithms and data structures for faster data analysis.\n",
        "\n",
        "**6. Readability and Maintainability:**\n",
        "\n",
        "- **Clear Code:** Pandas's intuitive syntax and expressive functions make your code more readable and easier to understand.\n",
        "- **Maintainability:** Well-structured Pandas code is easier to maintain and modify over time.\n"
      ],
      "metadata": {
        "id": "IRh4d03SvLpb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPfnA2gvw6Fb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **What Can Pandas Do?**\n",
        "Pandas gives you answers about the data. Like:\n",
        "\n",
        "* Is there a correlation between two or more columns?\n",
        "* What is average value?\n",
        "* Max value?\n",
        "* Min value?\n",
        "\n",
        "**Note:** Pandas are also able to delete rows that are not relevant, or contains wrong values, like empty or NULL values. This is called cleaning the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "LfZ19b_7vz1c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIh4U7u3w5NF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Install Pandas**\n",
        "!pip install pandas\n",
        "\n",
        "\n",
        "### **Importing Pandas**\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "bRlnrHlOwLVP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXiqWjWgw3mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Checking Pandas Version**\n",
        "import pandas as pd\n",
        "\n",
        "print(pd.__version__)"
      ],
      "metadata": {
        "id": "uJJr55fOwwmN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aazqj8dYuohW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Pandas Series**\n",
        "* **Pandas Series** is a one-dimensional labeled array capable of holding any data type (integers, strings, floats, Python objects, etc.).\n",
        "* **Series** is like a column in a DataFrame or a more powerful version of a NumPy array.\n",
        "* Each entry in a Series has a label (index), making it easier to access data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Creating a Pandas Series**\n",
        "\n",
        "#### a. **From a List**\n",
        "You can create a Series directly from a Python list.\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "data = [10, 20, 30, 40]\n",
        "s = pd.Series(data)\n",
        "print(s)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "0    10\n",
        "1    20\n",
        "2    30\n",
        "3    40\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "#### b. **From a Dictionary**\n",
        "You can create a Series from a Python dictionary, where the keys become the labels (index).\n",
        "```python\n",
        "data = {'a': 10, 'b': 20, 'c': 30}\n",
        "s = pd.Series(data)\n",
        "print(s)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "a    10\n",
        "b    20\n",
        "c    30\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "#### c. **With Custom Index**\n",
        "You can specify a custom index (labels) when creating a Series.\n",
        "```python\n",
        "data = [100, 200, 300]\n",
        "s = pd.Series(data, index=['x', 'y', 'z'])\n",
        "print(s)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "x    100\n",
        "y    200\n",
        "z    300\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "#### d. **From a Scalar Value**\n",
        "If you provide a scalar value, the same value is repeated for each index.\n",
        "```python\n",
        "s = pd.Series(5, index=['a', 'b', 'c'])\n",
        "print(s)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "a    5\n",
        "b    5\n",
        "c    5\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Accessing Data in a Series**\n",
        "\n",
        "#### a. **Accessing by Label (`.loc[]`)**\n",
        "Use `.loc[]` to access data using labels.\n",
        "```python\n",
        "print(s.loc['y'])  # Output: 200\n",
        "```\n",
        "\n",
        "#### b. **Accessing by Position (`.iloc[]`)**\n",
        "Use `.iloc[]` to access data by position.\n",
        "```python\n",
        "print(s.iloc[1])  # Output: 200\n",
        "```\n",
        "\n",
        "#### c. **Accessing by Boolean Mask**\n",
        "You can filter a Series based on conditions using Boolean indexing.\n",
        "```python\n",
        "s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
        "print(s[s > 20])  # Output: c    30, d    40\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Modifying a Series**\n",
        "\n",
        "#### a. **Modifying Values**\n",
        "You can modify values in a Series by index label or position.\n",
        "```python\n",
        "s['y'] = 500\n",
        "print(s)\n",
        "```\n",
        "\n",
        "#### b. **Adding or Removing Data**\n",
        "Pandas Series are mutable, so you can add or remove elements dynamically.\n",
        "```python\n",
        "s['new'] = 600  # Adding a new element\n",
        "print(s)\n",
        "\n",
        "s = s.drop('new')  # Removing an element\n",
        "print(s)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Series Operations**\n",
        "\n",
        "#### a. **Arithmetic Operations**\n",
        "Operations on Series are performed element-wise, and labels are automatically aligned.\n",
        "\n",
        "```python\n",
        "s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
        "s2 = pd.Series([4, 5, 6], index=['b', 'c', 'd'])\n",
        "print(s1 + s2)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "a    NaN\n",
        "b    6.0\n",
        "c    8.0\n",
        "d    NaN\n",
        "dtype: float64\n",
        "```\n",
        "\n",
        "#### b. **Mathematical Functions**\n",
        "You can apply mathematical functions like `sum()`, `mean()`, and `std()` to a Series.\n",
        "```python\n",
        "s = pd.Series([1, 2, 3, 4, 5])\n",
        "print(s.sum())    # Output: 15\n",
        "print(s.mean())   # Output: 3.0\n",
        "print(s.std())    # Output: 1.58 (Standard Deviation)\n",
        "```\n",
        "\n",
        "#### c. **Vectorized Operations**\n",
        "Operations like addition, subtraction, multiplication, etc., can be done directly on a Series.\n",
        "```python\n",
        "s = pd.Series([1, 2, 3])\n",
        "print(s * 10)  # Each element will be multiplied by 10\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Series Indexing**\n",
        "\n",
        "#### a. **Setting a Custom Index**\n",
        "You can set a custom index using `.set_index()`.\n",
        "```python\n",
        "s = pd.Series([10, 20, 30], index=['x', 'y', 'z'])\n",
        "print(s)\n",
        "```\n",
        "\n",
        "#### b. **Resetting Index**\n",
        "You can reset the index to default (0, 1, 2…) using `.reset_index()`.\n",
        "```python\n",
        "s_reset = s.reset_index(drop=True)\n",
        "print(s_reset)\n",
        "```\n",
        "\n",
        "#### c. **Checking for Index Existence**\n",
        "You can check if a label exists in the index using `in`.\n",
        "```python\n",
        "print('y' in s)  # Output: True\n",
        "```\n",
        "\n",
        "#### d. **Reindexing a Series**\n",
        "You can reindex a Series to add or remove labels using `.reindex()`.\n",
        "```python\n",
        "new_index = ['a', 'b', 'c', 'd']\n",
        "s_reindexed = s.reindex(new_index)\n",
        "print(s_reindexed)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "a     NaN\n",
        "b     NaN\n",
        "c    20.0\n",
        "d     NaN\n",
        "dtype: float64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Handling Missing Data in Series**\n",
        "\n",
        "#### a. **Handling `NaN` (Not a Number) Values**\n",
        "You can fill or drop missing values in a Series.\n",
        "- **Filling Missing Values**: `.fillna()`\n",
        "```python\n",
        "s_filled = s_reindexed.fillna(0)\n",
        "print(s_filled)\n",
        "```\n",
        "\n",
        "- **Dropping Missing Values**: `.dropna()`\n",
        "```python\n",
        "s_dropped = s_reindexed.dropna()\n",
        "print(s_dropped)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Combining Multiple Series**\n",
        "\n",
        "#### a. **Concatenating Series**\n",
        "You can concatenate multiple Series using `pd.concat()`.\n",
        "```python\n",
        "s1 = pd.Series([1, 2, 3])\n",
        "s2 = pd.Series([4, 5, 6])\n",
        "combined = pd.concat([s1, s2])\n",
        "print(combined)\n",
        "```\n",
        "\n",
        "#### b. **Appending Series**\n",
        "Series can also be appended using `.append()`.\n",
        "```python\n",
        "s_combined = s1.append(s2)\n",
        "print(s_combined)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Statistical Functions on Series**\n",
        "\n",
        "Pandas Series has several useful statistical methods:\n",
        "- **Describe**: Provides summary statistics for a Series.\n",
        "```python\n",
        "s = pd.Series([1, 2, 3, 4, 5])\n",
        "print(s.describe())\n",
        "```\n",
        "\n",
        "- **Count, Min, Max**:\n",
        "```python\n",
        "print(s.count())  # Output: 5\n",
        "print(s.min())    # Output: 1\n",
        "print(s.max())    # Output: 5\n",
        "```\n",
        "\n",
        "- **Correlation and Covariance**:\n",
        "```python\n",
        "s1 = pd.Series([1, 2, 3])\n",
        "s2 = pd.Series([4, 5, 6])\n",
        "print(s1.corr(s2))  # Output: 1.0 (perfect correlation)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Using `apply()` to Apply Functions on Series**\n",
        "The `apply()` function allows applying custom functions element-wise.\n",
        "\n",
        "Example with a lambda function:\n",
        "```python\n",
        "s = pd.Series([1, 2, 3])\n",
        "print(s.apply(lambda x: x**2))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Accessing Data in Series as Arrays**\n",
        "\n",
        "#### a. **Using `.values` Attribute**\n",
        "You can access the underlying NumPy array using `.values`.\n",
        "```python\n",
        "s = pd.Series([1, 2, 3])\n",
        "print(s.values)  # Output: [1 2 3]\n",
        "```\n",
        "\n",
        "#### b. **Accessing the Index**\n",
        "You can access the index (labels) of a Series using `.index`.\n",
        "```python\n",
        "print(s.index)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Label Alignment and Broadcasting**\n",
        "Operations between Series automatically align labels. If the labels do not match, Pandas fills with `NaN` for missing data.\n",
        "\n",
        "```python\n",
        "s1 = pd.Series([1, 2, 3], index=['a', 'b', 'c'])\n",
        "s2 = pd.Series([4, 5, 6], index=['b', 'c', 'd'])\n",
        "print(s1 + s2)\n",
        "```\n",
        "Output:\n",
        "```\n",
        "a    NaN\n",
        "b    6.0\n",
        "c    8.0\n",
        "d    NaN\n",
        "dtype: float64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Pandas Series Functionalities:\n",
        "\n",
        "- **Creation**: From lists, dictionaries, scalars, with custom indices.\n",
        "- **Accessing Data**: Using labels (`.loc[]`), positions (`.iloc[]`), and boolean masks.\n",
        "- **Modifying Data**: Adding, updating, and dropping elements.\n",
        "- **Mathematical Operations**: Element-wise operations, mathematical functions.\n",
        "- **Handling Missing Data**: `.fillna()`, `.dropna()`.\n",
        "- **\n",
        "\n",
        "Indexing**: Custom index, resetting index, reindexing.\n",
        "- **Combining Series**: Concatenation, appending.\n",
        "- **Statistical Functions**: `describe()`, `mean()`, `corr()`.\n",
        "- **Applying Functions**: Using `.apply()` for custom functions.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "i9w5sbuo590e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_pGTUqDh66Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Pandas Labels**\n",
        "* It is a one-dimensional array holding data of any type\n",
        "* Pandas labels are unique identifiers associated with each element in a Series or DataFrame\n",
        "* They provide a way to access and manipulate data based on meaningful names or categories rather than just integer indices\n",
        "\n",
        "\n",
        "**Key Characteristics:**\n",
        "\n",
        "* **Unique:** Each label within a Series or DataFrame must be unique.\n",
        "* **Immutable:** Labels cannot be modified once assigned.\n",
        "* **Data Type:** Labels can be of any data type (e.g., strings, integers, objects).\n",
        "* **Indexing:** Labels are used for indexing and selection of data.\n",
        "* **Alignment:** Labels are used for aligning Series and DataFrames during operations.\n",
        "\n",
        "\n",
        "**Types of Labels:**\n",
        "\n",
        "* **Integer labels:** Numeric indices used for traditional array-style access.\n",
        "* **String labels:** Descriptive names or categories assigned to elements.\n",
        "* **Datetime labels:** Timestamps used for time series data.\n",
        "* **Custom labels:** Any immutable object that can be used as a unique identifier.\n",
        "\n",
        "**Creating Labels:**\n",
        "\n",
        "* **Automatic labeling:** When creating a Series or DataFrame from a list or dictionary, labels are automatically generated based on the index or keys.\n",
        "\n",
        "* **Explicit labeling:** You can explicitly assign labels using the index attribute.\n",
        "---\n",
        "\n",
        "### 1. **Accessing Data Using Labels**\n",
        "\n",
        "#### a. **Using `.loc[]` for Label-Based Indexing**\n",
        "\n",
        "**Definition:**  \n",
        "`.loc[]` is used to access a group of rows and columns by labels (index or column names).\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.loc[row_labels, column_labels]\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['New York', 'San Francisco', 'Los Angeles']\n",
        "}, index=['A', 'B', 'C'])\n",
        "\n",
        "# Access data by label\n",
        "print(df.loc['A', 'Name'])  # Output: 'Alice'\n",
        "print(df.loc['B', :])       # Access all columns for row 'B'\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Alice\n",
        "Name          Bob\n",
        "Age            30\n",
        "City    San Francisco\n",
        "Name: B, dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### b. **Using `.iloc[]` for Integer-Based Indexing**\n",
        "\n",
        "**Definition:**  \n",
        "`.iloc[]` is used to access data by integer-based position (similar to NumPy).\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.iloc[row_index, column_index]\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Access data by integer position\n",
        "print(df.iloc[0, 0])  # Output: 'Alice' (First row, first column)\n",
        "print(df.iloc[1, :])  # All columns for the second row (Bob)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Alice\n",
        "Name            Bob\n",
        "Age              30\n",
        "City    San Francisco\n",
        "Name: B, dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Modifying Labels**\n",
        "\n",
        "#### a. **Renaming Labels**\n",
        "\n",
        "**Definition:**  \n",
        "The `.rename()` function is used to rename index labels or column names.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.rename(index={'old_label': 'new_label'}, columns={'old_col': 'new_col'})\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Rename row label 'A' to 'Alpha' and column 'Name' to 'First Name'\n",
        "df_renamed = df.rename(index={'A': 'Alpha'}, columns={'Name': 'First Name'})\n",
        "print(df_renamed)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      First Name  Age           City\n",
        "Alpha      Alice   25       New York\n",
        "B            Bob   30  San Francisco\n",
        "C        Charlie   35    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### b. **Setting Index Labels with `.set_index()`**\n",
        "\n",
        "**Definition:**  \n",
        "`.set_index()` is used to set one of the columns as the DataFrame's index.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.set_index(column_name)\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Set 'Name' as the index\n",
        "df_indexed = df.set_index('Name')\n",
        "print(df_indexed)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "          Age           City\n",
        "Name                         \n",
        "Alice      25       New York\n",
        "Bob        30  San Francisco\n",
        "Charlie    35    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### c. **Resetting Index with `.reset_index()`**\n",
        "\n",
        "**Definition:**  \n",
        "The `.reset_index()` method resets the index to the default integer-based index, optionally keeping the old index as a column.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.reset_index(drop=False)\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Reset index to default and keep the previous index as a column\n",
        "df_reset = df_indexed.reset_index()\n",
        "print(df_reset)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age           City\n",
        "0    Alice   25       New York\n",
        "1      Bob   30  San Francisco\n",
        "2  Charlie   35    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **MultiIndex (Hierarchical Indexing)**\n",
        "\n",
        "#### a. **Creating a MultiIndex**\n",
        "\n",
        "**Definition:**  \n",
        "A `MultiIndex` allows you to have multiple levels of index labels, which is useful for working with complex datasets.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "pd.MultiIndex.from_tuples(list_of_tuples)\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# MultiIndex with two levels (Location, ID)\n",
        "index = pd.MultiIndex.from_tuples([('New York', 'A'), ('San Francisco', 'B'), ('Los Angeles', 'C')], names=['City', 'ID'])\n",
        "df_multi = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}, index=index)\n",
        "print(df_multi)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "                       Name  Age\n",
        "City           ID                 \n",
        "New York       A      Alice   25\n",
        "San Francisco  B        Bob   30\n",
        "Los Angeles    C    Charlie   35\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### b. **Accessing Data in MultiIndex**\n",
        "\n",
        "**Definition:**  \n",
        "You can access data at different levels of the MultiIndex using `.loc[]`.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Access data for a specific location\n",
        "print(df_multi.loc['New York'])\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   Name  Age\n",
        "ID           \n",
        "A  Alice   25\n",
        "```\n",
        "\n",
        "```python\n",
        "# Access data for a specific (City, ID) combination\n",
        "print(df_multi.loc[('New York', 'A')])\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name    Alice\n",
        "Age        25\n",
        "Name: (New York, A), dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Handling Missing Labels**\n",
        "\n",
        "#### a. **Reindexing a DataFrame**\n",
        "\n",
        "**Definition:**  \n",
        "`.reindex()` is used to conform a DataFrame to a new index, adding missing rows or columns as `NaN`.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.reindex(new_labels)\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Reindexing rows, adding new labels with NaN values\n",
        "new_index = ['A', 'B', 'C', 'D']\n",
        "df_reindexed = df.reindex(new_index)\n",
        "print(df_reindexed)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "     Name   Age           City\n",
        "A   Alice  25.0       New York\n",
        "B     Bob  30.0  San Francisco\n",
        "C Charlie  35.0    Los Angeles\n",
        "D     NaN   NaN            NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### b. **Filling Missing Labels Using `.fillna()`**\n",
        "\n",
        "**Definition:**  \n",
        "`.fillna()` is used to fill missing values (`NaN`) with specific values.\n",
        "\n",
        "**Syntax:**  \n",
        "```python\n",
        "DataFrame.fillna(value)\n",
        "```\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Fill NaN values with 0\n",
        "df_filled = df_reindexed.fillna(0)\n",
        "print(df_filled)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name   Age           City\n",
        "A    Alice  25.0       New York\n",
        "B      Bob  30.0  San Francisco\n",
        "C  Charlie  35.0    Los Angeles\n",
        "D        0   0.0              0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Indexing with Boolean Masks**\n",
        "\n",
        "**Definition:**  \n",
        "You can filter data by creating a Boolean mask based on the labels or data in the DataFrame.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Filter rows where the 'Age' column is greater than 30\n",
        "mask = df['Age'] > 30\n",
        "print(df[mask])\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "C  Charlie   35  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Using `.at[]` and `.iat[]` for Fast Scalar Access**\n",
        "\n",
        "#### a. **`.at[]`: Access by Label**\n",
        "\n",
        "**Definition:**  \n",
        "`.at[]` is used to access a single element using a label.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Access the element at row 'A' and column 'Name'\n",
        "print(df.at['A', 'Name'])  # Output: 'Alice'\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### b. **`.iat[]`: Access by Integer Location**\n",
        "\n",
        "**Definition:**  \n",
        "`.iat[]` is used to access a single element using an integer location.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Access the element at row 0 and column 0\n",
        "print(df.iat[0, 0])  # Output: 'Alice'\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Indexing with Conditions Based on Labels**\n",
        "\n",
        "**Definition:**  \n",
        "You can select specific columns or rows based on conditional labels.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Select columns based on a list of column names\n",
        "print(df[['Name', 'Age']])  # Select 'Name' and 'Age' columns\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age\n",
        "A    Alice   25\n",
        "B      Bob   30\n",
        "C  Charlie   35\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Using `.query()` for Label-Based Querying**\n",
        "\n",
        "**Definition:**  \n",
        "`.query()` allows querying the DataFrame using column labels with a more readable syntax.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```python\n",
        "# Query rows where Age > 30\n",
        "print(df.query('Age > 30'))\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "C  Charlie   35  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Label Alignment**\n",
        "\n",
        "**Definition:**  \n",
        "Operations between Series and DataFrames automatically align labels by index, making Pandas label-alignment-friendly.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "```\n",
        "\n",
        "python\n",
        "# Automatic alignment by labels\n",
        "s = pd.Series([1, 2, 3], index=['A', 'B', 'C'])\n",
        "print(df['Age'] + s)  # Adds corresponding values by index labels\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "A    26\n",
        "B    32\n",
        "C    38\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **Summary of Pandas Label Methods:**\n",
        "\n",
        "- **Accessing**: `.loc[]`, `.iloc[]`, `.at[]`, `.iat[]`\n",
        "- **Modifying**: `.rename()`, `.set_index()`, `.reset_index()`\n",
        "- **MultiIndex**: Creating and accessing data with multiple labels.\n",
        "- **Handling Missing Labels**: `.reindex()`, `.fillna()`\n",
        "- **Filtering**: Boolean masks, `.query()`\n",
        "- **Fast Access**: `.at[]`, `.iat[]` for scalar access.\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "-kx1gPue66pT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YeD0GJSh9WsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Pandas DataFrame:**\n",
        "\n",
        "* **Pandas DataFrame** is a two-dimensional, size-mutable, and heterogeneous tabular data structure with labeled axes (rows and columns).\n",
        "* It is one of the most commonly used structures for data analysis in Python.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Creating a Pandas DataFrame**\n",
        "\n",
        "#### a. **From a Dictionary of Lists**\n",
        "You can create a DataFrame from a dictionary where keys are column names and values are lists.\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B  C\n",
        "0  1  4  7\n",
        "1  2  5  8\n",
        "2  3  6  9\n",
        "```\n",
        "\n",
        "#### b. **From a List of Dictionaries**\n",
        "Each dictionary in the list represents a row.\n",
        "```python\n",
        "data = [{'A': 1, 'B': 2}, {'A': 3, 'B': 4, 'C': 5}]\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B    C\n",
        "0  1  2  NaN\n",
        "1  3  4  5.0\n",
        "```\n",
        "\n",
        "#### c. **From a 2D NumPy Array**\n",
        "You can create a DataFrame from a NumPy array, optionally with custom row and column labels.\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "data = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B  C\n",
        "0  1  2  3\n",
        "1  4  5  6\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Accessing Data in DataFrame**\n",
        "\n",
        "#### a. **Accessing Columns**\n",
        "You can access a single column by its label.\n",
        "```python\n",
        "print(df['A'])\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "0    1\n",
        "1    4\n",
        "Name: A, dtype: int32\n",
        "```\n",
        "\n",
        "#### b. **Accessing Rows by Index (`.iloc[]`)**\n",
        "Access rows by their index position.\n",
        "```python\n",
        "print(df.iloc[1])\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "A    4\n",
        "B    5\n",
        "C    6\n",
        "Name: 1, dtype: int32\n",
        "```\n",
        "\n",
        "#### c. **Accessing Rows by Label (`.loc[]`)**\n",
        "Access rows by their index labels (row names).\n",
        "```python\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C'], index=['row1', 'row2'])\n",
        "print(df.loc['row1'])\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "A    1\n",
        "B    2\n",
        "C    3\n",
        "Name: row1, dtype: int32\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Modifying a DataFrame**\n",
        "\n",
        "#### a. **Adding a New Column**\n",
        "You can add a new column by assigning it a list or a scalar value.\n",
        "```python\n",
        "df['D'] = [10, 11]\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B  C   D\n",
        "0  1  2  3  10\n",
        "1  4  5  6  11\n",
        "```\n",
        "\n",
        "#### b. **Dropping Columns or Rows**\n",
        "Use `.drop()` to remove columns or rows.\n",
        "```python\n",
        "df = df.drop('C', axis=1)  # Drop column 'C'\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B   D\n",
        "0  1  2  10\n",
        "1  4  5  11\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Filtering and Boolean Indexing**\n",
        "\n",
        "#### a. **Filtering Rows Based on Conditions**\n",
        "Filter rows based on a condition.\n",
        "```python\n",
        "print(df[df['A'] > 1])\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B   D\n",
        "1  4  5  11\n",
        "```\n",
        "\n",
        "#### b. **Using `.isin()` to Filter**\n",
        "* Check if values are in a list.\n",
        "* Filters rows where a column contains specific values using\n",
        "```python\n",
        "print(df[df['B'].isin([2, 5])])\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B   D\n",
        "0  1  2  10\n",
        "1  4  5  11\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **DataFrame Operations**\n",
        "\n",
        "#### a. **Mathematical Operations**\n",
        "* You can apply mathematical operations directly on DataFrame columns.\n",
        "* Performs element-wise operations on DataFrame columns\n",
        "```python\n",
        "df['A_plus_B'] = df['A'] + df['B']\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B   D  A_plus_B\n",
        "0  1  2  10         3\n",
        "1  4  5  11         9\n",
        "```\n",
        "\n",
        "#### b. **Applying Functions Row/Column-wise (`.apply()`)**\n",
        "Apply a function to each row or column.\n",
        "```python\n",
        "df['double_A'] = df['A'].apply(lambda x: x * 2)\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B   D  A_plus_B  double_A\n",
        "0  1  2  10         3         2\n",
        "1  4  5  11         9         8\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Grouping and Aggregating Data**\n",
        "\n",
        "#### a. **Grouping Data (`.groupby()`)**\n",
        "Group rows based on column values.\n",
        "```python\n",
        "df = pd.DataFrame({'A': ['foo', 'bar', 'foo', 'bar'], 'B': [1, 2, 3, 4]})\n",
        "grouped = df.groupby('A').sum()\n",
        "print(grouped)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "       B\n",
        "A       \n",
        "bar    6\n",
        "foo    4\n",
        "```\n",
        "\n",
        "#### b. **Aggregating Data (`.agg()`)**\n",
        "Perform multiple aggregations on DataFrame columns.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3, 4]})\n",
        "print(df.agg(['sum', 'mean']))\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "      A\n",
        "sum   10\n",
        "mean   2.5\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Merging, Joining, and Concatenating DataFrames**\n",
        "\n",
        "#### a. **Concatenating DataFrames**\n",
        "You can concatenate DataFrames vertically or horizontally using `pd.concat()`.\n",
        "```python\n",
        "df1 = pd.DataFrame({'A': [1, 2]})\n",
        "df2 = pd.DataFrame({'B': [3, 4]})\n",
        "df_concat = pd.concat([df1, df2], axis=1)\n",
        "print(df_concat)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A  B\n",
        "0  1  3\n",
        "1  2  4\n",
        "```\n",
        "\n",
        "#### b. **Merging DataFrames (`pd.merge()`)**\n",
        "Merge DataFrames based on common columns or indices.\n",
        "```python\n",
        "df1 = pd.DataFrame({'key': ['A', 'B'], 'value': [1, 2]})\n",
        "df2 = pd.DataFrame({'key': ['A', 'B'], 'value2': [3, 4]})\n",
        "df_merged = pd.merge(df1, df2, on='key')\n",
        "print(df_merged)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "  key  value  value2\n",
        "0   A      1       3\n",
        "1   B      2       4\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Handling Missing Data**\n",
        "\n",
        "#### a. **Filling Missing Values (`.fillna()`)**\n",
        "Fill `NaN` values with a specific value.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, None, 3]})\n",
        "df_filled = df.fillna(0)\n",
        "print(df_filled)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "     A\n",
        "0  1.0\n",
        "1  0.0\n",
        "2  3.0\n",
        "```\n",
        "\n",
        "#### b. **Dropping Missing Values (`.dropna()`)**\n",
        "Remove rows containing `NaN` values.\n",
        "```python\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, None, 3], 'B': [4, 5, None]})\n",
        "df_dropped = df.dropna()\n",
        "print(df_dropped)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Sorting Data**\n",
        "\n",
        "#### a. **Sorting by Column Values (`.sort_values()`)**\n",
        "Sort the DataFrame based on column values.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [3, 1, 2]})\n",
        "df_sorted = df.sort_values(by='A')\n",
        "print(df_sorted)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A\n",
        "1  1\n",
        "2  2\n",
        "0  3\n",
        "```\n",
        "\n",
        "#### b. **Sorting by Index (`.sort_index()`)**\n",
        "Sort the DataFrame based on the index.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3]}, index=[2, 0, 1])\n",
        "df_sorted = df.sort_index()\n",
        "print(df_sorted)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A\n",
        "0  2\n",
        "1  3\n",
        "2  1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Statistical Functions**\n",
        "\n",
        "#### a. **Descriptive Statistics (`.describe()`)**\n",
        "Generate descriptive statistics for DataFrame columns.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "print(df.describe())\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "         A    B\n",
        "count  3.0  3.0\n",
        "mean   2.0  5.0\n",
        "std    1.0  1.0\n",
        "min    1.0  4.0\n",
        "25%    1.5  4.5\n",
        "50%    2.0  5.0\n",
        "75%    2.5  5.5\n",
        "max    3.0  6.0\n",
        "```\n",
        "\n",
        "#### b. **Correlation (`.corr()`)**\n",
        "Computes the correlation between DataFrame columns.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
        "print(df.corr())\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "     A    B\n",
        "A  1.0  1.0\n",
        "B  1.0  1.0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Pivoting and Reshaping**\n",
        "\n",
        "#### a. **Pivoting Data (`.pivot_table()`)**\n",
        "Create a pivot table based on the DataFrame.\n",
        "```python\n",
        "df = pd.DataFrame({'A': ['foo', 'bar', 'foo'], 'B': [1, 2, 3]})\n",
        "pivot_df = df.pivot_table(values='B', index='A', aggfunc='mean')\n",
        "print(pivot_df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "       B\n",
        "A       \n",
        "bar  2.0\n",
        "foo  2.0\n",
        "```\n",
        "\n",
        "#### b. **Reshaping with `.melt()`**\n",
        "Unpivots a DataFrame from wide format to long format.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
        "melted_df = pd.melt(df, id_vars='A', value_vars=['B'])\n",
        "print(melted_df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A variable  value\n",
        "0  1        B      3\n",
        "1  2        B      4\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 12. **Indexing and Selecting Data**\n",
        "\n",
        "#### a. **Resetting the Index (`.reset_index()`)**\n",
        "Resets the index of the DataFrame to default.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3]}, index=['x', 'y', 'z'])\n",
        "df_reset = df.reset_index()\n",
        "print(df_reset)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "  index  A\n",
        "0     x  1\n",
        "1     y  2\n",
        "2     z  3\n",
        "```\n",
        "\n",
        "#### b. **Reindexing the DataFrame (`.reindex()`)**\n",
        "Reindex the DataFrame to align with new row/column labels.\n",
        "```python\n",
        "df = pd.DataFrame({'A': [1, 2, 3]}, index=['a', 'b', 'c'])\n",
        "df_reindexed = df.reindex(['c', 'b', 'a', 'd'])\n",
        "print(df_reindexed)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "     A\n",
        "c  3.0\n",
        "b  2.0\n",
        "a  1.0\n",
        "d  NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 13. **Combining DataFrames**\n",
        "\n",
        "#### a. **Appending Rows (`.append()`)**\n",
        "Append rows of another DataFrame to the current DataFrame.\n",
        "```python\n",
        "df1 = pd.DataFrame({'A': [1, 2]})\n",
        "df2 = pd.DataFrame({'A': [3, 4]})\n",
        "df_appended = df1.append(df2)\n",
        "print(df_appended)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "   A\n",
        "0  1\n",
        "1  2\n",
        "0  3\n",
        "1  4\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 14. **Time Series Handling**\n",
        "\n",
        "#### a. **Handling Dates and Times (`pd.to_datetime()`)**\n",
        "Converts strings to datetime objects.\n",
        "```python\n",
        "df = pd.DataFrame({'A': ['2023-01-01', '2023-02-01']})\n",
        "df['A'] = pd.to_datetime(df['A'])\n",
        "print(df)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "           A\n",
        "0 2023-01-01\n",
        "1 2023-02-01\n",
        "```\n",
        "\n",
        "#### b. **Resampling Time Series Data (`.resample()`)**\n",
        "Resample time series data for different frequencies.\n",
        "```python\n",
        "df = pd.DataFrame({'A': pd.date_range('2023-01-01', periods=4, freq='D'), 'B': [1, 2, 3, 4]})\n",
        "df_resampled = df.resample('2D', on='A').sum()\n",
        "print(df_resampled)\n",
        "```\n",
        "**Output:**\n",
        "```\n",
        "            B\n",
        "A             \n",
        "2023-01-01  3\n",
        "2023-01-03  7\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "XNOAlWB19XrT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tkjx58-Q9Wp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Indexing and Selecting Data**\n",
        "* In Pandas, indexing and selecting data refers to the process of accessing specific elements, rows, or columns within a Series or DataFrame\n",
        "* It allows you to isolate and manipulate particular parts of your dataset\n",
        "\n",
        "\n",
        "### 1. **Basic Indexing**\n",
        "Indexing refers to selecting rows and columns from a DataFrame or Series. In Pandas, there are several ways to perform indexing:\n",
        "\n",
        "- **Single column selection:** You can select a single column by using the column name in square brackets `[]`.\n",
        "- **Multiple columns selection:** You can select multiple columns by passing a list of column names.\n",
        "- **Row selection:** You can select rows by label or position using `.loc[]` and `.iloc[]`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Single Column Selection**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Select single column (by column name)\n",
        "age_column = df['Age']\n",
        "print(age_column)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "0    25\n",
        "1    30\n",
        "2    35\n",
        "Name: Age, dtype: int64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Multiple Columns Selection**\n",
        "\n",
        "```python\n",
        "# Select multiple columns\n",
        "selected_columns = df[['Name', 'City']]\n",
        "print(selected_columns)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name           City\n",
        "0    Alice       New York\n",
        "1      Bob  San Francisco\n",
        "2  Charlie    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Label-Based Indexing with `.loc[]`**\n",
        "The `.loc[]` function is used for label-based indexing, meaning you select rows and columns based on their labels.\n",
        "\n",
        "#### **Syntax:**\n",
        "```python\n",
        "DataFrame.loc[row_labels, column_labels]\n",
        "```\n",
        "\n",
        "- `row_labels`: Can be a single label, a list of labels, or a slice of labels.\n",
        "- `column_labels`: Can be a single column name, a list of column names, or a slice of column names.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Label-Based Indexing with .loc[]**\n",
        "\n",
        "```python\n",
        "# Select rows and columns by label using .loc[]\n",
        "selected_data = df.loc[0, 'Name']  # First row, \"Name\" column\n",
        "print(selected_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Alice\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Multiple Rows and Columns with .loc[]**\n",
        "\n",
        "```python\n",
        "# Select multiple rows and columns\n",
        "selected_data = df.loc[0:1, ['Name', 'City']]\n",
        "print(selected_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name           City\n",
        "0  Alice       New York\n",
        "1    Bob  San Francisco\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Position-Based Indexing with `.iloc[]`**\n",
        "The `.iloc[]` function is used for integer-based indexing, where you select rows and columns by their positions (0-based index).\n",
        "\n",
        "#### **Syntax:**\n",
        "```python\n",
        "DataFrame.iloc[row_index, column_index]\n",
        "```\n",
        "\n",
        "- `row_index`: Integer index for rows.\n",
        "- `column_index`: Integer index for columns.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Position-Based Indexing with .iloc[]**\n",
        "\n",
        "```python\n",
        "# Select data using .iloc[] (by integer position)\n",
        "selected_data = df.iloc[0, 1]  # First row, second column (\"Age\")\n",
        "print(selected_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "25\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **Example: Multiple Rows and Columns with .iloc[]**\n",
        "\n",
        "```python\n",
        "# Select multiple rows and columns using .iloc[]\n",
        "selected_data = df.iloc[0:2, 0:2]  # First two rows, first two columns\n",
        "print(selected_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age\n",
        "0    Alice   25\n",
        "1      Bob   30\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Boolean Indexing**\n",
        "You can filter data using Boolean conditions. This is called Boolean Indexing, where the condition returns a Boolean mask (True/False) for filtering.\n",
        "\n",
        "#### **Example: Boolean Indexing**\n",
        "\n",
        "```python\n",
        "# Boolean indexing to filter rows where Age is greater than 30\n",
        "filtered_data = df[df['Age'] > 30]\n",
        "print(filtered_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "2  Charlie   35  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Using `.at[]` and `.iat[]` for Fast Scalar Access**\n",
        "- **`.at[]`**: Fast label-based access for a single element.\n",
        "- **`.iat[]`**: Fast position-based access for a single element.\n",
        "\n",
        "#### **Example: Using `.at[]` and `.iat[]`**\n",
        "\n",
        "```python\n",
        "# Access single value using .at[] (label-based)\n",
        "name_value = df.at[0, 'Name']\n",
        "print(name_value)\n",
        "\n",
        "# Access single value using .iat[] (position-based)\n",
        "age_value = df.iat[0, 1]\n",
        "print(age_value)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Alice\n",
        "25\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Slicing Data**\n",
        "You can slice rows and columns in Pandas similarly to how you slice lists or arrays in Python.\n",
        "\n",
        "#### **Example: Slicing Rows**\n",
        "\n",
        "```python\n",
        "# Slice rows from index 1 to 2 (inclusive)\n",
        "row_slice = df[1:3]\n",
        "print(row_slice)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age           City\n",
        "1      Bob   30  San Francisco\n",
        "2  Charlie   35    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Setting Data Using Labels or Indexes**\n",
        "You can set values in a DataFrame by using `.loc[]` or `.iloc[]`.\n",
        "\n",
        "#### **Example: Setting Values**\n",
        "\n",
        "```python\n",
        "# Set value using label-based indexing\n",
        "df.loc[0, 'Age'] = 26\n",
        "print(df)\n",
        "\n",
        "# Set value using integer-based indexing\n",
        "df.iloc[1, 2] = 'SF'\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   26      New York\n",
        "1      Bob   30  San Francisco\n",
        "2  Charlie   35    Los Angeles\n",
        "```\n",
        "\n",
        "After setting value with `.iloc[]`:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   26      New York\n",
        "1      Bob   30            SF\n",
        "2  Charlie   35    Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Indexing with Conditions (Boolean Masking)**\n",
        "You can use conditions to filter rows and select data that meets the condition.\n",
        "\n",
        "#### **Example: Conditional Selection**\n",
        "\n",
        "```python\n",
        "# Select rows where Age > 30\n",
        "filtered_data = df[df['Age'] > 30]\n",
        "print(filtered_data)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "2  Charlie   35  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Using `.query()` for Label-Based Querying**\n",
        "The `.query()` method allows querying a DataFrame using expressions based on column labels.\n",
        "\n",
        "#### **Example: Using `.query()`**\n",
        "\n",
        "```python\n",
        "# Query rows where Age > 30\n",
        "query_result = df.query('Age > 30')\n",
        "print(query_result)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name  Age         City\n",
        "2  Charlie   35  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **MultiIndex (Hierarchical Indexing)**\n",
        "Pandas allows for a MultiIndex, which is a way to have multiple levels of indexing, useful for more complex datasets.\n",
        "\n",
        "#### **Example: Creating a MultiIndex**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with a MultiIndex\n",
        "index = pd.MultiIndex.from_tuples([('NY', 'A'), ('SF', 'B'), ('LA', 'C')], names=['City', 'ID'])\n",
        "df_multi = pd.DataFrame({'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}, index=index)\n",
        "print(df_multi)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "             Name  Age\n",
        "City ID              \n",
        "NY   A      Alice   25\n",
        "SF   B        Bob   30\n",
        "LA   C    Charlie   35\n",
        "```\n",
        "\n",
        "#### **Accessing Data with MultiIndex**\n",
        "\n",
        "```python\n",
        "# Access data by MultiIndex\n",
        "print(df_multi.loc['NY'])  # All data for 'NY'\n",
        "print(df_multi.loc[('SF', 'B')])  # Specific (City, ID) combination\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name    Alice\n",
        "Age        25\n",
        "Name: A, dtype: object\n",
        "\n",
        "Name    Bob\n",
        "Age      30\n",
        "Name: B, dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Handling Missing Data (Null Values)**\n",
        "Handling missing data is crucial. You can use `.isnull()`, `.notnull()`, `.fillna()`, and `.dropna()` to handle missing values.\n",
        "\n",
        "#### **Example: Handling Missing Data**\n",
        "\n",
        "```python\n",
        "df_with_nan = df.reindex([0, 1, 2, 3])\n",
        "print(df_with_nan)\n",
        "\n",
        "# Fill NaN values\n",
        "df_filled = df_with_nan.fillna(0)\n",
        "print(df_filled)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name   Age         City\n",
        "0    Alice  26.0      New York\n",
        "1      Bob  30.0  San Francisco\n",
        "2  Charlie  35.0    Los Angeles\n",
        "3      NaN   NaN           NaN\n",
        "\n",
        "      Name   Age         City\n",
        "0    Alice  26.0      New York\n",
        "1      Bob  30.0  San Francisco\n",
        "2  Charlie  35.0    Los Angeles\n",
        "3        0   0.0             0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Summary\n",
        "This section covered:\n",
        "- Basic indexing (`[]`)\n",
        "- Label-based indexing (`.loc[]`)\n",
        "- Position-based indexing (`.iloc[]`)\n",
        "- Boolean indexing\n",
        "- Scalar access (`.at[]`, `.iat[]`)\n",
        "- Slicing\n",
        "- Setting values\n",
        "- Conditional selection\n",
        "- MultiIndexing\n",
        "- Handling missing data\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "qOzUQiBXA_eY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "klo2Dy2t9Wnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Types in Pandas**\n",
        "* Pandas supports a variety of data types, which are essential for effective data analysis and manipulation.\n",
        "\n",
        "### 1. **Understanding Data Types (`dtypes`)**\n",
        "In Pandas, each column in a DataFrame is assigned a specific data type. Pandas supports various data types like integers, floats, strings (objects), datetime, and more. The `.dtypes` attribute shows the data types of all columns.\n",
        "\n",
        "#### **Example: Checking Data Types**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35], 'Salary': [70000.0, 80000.0, 120000.0]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name       object\n",
        "Age         int64\n",
        "Salary    float64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Converting Data Types (`astype()`)**\n",
        "You can explicitly convert data from one type to another using `.astype()`. This is useful when handling data that comes in an incorrect type (e.g., numbers as strings).\n",
        "\n",
        "#### **Example: Convert Data Types**\n",
        "\n",
        "```python\n",
        "# Convert Age to float\n",
        "df['Age'] = df['Age'].astype(float)\n",
        "print(df.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name       object\n",
        "Age       float64\n",
        "Salary    float64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "#### **Example: Convert String to Integer**\n",
        "\n",
        "```python\n",
        "# Create DataFrame with string numbers\n",
        "data = {'ID': ['1', '2', '3'], 'Value': ['10', '20', '30']}\n",
        "df_str = pd.DataFrame(data)\n",
        "\n",
        "# Convert ID and Value columns to integer type\n",
        "df_str['ID'] = df_str['ID'].astype(int)\n",
        "df_str['Value'] = df_str['Value'].astype(int)\n",
        "print(df_str.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "ID       int64\n",
        "Value    int64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Automatic Type Inference**\n",
        "Pandas automatically infers the data type when a DataFrame or Series is created, but sometimes you may need to check the types and ensure they're correct.\n",
        "\n",
        "#### **Example: Automatic Type Detection**\n",
        "\n",
        "```python\n",
        "# Creating a DataFrame with mixed data types\n",
        "data = {'Name': ['Alice', 'Bob'], 'Age': [25, '30'], 'Salary': [60000, '75000']}\n",
        "df_mixed = pd.DataFrame(data)\n",
        "\n",
        "# Check the inferred types\n",
        "print(df_mixed.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name      object\n",
        "Age       object\n",
        "Salary    object\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Categorical Data Type**\n",
        "Categorical data is a type that stores limited, predefined values. This reduces memory usage and speeds up operations for certain columns, especially for large datasets with repeated values.\n",
        "\n",
        "#### **Example: Using Categorical Data**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with categorical data\n",
        "df['Department'] = pd.Categorical(['HR', 'Finance', 'IT'])\n",
        "print(df['Department'].dtype)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "category\n",
        "```\n",
        "\n",
        "#### **Example: Convert Column to Categorical**\n",
        "\n",
        "```python\n",
        "# Convert existing column to categorical type\n",
        "df['Name'] = df['Name'].astype('category')\n",
        "print(df.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name       category\n",
        "Age        float64\n",
        "Salary     float64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Datetime Data Type (`datetime64`)**\n",
        "The `datetime64` data type allows you to work with dates and times efficiently. You can convert a column to a datetime type using `pd.to_datetime()`.\n",
        "\n",
        "#### **Example: Converting to Datetime**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with date strings\n",
        "data = {'Event': ['Event1', 'Event2'], 'Date': ['2023-01-01', '2024-01-01']}\n",
        "df_dates = pd.DataFrame(data)\n",
        "\n",
        "# Convert 'Date' column to datetime64\n",
        "df_dates['Date'] = pd.to_datetime(df_dates['Date'])\n",
        "print(df_dates.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Event            object\n",
        "Date     datetime64[ns]\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "#### **Example: Datetime Operations**\n",
        "\n",
        "```python\n",
        "# Extract the year and month from a datetime column\n",
        "df_dates['Year'] = df_dates['Date'].dt.year\n",
        "df_dates['Month'] = df_dates['Date'].dt.month\n",
        "print(df_dates)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Event       Date  Year  Month\n",
        "0  Event1 2023-01-01  2023      1\n",
        "1  Event2 2024-01-01  2024      1\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Handling Missing Data Types (`NaN`)**\n",
        "Missing data in Pandas is represented by `NaN` (Not a Number). It is important to understand that `NaN` values have the float64 data type, even if they are in a column with integers.\n",
        "\n",
        "#### **Example: Handling Missing Data**\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "# Create DataFrame with NaN values\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, np.nan, 35]}\n",
        "df_nan = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df_nan.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name     object\n",
        "Age     float64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "#### **Example: Fill Missing Values**\n",
        "\n",
        "```python\n",
        "# Fill NaN values with a default value\n",
        "df_filled = df_nan.fillna(30)\n",
        "print(df_filled)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "      Name   Age\n",
        "0    Alice  25.0\n",
        "1      Bob  30.0\n",
        "2  Charlie  35.0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Object Data Type**\n",
        "The `object` data type in Pandas is used for storing strings or mixed data types. If a column contains both numeric and non-numeric values, it will default to the object data type.\n",
        "\n",
        "#### **Example: Object Type for Strings**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with strings\n",
        "data = {'Name': ['Alice', 'Bob'], 'City': ['New York', 'San Francisco']}\n",
        "df_strings = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df_strings.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name    object\n",
        "City    object\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Float Data Type (`float64`)**\n",
        "The float data type is used for decimal numbers. If a column contains numbers with decimals, Pandas will infer it as `float64`.\n",
        "\n",
        "#### **Example: Float Data Type**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with float numbers\n",
        "data = {'Name': ['Alice', 'Bob'], 'Salary': [75000.0, 85000.0]}\n",
        "df_float = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df_float.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Name      object\n",
        "Salary    float64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Integer Data Type (`int64`)**\n",
        "The integer data type is used for whole numbers. Pandas assigns columns with whole numbers to the `int64` type.\n",
        "\n",
        "#### **Example: Integer Data Type**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with integer numbers\n",
        "data = {'ID': [101, 102, 103], 'Age': [25, 30, 35]}\n",
        "df_int = pd.DataFrame(data)\n",
        "\n",
        "# Check data types\n",
        "print(df_int.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "ID     int64\n",
        "Age    int64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Nullable Integer Data Type (`Int64`)**\n",
        "Pandas supports nullable integer types (`Int64`), which allow columns to have `NaN` (missing values) and integer values.\n",
        "\n",
        "#### **Example: Nullable Integer**\n",
        "\n",
        "```python\n",
        "# Create a DataFrame with NaN in integer column\n",
        "data = {'ID': [101, np.nan, 103]}\n",
        "df_nullable_int = pd.DataFrame(data, dtype='Int64')\n",
        "\n",
        "# Check data types\n",
        "print(df_nullable_int.dtypes)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "ID    Int64\n",
        "dtype: object\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Checking Memory Usage (`memory_usage()`)**\n",
        "You can check the memory usage of each column in a DataFrame using the `.memory_usage()` method. This is useful for optimizing data types.\n",
        "\n",
        "#### **Example: Checking Memory Usage**\n",
        "\n",
        "```python\n",
        "# Check memory usage of DataFrame\n",
        "memory_usage = df.memory_usage(deep=True)\n",
        "print(memory_usage)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "Index      128\n",
        "Name        90\n",
        "Age         24\n",
        "Salary      24\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Key Methods for Data Types:\n",
        "- **Checking Data Types:** `.dtypes`\n",
        "- **Converting Data Types:** `.astype()`\n",
        "- **Handling Missing Values:** `.fillna()`, `.dropna()`\n",
        "- **Categorical Data:** `pd.Categorical()`, `astype('category')`\n",
        "- **Datetime Data:** `pd.to_datetime()`, `.dt` accessor for extracting components\n",
        "- **Nullable Integers:** `Int64`\n",
        "- **Memory Optimization:** `.memory_usage()`\n"
      ],
      "metadata": {
        "id": "zqzPsTbZCGyo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kpi6EMD39Wjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Reading and Writing Data (CSV, Excel, SQL, etc.)**\n",
        "---\n",
        "\n",
        "### 1. **Reading CSV Files (`pd.read_csv()`)**\n",
        "Pandas can read CSV files using the `pd.read_csv()` function. This is one of the most commonly used functions for importing data into Pandas.\n",
        "\n",
        "#### **Example: Reading a CSV File**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Reading a CSV file\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Writing to CSV Files (`df.to_csv()`)**\n",
        "You can write DataFrame data to a CSV file using the `to_csv()` method. By default, it writes data with an index column.\n",
        "\n",
        "#### **Example: Writing to a CSV File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to CSV without index\n",
        "df.to_csv('output.csv', index=False)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "A CSV file `output.csv` is created without the index column.\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Reading Excel Files (`pd.read_excel()`)**\n",
        "Pandas can read Excel files using the `pd.read_excel()` function. You can specify the sheet name if the Excel file contains multiple sheets.\n",
        "\n",
        "#### **Example: Reading an Excel File**\n",
        "\n",
        "```python\n",
        "# Reading an Excel file\n",
        "df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_excel.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Writing to Excel Files (`df.to_excel()`)**\n",
        "You can write data to an Excel file using `to_excel()`. Similar to CSV, you can control whether to include the index and specify the sheet name.\n",
        "\n",
        "#### **Example: Writing to an Excel File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to Excel without index\n",
        "df.to_excel('output.xlsx', index=False, sheet_name='Employees')\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "An Excel file `output.xlsx` is created with the DataFrame data on the sheet \"Employees\".\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Reading SQL Databases (`pd.read_sql()`)**\n",
        "Pandas can read data from SQL databases using `pd.read_sql()`. You need a connection object to the database and a valid SQL query.\n",
        "\n",
        "#### **Example: Reading from an SQL Database**\n",
        "\n",
        "```python\n",
        "import sqlite3\n",
        "\n",
        "# Create a connection to the database\n",
        "conn = sqlite3.connect('example.db')\n",
        "\n",
        "# Query the SQL database\n",
        "df_sql = pd.read_sql('SELECT * FROM employees', conn)\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_sql.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Writing to SQL Databases (`df.to_sql()`)**\n",
        "You can write data to an SQL database using `to_sql()`. You'll need to pass the table name and connection object.\n",
        "\n",
        "#### **Example: Writing to an SQL Database**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to SQL table\n",
        "df.to_sql('employees', conn, if_exists='replace', index=False)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "The data from the DataFrame is written to the `employees` table in the SQL database.\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Reading JSON Files (`pd.read_json()`)**\n",
        "Pandas can read data from JSON files using `pd.read_json()`. This is useful for working with web data or APIs.\n",
        "\n",
        "#### **Example: Reading a JSON File**\n",
        "\n",
        "```python\n",
        "# Reading a JSON file\n",
        "df_json = pd.read_json('data.json')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_json.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Writing to JSON Files (`df.to_json()`)**\n",
        "You can write a DataFrame to a JSON file using the `to_json()` method. You can control the format of the JSON output (e.g., `records`, `split`).\n",
        "\n",
        "#### **Example: Writing to a JSON File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to JSON\n",
        "df.to_json('output.json', orient='records')\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "A JSON file `output.json` is created with the DataFrame data in the \"records\" format.\n",
        "\n",
        "---\n",
        "\n",
        "### 9. **Reading HTML Tables (`pd.read_html()`)**\n",
        "Pandas can extract tables from HTML files or web pages using the `pd.read_html()` function. It returns a list of DataFrames if multiple tables are present.\n",
        "\n",
        "#### **Example: Reading an HTML Table**\n",
        "\n",
        "```python\n",
        "# Reading tables from an HTML file\n",
        "df_html_list = pd.read_html('data.html')\n",
        "\n",
        "# Select the first table\n",
        "df_html = df_html_list[0]\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_html.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 10. **Writing to HTML Files (`df.to_html()`)**\n",
        "You can write a DataFrame to an HTML file using `to_html()`, which converts the DataFrame into an HTML table.\n",
        "\n",
        "#### **Example: Writing to an HTML File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to HTML\n",
        "df.to_html('output.html', index=False)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "An HTML file `output.html` is created with the DataFrame data as an HTML table.\n",
        "\n",
        "---\n",
        "\n",
        "### 11. **Reading from a Clipboard (`pd.read_clipboard()`)**\n",
        "Pandas can read data that has been copied to your system clipboard using the `pd.read_clipboard()` function. This is convenient for quick data sharing from spreadsheets or websites.\n",
        "\n",
        "#### **Example: Reading from Clipboard**\n",
        "\n",
        "```python\n",
        "# Reading data from clipboard\n",
        "df_clipboard = pd.read_clipboard()\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_clipboard.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 12. **Writing to a Clipboard (`df.to_clipboard()`)**\n",
        "You can write DataFrame data to the clipboard using `to_clipboard()`. This is useful for quickly pasting data into other applications.\n",
        "\n",
        "#### **Example: Writing to Clipboard**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to clipboard\n",
        "df.to_clipboard(index=False)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "The DataFrame data is now copied to your system clipboard and can be pasted into a spreadsheet or text editor.\n",
        "\n",
        "---\n",
        "\n",
        "### 13. **Reading Pickle Files (`pd.read_pickle()`)**\n",
        "Pandas can read a DataFrame from a pickle file using `pd.read_pickle()`. This is a binary format specific to Python, which is faster than CSV for large datasets.\n",
        "\n",
        "#### **Example: Reading a Pickle File**\n",
        "\n",
        "```python\n",
        "# Reading a pickle file\n",
        "df_pickle = pd.read_pickle('data.pkl')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_pickle.head())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "   ID    Name  Age   Salary\n",
        "0   1   Alice   25   70000\n",
        "1   2     Bob   30   80000\n",
        "2   3  Charlie  35  120000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 14. **Writing to Pickle Files (`df.to_pickle()`)**\n",
        "You can write DataFrame data to a pickle file using `to_pickle()`. This is useful for saving data quickly in a format that can be loaded back into Pandas.\n",
        "\n",
        "#### **Example: Writing to a Pickle File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to a pickle file\n",
        "df.to_pickle('output.pkl')\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "A pickle file `output.pkl` is created with the DataFrame data.\n",
        "\n",
        "---\n",
        "\n",
        "### 15. **Reading and Writing Parquet Files**\n",
        "Pandas supports the Parquet format, which is a columnar storage file format optimized for large-scale data processing.\n",
        "\n",
        "#### **Example: Reading a Parquet File**\n",
        "\n",
        "```python\n",
        "# Reading a Parquet file\n",
        "df_parquet = pd.read_parquet('data.parquet')\n",
        "\n",
        "# Display the first few rows\n",
        "print(df_parquet.head())\n",
        "```\n",
        "\n",
        "#### **Example: Writing to a Parquet File**\n",
        "\n",
        "```python\n",
        "# Writing DataFrame to Parquet\n",
        "df.to_parquet('output.parquet')\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Summary of Key Methods for Reading and Writing Data:\n",
        "- **CSV Files:** `pd.read_csv()`, `df.to_csv()`\n",
        "- **Excel Files:** `pd.read_excel()`, `df.to_excel()`\n",
        "- **SQL Databases:** `pd.read_sql()`, `df.to_sql()`\n",
        "- **\n",
        "\n",
        "JSON Files:** `pd.read_json()`, `df.to_json()`\n",
        "- **HTML Tables:** `pd.read_html()`, `df.to_html()`\n",
        "- **Clipboard:** `pd.read_clipboard()`, `df.to_clipboard()`\n",
        "- **Pickle Files:** `pd.read_pickle()`, `df.to_pickle()`\n",
        "- **Parquet Files:** `pd.read_parquet()`, `df.to_parquet()`\n",
        "\n",
        "---\n",
        "---\n",
        "---\n"
      ],
      "metadata": {
        "id": "m7GSaJC8C-68"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-3a6o8Qy9Wd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Data Cleaning and Preprocessing**\n",
        "* Data cleaning and preprocessing are essential steps in data analysis to ensure data quality and consistency\n",
        "* Pandas provides a rich set of tools to handle these tasks effectively.\n",
        "\n",
        "---\n",
        "\n",
        "### 1. **Handling Missing Data**\n",
        "\n",
        "Missing data is common in real-world datasets. Pandas provides several methods to handle missing values effectively.\n",
        "\n",
        "#### **1.1. Identifying Missing Data (`isna()`, `notna()`)**\n",
        "\n",
        "- **`isna()`**: Returns a DataFrame of Boolean values, where `True` indicates a missing value.\n",
        "- **`notna()`**: Returns the opposite of `isna()`, where `True` indicates a non-missing value.\n",
        "\n",
        "#### **Example: Checking for Missing Data**\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data with missing values\n",
        "data = {'Name': ['Alice', 'Bob', None],\n",
        "        'Age': [25, None, 35],\n",
        "        'Salary': [70000, 80000, None]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Identifying missing data\n",
        "print(df.isna())\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name    Age  Salary\n",
        "0  False  False   False\n",
        "1  False   True   False\n",
        "2   True  False    True\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **1.2. Dropping Missing Data (`dropna()`)**\n",
        "\n",
        "- **`dropna()`**: Removes rows or columns with missing data. You can specify to drop rows (`axis=0`) or columns (`axis=1`).\n",
        "\n",
        "#### **Example: Dropping Rows with Missing Data**\n",
        "\n",
        "```python\n",
        "# Dropping rows with missing values\n",
        "df_dropped = df.dropna()\n",
        "\n",
        "print(df_dropped)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary\n",
        "0  Alice  25.0  70000.0\n",
        "```\n",
        "\n",
        "#### **Example: Dropping Columns with Missing Data**\n",
        "\n",
        "```python\n",
        "# Dropping columns with missing values\n",
        "df_dropped_col = df.dropna(axis=1)\n",
        "\n",
        "print(df_dropped_col)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name\n",
        "0  Alice\n",
        "1    Bob\n",
        "2   None\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **1.3. Filling Missing Data (`fillna()`)**\n",
        "\n",
        "- **`fillna()`**: Fills missing values with a specified value or method (like forward-fill, backward-fill).\n",
        "\n",
        "#### **Example: Filling Missing Data with a Specific Value**\n",
        "\n",
        "```python\n",
        "# Filling missing data with 0\n",
        "df_filled = df.fillna(0)\n",
        "\n",
        "print(df_filled)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary\n",
        "0  Alice  25.0  70000.0\n",
        "1    Bob   0.0  80000.0\n",
        "2    0.0  35.0      0.0\n",
        "```\n",
        "\n",
        "#### **Example: Forward Filling Missing Data**\n",
        "\n",
        "```python\n",
        "# Forward fill (propagate the next valid value forward)\n",
        "df_ffill = df.fillna(method='ffill')\n",
        "\n",
        "print(df_ffill)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary\n",
        "0  Alice  25.0  70000.0\n",
        "1    Bob  25.0  80000.0\n",
        "2    Bob  35.0  80000.0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **1.4. Interpolating Missing Data (`interpolate()`)**\n",
        "\n",
        "- **`interpolate()`**: Fills missing values by interpolating between existing data points.\n",
        "\n",
        "#### **Example: Interpolating Missing Data**\n",
        "\n",
        "```python\n",
        "# Interpolating missing data\n",
        "df_interpolated = df.interpolate()\n",
        "\n",
        "print(df_interpolated)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary\n",
        "0  Alice  25.0  70000.0\n",
        "1    Bob  30.0  80000.0\n",
        "2    Bob  35.0  80000.0\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Handling Duplicates (`drop_duplicates()`)**\n",
        "\n",
        "Duplicate rows can be a problem when processing data. Pandas provides the `drop_duplicates()` function to remove them.\n",
        "\n",
        "#### **Example: Dropping Duplicate Rows**\n",
        "\n",
        "```python\n",
        "# Sample data with duplicates\n",
        "data_dup = {'Name': ['Alice', 'Bob', 'Bob'],\n",
        "            'Age': [25, 30, 30],\n",
        "            'Salary': [70000, 80000, 80000]}\n",
        "\n",
        "df_dup = pd.DataFrame(data_dup)\n",
        "\n",
        "# Dropping duplicate rows\n",
        "df_unique = df_dup.drop_duplicates()\n",
        "\n",
        "print(df_unique)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name  Age  Salary\n",
        "0  Alice   25   70000\n",
        "1    Bob   30   80000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Data Transformation**\n",
        "\n",
        "#### **3.1. Replacing Values (`replace()`)**\n",
        "\n",
        "You can replace specific values in the DataFrame using `replace()`.\n",
        "\n",
        "#### **Example: Replacing Specific Values**\n",
        "\n",
        "```python\n",
        "# Replace all occurrences of 70000 with 75000\n",
        "df_replaced = df.replace(70000, 75000)\n",
        "\n",
        "print(df_replaced)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary\n",
        "0  Alice  25.0  75000.0\n",
        "1    Bob   NaN  80000.0\n",
        "2   None  35.0      NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### **3.2. Renaming Columns (`rename()`)**\n",
        "\n",
        "You can rename columns using `rename()`.\n",
        "\n",
        "#### **Example: Renaming a Column**\n",
        "\n",
        "```python\n",
        "# Rename the 'Salary' column to 'Income'\n",
        "df_renamed = df.rename(columns={'Salary': 'Income'})\n",
        "\n",
        "print(df_renamed)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Income\n",
        "0  Alice  25.0  70000.0\n",
        "1    Bob   NaN  80000.0\n",
        "2   None  35.0      NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Changing Data Types (`astype()`)**\n",
        "\n",
        "You may need to convert the data type of a column. The `astype()` function allows you to change the data type.\n",
        "\n",
        "#### **Example: Changing the Data Type of a Column**\n",
        "\n",
        "```python\n",
        "# Convert the 'Age' column to an integer\n",
        "df_converted = df.astype({'Age': 'Int64'})\n",
        "\n",
        "print(df_converted)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name  Age   Salary\n",
        "0  Alice   25  70000.0\n",
        "1    Bob  <NA>  80000.0\n",
        "2   None   35     NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Binning and Categorizing Data (`cut()`, `qcut()`)**\n",
        "\n",
        "You can group continuous data into discrete intervals using `cut()` or `qcut()`.\n",
        "\n",
        "#### **Example: Binning Data into Intervals**\n",
        "\n",
        "```python\n",
        "# Binning ages into categories\n",
        "bins = [0, 18, 35, 60]\n",
        "labels = ['Teen', 'Adult', 'Senior']\n",
        "df['Age_Group'] = pd.cut(df['Age'], bins=bins, labels=labels)\n",
        "\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary Age_Group\n",
        "0  Alice  25.0  70000.0     Adult\n",
        "1    Bob   NaN  80000.0      NaN\n",
        "2   None  35.0      NaN     Adult\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Scaling and Normalizing Data**\n",
        "\n",
        "Pandas can normalize data, although libraries like `scikit-learn` are typically used. You can perform simple scaling using `apply()`.\n",
        "\n",
        "#### **Example: Scaling Salary by Dividing by 1000**\n",
        "\n",
        "```python\n",
        "# Scale Salary column by dividing by 1000\n",
        "df['Salary_Scaled'] = df['Salary'] / 1000\n",
        "\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary Age_Group  Salary_Scaled\n",
        "0  Alice  25.0  70000.0     Adult         70.0\n",
        "1    Bob   NaN  80000.0      NaN         80.0\n",
        "2   None  35.0      NaN     Adult          NaN\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **String Operations**\n",
        "\n",
        "String data in a DataFrame can be manipulated using `str` accessor methods.\n",
        "\n",
        "#### **Example: Converting to Lowercase**\n",
        "\n",
        "```python\n",
        "# Converting 'Name' column to lowercase\n",
        "df['Name_Lower'] = df['Name'].str.lower()\n",
        "\n",
        "print(df)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary Age_Group  Salary_Scaled Name_Lower\n",
        "0  Alice  25.0  70000.0     Adult         70.0      alice\n",
        "1    Bob   NaN  80000.0      NaN         80.0        bob\n",
        "2   None  35.0      NaN     Adult          NaN       None\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 8. **Outlier Detection and Removal**\n",
        "\n",
        "Detecting and removing outliers is important during preprocessing. One approach is to use interquartile ranges (IQR).\n",
        "\n",
        "#### **Example: Detecting Outliers Using IQR**\n",
        "\n",
        "```python\n",
        "# Calculate the IQR for the Salary column\n",
        "Q1 = df['Salary'].quantile(0.25)\n",
        "Q3 = df['Salary'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outliers as anything outside 1.5 * IQR\n",
        "df_outliers = df[~((df['Salary'] < (Q1 - 1.5 * IQR)) | (df['Salary'] > (Q3 + 1\n",
        "\n",
        ".5 * IQR)))]\n",
        "\n",
        "print(df_outliers)\n",
        "```\n",
        "\n",
        "**Output:**\n",
        "```\n",
        "    Name   Age   Salary Age_Group  Salary_Scaled Name_Lower\n",
        "0  Alice  25.0  70000.0     Adult         70.0      alice\n",
        "1    Bob   NaN  80000.0      NaN         80.0        bob\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "_ITdK_9xDeV4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlhPtmsu9WZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "### **Handling Missing Data**\n",
        "\n",
        "* Handling missing data is a crucial aspect of data analysis, as missing values can lead to inaccurate results and insights. * Pandas provides several methods to identify, handle, and fill missing data.\n",
        "\n",
        "### 1. Identifying Missing Data\n",
        "• **Definition**: Missing data can be identified using functions that check for null or NaN (Not a Number) values.\n",
        "• **Methods**:\n",
        "  - `isnull()`: Returns a DataFrame of the same shape as the original, with `True` for missing values and `False` for non-missing values.\n",
        "  - `notnull()`: Returns the opposite of `isnull()`, indicating non-missing values.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'A': [1, 2, np.nan], 'B': [4, np.nan, 6]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Identifying missing data\n",
        "missing_data = df.isnull()\n",
        "print(missing_data)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "       A      B\n",
        "0  False  False\n",
        "1  False   True\n",
        "2   True  False\n",
        "```\n",
        "\n",
        "### 2. Dropping Missing Data\n",
        "• **Definition**: Removing rows or columns that contain missing values.\n",
        "• **Methods**:\n",
        "  - `dropna()`: Removes missing values based on specified criteria.\n",
        "    - `axis=0`: Drop rows with missing values.\n",
        "    - `axis=1`: Drop columns with missing values.\n",
        "    - `how='any'`: Drop if any value is missing.\n",
        "    - `how='all'`: Drop if all values are missing.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Dropping rows with any missing values\n",
        "df_dropped_rows = df.dropna(axis=0, how='any')\n",
        "print(df_dropped_rows)\n",
        "\n",
        "# Dropping columns with any missing values\n",
        "df_dropped_columns = df.dropna(axis=1, how='any')\n",
        "print(df_dropped_columns)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   A    B\n",
        "0  1.0  4.0\n",
        "```\n",
        "```\n",
        "     A\n",
        "0  1.0\n",
        "1  2.0\n",
        "```\n",
        "\n",
        "### 3. Filling Missing Data\n",
        "• **Definition**: Replacing missing values with a specified value or method.\n",
        "• **Methods**:\n",
        "  - `fillna()`: Fill missing values with a specified value, method, or forward/backward fill.\n",
        "    - `value`: Fill with a specific value.\n",
        "    - `method='ffill'`: Forward fill.\n",
        "    - `method='bfill'`: Backward fill.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filling missing values with a specific value\n",
        "df_filled_value = df.fillna(0)\n",
        "print(df_filled_value)\n",
        "\n",
        "# Forward filling missing values\n",
        "df_filled_ffill = df.fillna(method='ffill')\n",
        "print(df_filled_ffill)\n",
        "\n",
        "# Backward filling missing values\n",
        "df_filled_bfill = df.fillna(method='bfill')\n",
        "print(df_filled_bfill)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "1  2.0  0.0\n",
        "2  0.0  6.0\n",
        "```\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "1  2.0  4.0\n",
        "2  2.0  6.0\n",
        "```\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "1  2.0  6.0\n",
        "2  2.0  6.0\n",
        "```\n",
        "\n",
        "### 4. Interpolating Missing Data\n",
        "• **Definition**: Estimating missing values based on other available data points.\n",
        "• **Method**:\n",
        "  - `interpolate()`: Fills missing values using interpolation methods (linear, polynomial, etc.).\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Interpolating missing values\n",
        "df_interpolated = df.interpolate()\n",
        "print(df_interpolated)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "1  2.0  5.0\n",
        "2  3.0  6.0\n",
        "```\n",
        "\n",
        "### 5. Replacing Missing Data\n",
        "• **Definition**: Replacing missing values with another value or method.\n",
        "• **Method**:\n",
        "  - `replace()`: Replace specified values with another value.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Replacing NaN with a specific value\n",
        "df_replaced = df.replace(np.nan, -1)\n",
        "print(df_replaced)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A    B\n",
        "0  1.0  4.0\n",
        "1  2.0 -1.0\n",
        "2 -1.0  6.0\n",
        "```\n",
        "\n",
        "### 6. Checking for Missing Data\n",
        "• **Definition**: Summarizing the count of missing values in the DataFrame.\n",
        "• **Method**:\n",
        "  - `isnull().sum()`: Returns the count of missing values for each column.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Checking for missing data\n",
        "missing_count = df.isnull().sum()\n",
        "print(missing_count)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "A    1\n",
        "B    1\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 7. Advanced Techniques\n",
        "• **Using `pd.Series` with `isna()`**: Similar to `isnull()`, but can be used for Series objects.\n",
        "• **Custom Functions**: You can define custom functions to handle missing data based on specific business logic.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "### **Filtering and Sorting data**\n",
        "\n",
        "* Filtering and sorting data in Pandas are essential operations for data analysis, allowing you to extract specific subsets of data and arrange them in a meaningful order.\n",
        "\n",
        "### 1. Filtering Data\n",
        "• **Definition**: Extracting rows from a DataFrame based on specific conditions.\n",
        "• **Methods**:\n",
        "  - Boolean indexing: Using boolean conditions to filter rows.\n",
        "  - `query()`: A method that allows filtering using a query string.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, 30, 22, 35],\n",
        "    'Salary': [50000, 60000, 45000, 70000]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Filtering using boolean indexing\n",
        "filtered_age = df[df['Age'] > 25]\n",
        "print(filtered_age)\n",
        "\n",
        "# Filtering using query()\n",
        "filtered_query = df.query('Salary > 55000')\n",
        "print(filtered_query)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "    Name  Age  Salary\n",
        "1    Bob   30   60000\n",
        "3  David   35   70000\n",
        "```\n",
        "```\n",
        "    Name  Age  Salary\n",
        "1    Bob   30   60000\n",
        "3  David   35   70000\n",
        "```\n",
        "\n",
        "### 2. Filtering with Multiple Conditions\n",
        "• **Definition**: Applying multiple conditions to filter data using logical operators.\n",
        "• **Methods**:\n",
        "  - Using `&` (and), `|` (or) for combining conditions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filtering with multiple conditions\n",
        "filtered_multiple = df[(df['Age'] > 25) & (df['Salary'] > 55000)]\n",
        "print(filtered_multiple)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "    Name  Age  Salary\n",
        "1    Bob   30   60000\n",
        "3  David   35   70000\n",
        "```\n",
        "\n",
        "### 3. Sorting Data\n",
        "• **Definition**: Arranging the rows of a DataFrame based on the values in one or more columns.\n",
        "• **Methods**:\n",
        "  - `sort_values()`: Sorts the DataFrame by specified column(s).\n",
        "    - `by`: Column name(s) to sort by.\n",
        "    - `ascending`: Boolean to specify ascending or descending order.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sorting by a single column\n",
        "sorted_by_age = df.sort_values(by='Age')\n",
        "print(sorted_by_age)\n",
        "\n",
        "# Sorting by multiple columns\n",
        "sorted_by_multiple = df.sort_values(by=['Salary', 'Age'], ascending=[True, False])\n",
        "print(sorted_by_multiple)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "    Name  Age  Salary\n",
        "2  Charlie   22   45000\n",
        "0    Alice   24   50000\n",
        "1      Bob   30   60000\n",
        "3    David   35   70000\n",
        "```\n",
        "```\n",
        "    Name  Age  Salary\n",
        "2  Charlie   22   45000\n",
        "0    Alice   24   50000\n",
        "1      Bob   30   60000\n",
        "3    David   35   70000\n",
        "```\n",
        "\n",
        "### 4. Sorting by Index\n",
        "• **Definition**: Sorting the DataFrame based on its index.\n",
        "• **Method**:\n",
        "  - `sort_index()`: Sorts the DataFrame by its index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with custom index\n",
        "df_indexed = df.set_index('Name')\n",
        "\n",
        "# Sorting by index\n",
        "sorted_by_index = df_indexed.sort_index()\n",
        "print(sorted_by_index)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          Age  Salary\n",
        "Name                 \n",
        "Alice      24   50000\n",
        "Bob        30   60000\n",
        "Charlie    22   45000\n",
        "David      35   70000\n",
        "```\n",
        "\n",
        "### 5. Sorting with NaN Values\n",
        "• **Definition**: Handling NaN values while sorting.\n",
        "• **Method**:\n",
        "  - `na_position`: Specifies whether NaN values should be placed at the beginning or end.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with NaN values\n",
        "data_nan = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, None, 22, 35],\n",
        "    'Salary': [50000, 60000, None, 70000]\n",
        "}\n",
        "df_nan = pd.DataFrame(data_nan)\n",
        "\n",
        "# Sorting with NaN values at the end\n",
        "sorted_nan = df_nan.sort_values(by='Age', na_position='last')\n",
        "print(sorted_nan)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name   Age   Salary\n",
        "0    Alice  24.0  50000.0\n",
        "2  Charlie  22.0      NaN\n",
        "3    David  35.0  70000.0\n",
        "1      Bob   NaN  60000.0\n",
        "```\n",
        "\n",
        "### 6. Resetting Index After Sorting\n",
        "• **Definition**: Resetting the index of a DataFrame after sorting.\n",
        "• **Method**:\n",
        "  - `reset_index()`: Resets the index of the DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Resetting index after sorting\n",
        "sorted_reset_index = df.sort_values(by='Age').reset_index(drop=True)\n",
        "print(sorted_reset_index)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name   Age  Salary\n",
        "0  Charlie  22.0     NaN\n",
        "1    Alice  24.0  50000.0\n",
        "2      Bob  30.0  60000.0\n",
        "3    David  35.0  70000.0\n",
        "```\n",
        "\n",
        "----\n",
        "----\n",
        "----\n",
        "\n",
        "### **Merging , Joining , Concatenating data**\n",
        "\n",
        "* Merging, joining, and concatenating data in Pandas are essential operations for combining multiple DataFrames into a single DataFrame. Each method serves different purposes and is used in various scenarios.\n",
        "\n",
        "### 1. Merging DataFrames\n",
        "• **Definition**: Merging combines two DataFrames based on a common key or index, similar to SQL joins.\n",
        "• **Method**:\n",
        "  - `merge()`: Combines DataFrames based on specified columns or indices.\n",
        "    - `how`: Type of merge to be performed (inner, outer, left, right).\n",
        "    - `on`: Column(s) to join on.\n",
        "    - `left_on` and `right_on`: Columns from the left and right DataFrames to join on.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrames\n",
        "df1 = pd.DataFrame({\n",
        "    'EmployeeID': [1, 2, 3],\n",
        "    'Name': ['Alice', 'Bob', 'Charlie']\n",
        "})\n",
        "\n",
        "df2 = pd.DataFrame({\n",
        "    'EmployeeID': [1, 2, 4],\n",
        "    'Salary': [50000, 60000, 70000]\n",
        "})\n",
        "\n",
        "# Merging DataFrames\n",
        "merged_inner = pd.merge(df1, df2, on='EmployeeID', how='inner')\n",
        "print(merged_inner)\n",
        "\n",
        "merged_outer = pd.merge(df1, df2, on='EmployeeID', how='outer')\n",
        "print(merged_outer)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   EmployeeID     Name  Salary\n",
        "0           1    Alice   50000\n",
        "1           2      Bob   60000\n",
        "```\n",
        "```\n",
        "   EmployeeID     Name   Salary\n",
        "0           1    Alice   50000.0\n",
        "1           2      Bob   60000.0\n",
        "2           3  Charlie       NaN\n",
        "3           4      NaN   70000.0\n",
        "```\n",
        "\n",
        "### 2. Joining DataFrames\n",
        "• **Definition**: Joining is a method of combining DataFrames based on their indices.\n",
        "• **Method**:\n",
        "  - `join()`: Combines DataFrames using their indices.\n",
        "    - `how`: Type of join to be performed (inner, outer, left, right).\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrames with indices\n",
        "df3 = pd.DataFrame({\n",
        "    'Salary': [50000, 60000, 70000]},\n",
        "    index=[1, 2, 3]\n",
        ")\n",
        "\n",
        "df4 = pd.DataFrame({\n",
        "    'Department': ['HR', 'IT', 'Finance']},\n",
        "    index=[1, 2, 4]\n",
        ")\n",
        "\n",
        "# Joining DataFrames\n",
        "joined_inner = df3.join(df4, how='inner')\n",
        "print(joined_inner)\n",
        "\n",
        "joined_outer = df3.join(df4, how='outer')\n",
        "print(joined_outer)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   Salary Department\n",
        "1  50000.0        HR\n",
        "2  60000.0        IT\n",
        "```\n",
        "```\n",
        "   Salary Department\n",
        "1  50000.0        HR\n",
        "2  60000.0        IT\n",
        "3      NaN        NaN\n",
        "4      NaN   Finance\n",
        "```\n",
        "\n",
        "### 3. Concatenating DataFrames\n",
        "• **Definition**: Concatenation combines DataFrames along a particular axis (rows or columns).\n",
        "• **Method**:\n",
        "  - `concat()`: Combines DataFrames along a specified axis.\n",
        "    - `axis`: 0 for rows, 1 for columns.\n",
        "    - `ignore_index`: Boolean to reset the index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrames\n",
        "df5 = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob'],\n",
        "    'Age': [24, 30]\n",
        "})\n",
        "\n",
        "df6 = pd.DataFrame({\n",
        "    'Name': ['Charlie', 'David'],\n",
        "    'Age': [22, 35]\n",
        "})\n",
        "\n",
        "# Concatenating DataFrames vertically (along rows)\n",
        "concatenated_rows = pd.concat([df5, df6], axis=0, ignore_index=True)\n",
        "print(concatenated_rows)\n",
        "\n",
        "# Concatenating DataFrames horizontally (along columns)\n",
        "df7 = pd.DataFrame({\n",
        "    'Salary': [50000, 60000]\n",
        "})\n",
        "\n",
        "concatenated_columns = pd.concat([df5, df7], axis=1)\n",
        "print(concatenated_columns)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age\n",
        "0    Alice   24\n",
        "1      Bob   30\n",
        "2  Charlie   22\n",
        "3    David   35\n",
        "```\n",
        "```\n",
        "      Name  Age  Salary\n",
        "0    Alice   24   50000\n",
        "1      Bob   30   60000\n",
        "```\n",
        "\n",
        "### 4. Handling Duplicates in Concatenation\n",
        "• **Definition**: Managing duplicate entries when concatenating DataFrames.\n",
        "• **Method**:\n",
        "  - `drop_duplicates()`: Removes duplicate rows from the concatenated DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrames with duplicates\n",
        "df8 = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob'],\n",
        "    'Age': [24, 30]\n",
        "})\n",
        "\n",
        "df9 = pd.DataFrame({\n",
        "    'Name': ['Alice', 'David'],\n",
        "    'Age': [24, 35]\n",
        "})\n",
        "\n",
        "# Concatenating and removing duplicates\n",
        "concatenated_unique = pd.concat([df8, df9]).drop_duplicates().reset_index(drop=True)\n",
        "print(concatenated_unique)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age\n",
        "0    Alice   24\n",
        "1      Bob   30\n",
        "2    David   35\n",
        "```\n",
        "\n",
        "### 5. Concatenating with Different Columns\n",
        "• **Definition**: Concatenating DataFrames with different columns.\n",
        "• **Method**:\n",
        "  - `concat()` will fill missing values with NaN for non-matching columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrames with different columns\n",
        "df10 = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob'],\n",
        "    'Age': [24, 30]\n",
        "})\n",
        "\n",
        "df11 = pd.DataFrame({\n",
        "    'Name': ['Charlie', 'David'],\n",
        "    'Salary': [45000, 70000]\n",
        "})\n",
        "\n",
        "# Concatenating DataFrames with different columns\n",
        "concatenated_diff_columns = pd.concat([df10, df11], axis=0, ignore_index=True)\n",
        "print(concatenated_diff_columns)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name   Age   Salary\n",
        "0    Alice  24.0      NaN\n",
        "1      Bob  30.0      NaN\n",
        "2  Charlie   NaN  45000.0\n",
        "3    David   NaN  70000.0\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **GroupBy Operations**\n",
        "\n",
        "* GroupBy operations in Pandas are powerful tools for aggregating and summarizing data based on specific criteria. They allow you to split the data into groups, apply a function to each group, and combine the results back into a DataFrame.\n",
        "\n",
        "### 1. Introduction to GroupBy\n",
        "• **Definition**: The GroupBy operation involves splitting the data into groups based on some criteria, applying a function to each group, and then combining the results.\n",
        "• **Method**:\n",
        "  - `groupby()`: Used to group the DataFrame by one or more columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40, 50, 60]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Grouping by 'Category'\n",
        "grouped = df.groupby('Category')\n",
        "print(grouped)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x...>\n",
        "```\n",
        "\n",
        "### 2. Aggregating Data\n",
        "• **Definition**: Applying aggregation functions to each group to summarize the data.\n",
        "• **Common Aggregation Functions**:\n",
        "  - `sum()`: Sum of values.\n",
        "  - `mean()`: Average of values.\n",
        "  - `count()`: Count of non-null values.\n",
        "  - `min()`: Minimum value.\n",
        "  - `max()`: Maximum value.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Aggregating data using sum\n",
        "aggregated_sum = grouped.sum()\n",
        "print(aggregated_sum)\n",
        "\n",
        "# Aggregating data using mean\n",
        "aggregated_mean = grouped.mean()\n",
        "print(aggregated_mean)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          Values\n",
        "Category        \n",
        "A             90\n",
        "B            120\n",
        "```\n",
        "```\n",
        "          Values\n",
        "Category        \n",
        "A            30.0\n",
        "B            40.0\n",
        "```\n",
        "\n",
        "### 3. Applying Multiple Aggregation Functions\n",
        "• **Definition**: Applying multiple aggregation functions to the grouped data.\n",
        "• **Method**:\n",
        "  - `agg()`: Allows you to specify multiple aggregation functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Applying multiple aggregation functions\n",
        "aggregated_multiple = grouped.agg(['sum', 'mean', 'count'])\n",
        "print(aggregated_multiple)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          Values           \n",
        "            sum  mean count\n",
        "Category                  \n",
        "A             90  30.0    3\n",
        "B            120  40.0    3\n",
        "```\n",
        "\n",
        "### 4. Grouping by Multiple Columns\n",
        "• **Definition**: Grouping data based on multiple columns.\n",
        "• **Method**:\n",
        "  - Pass a list of column names to `groupby()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with multiple grouping columns\n",
        "data_multi = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Subcategory': ['X', 'Y', 'Y', 'X', 'X', 'Y'],\n",
        "    'Values': [10, 20, 30, 40, 50, 60]\n",
        "}\n",
        "df_multi = pd.DataFrame(data_multi)\n",
        "\n",
        "# Grouping by 'Category' and 'Subcategory'\n",
        "grouped_multi = df_multi.groupby(['Category', 'Subcategory']).sum()\n",
        "print(grouped_multi)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "                   Values\n",
        "Category Subcategory       \n",
        "A        X            60\n",
        "         Y            30\n",
        "B        X            40\n",
        "         Y            80\n",
        "```\n",
        "\n",
        "### 5. Filtering Groups\n",
        "• **Definition**: Filtering groups based on a condition.\n",
        "• **Method**:\n",
        "  - `filter()`: Returns a DataFrame with groups that meet a specified condition.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filtering groups where the sum of values is greater than 50\n",
        "filtered_groups = grouped.filter(lambda x: x['Values'].sum() > 50)\n",
        "print(filtered_groups)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "  Category  Values\n",
        "1        B      20\n",
        "3        B      40\n",
        "5        B      60\n",
        "```\n",
        "\n",
        "### 6. Transforming Data\n",
        "• **Definition**: Applying a function to each group and returning a DataFrame with the same shape as the original.\n",
        "• **Method**:\n",
        "  - `transform()`: Used to perform operations that return a DataFrame with the same index as the original.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Transforming data to get the mean of each group\n",
        "transformed = grouped.transform('mean')\n",
        "print(transformed)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   Values\n",
        "0    30.0\n",
        "1    40.0\n",
        "2    30.0\n",
        "3    40.0\n",
        "4    30.0\n",
        "5    40.0\n",
        "```\n",
        "\n",
        "### 7. Custom Aggregation Functions\n",
        "• **Definition**: Using custom functions for aggregation.\n",
        "• **Method**:\n",
        "  - Pass a custom function to `agg()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Custom aggregation function to calculate range\n",
        "def range_func(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "# Applying custom aggregation function\n",
        "custom_agg = grouped.agg(range=range_func)\n",
        "print(custom_agg)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          Values\n",
        "Category        \n",
        "A             40\n",
        "B             40\n",
        "```\n",
        "\n",
        "### 8. GroupBy with Time Series Data\n",
        "• **Definition**: Grouping time series data by time intervals.\n",
        "• **Method**:\n",
        "  - Use `Grouper` to specify the frequency.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample time series DataFrame\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "df_time = pd.DataFrame(date_rng, columns=['date'])\n",
        "df_time['data'] = pd.Series(range(1, len(df_time) + 1))\n",
        "\n",
        "# Grouping by day\n",
        "df_time.set_index('date', inplace=True)\n",
        "grouped_time = df_time.groupby(pd.Grouper(freq='2D')).sum()\n",
        "print(grouped_time)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01    3\n",
        "2023-01-03    7\n",
        "2023-01-05   11\n",
        "2023-01-07   15\n",
        "2023-01-09   19\n",
        "```\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Aggregation and Descriptive Statistics**\n",
        "\n",
        "Aggregation and descriptive statistics in Pandas are essential for summarizing and understanding datasets. They provide insights into the data's central tendency, dispersion, and overall distribution. Below are the key topics related to aggregation and descriptive statistics in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Introduction to Aggregation\n",
        "• **Definition**: Aggregation involves computing a summary statistic for a group of data points. It allows you to condense large datasets into meaningful metrics.\n",
        "• **Common Aggregation Functions**:\n",
        "  - `sum()`: Total sum of values.\n",
        "  - `mean()`: Average of values.\n",
        "  - `count()`: Number of non-null values.\n",
        "  - `min()`: Minimum value.\n",
        "  - `max()`: Maximum value.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40, 50, 60]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Aggregating data using sum\n",
        "aggregated_sum = df.groupby('Category')['Values'].sum()\n",
        "print(aggregated_sum)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category\n",
        "A     90\n",
        "B    120\n",
        "Name: Values, dtype: int64\n",
        "```\n",
        "\n",
        "### 2. Descriptive Statistics\n",
        "• **Definition**: Descriptive statistics provide a summary of the main characteristics of a dataset, including measures of central tendency and variability.\n",
        "• **Method**:\n",
        "  - `describe()`: Generates descriptive statistics for numerical columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Generating descriptive statistics\n",
        "descriptive_stats = df['Values'].describe()\n",
        "print(descriptive_stats)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "count     6.000000\n",
        "mean     35.000000\n",
        "std      18.520259\n",
        "min      10.000000\n",
        "25%      25.000000\n",
        "50%      35.000000\n",
        "75%      45.000000\n",
        "max      60.000000\n",
        "Name: Values, dtype: float64\n",
        "```\n",
        "\n",
        "### 3. Applying Multiple Aggregation Functions\n",
        "• **Definition**: You can apply multiple aggregation functions to summarize data in various ways.\n",
        "• **Method**:\n",
        "  - `agg()`: Allows you to specify multiple aggregation functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Applying multiple aggregation functions\n",
        "aggregated_multiple = df.groupby('Category')['Values'].agg(['sum', 'mean', 'count'])\n",
        "print(aggregated_multiple)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          sum  mean  count\n",
        "Category                  \n",
        "A          90  30.0      3\n",
        "B         120  40.0      3\n",
        "```\n",
        "\n",
        "### 4. Custom Aggregation Functions\n",
        "• **Definition**: You can define and apply custom functions for aggregation.\n",
        "• **Method**:\n",
        "  - Pass a custom function to `agg()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Custom aggregation function to calculate range\n",
        "def range_func(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "# Applying custom aggregation function\n",
        "custom_agg = df.groupby('Category')['Values'].agg(range=range_func)\n",
        "print(custom_agg)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          range\n",
        "Category       \n",
        "A             40\n",
        "B             40\n",
        "```\n",
        "\n",
        "### 5. Descriptive Statistics for Categorical Data\n",
        "• **Definition**: Descriptive statistics can also be applied to categorical data to summarize counts and unique values.\n",
        "• **Method**:\n",
        "  - `value_counts()`: Returns the counts of unique values in a Series.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with categorical data\n",
        "data_cat = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Subcategory': ['X', 'Y', 'Y', 'X', 'X', 'Y']\n",
        "}\n",
        "df_cat = pd.DataFrame(data_cat)\n",
        "\n",
        "# Descriptive statistics for categorical data\n",
        "category_counts = df_cat['Category'].value_counts()\n",
        "print(category_counts)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "A    3\n",
        "B    3\n",
        "Name: Category, dtype: int64\n",
        "```\n",
        "\n",
        "### 6. Correlation and Covariance\n",
        "• **Definition**: Correlation measures the relationship between two variables, while covariance indicates the direction of the relationship.\n",
        "• **Methods**:\n",
        "  - `corr()`: Computes pairwise correlation of columns.\n",
        "  - `cov()`: Computes pairwise covariance of columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame for correlation and covariance\n",
        "data_corr = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6]\n",
        "}\n",
        "df_corr = pd.DataFrame(data_corr)\n",
        "\n",
        "# Calculating correlation\n",
        "correlation = df_corr.corr()\n",
        "print(correlation)\n",
        "\n",
        "# Calculating covariance\n",
        "covariance = df_corr.cov()\n",
        "print(covariance)\n",
        "```\n",
        "**Output (Correlation)**:\n",
        "```\n",
        "          A    B    C\n",
        "A  1.000000 -1.0  1.0\n",
        "B -1.000000  1.0 -1.0\n",
        "C  1.000000 -1.0  1.0\n",
        "```\n",
        "**Output (Covariance)**:\n",
        "```\n",
        "          A    B    C\n",
        "A  2.500000 -2.500000  2.500000\n",
        "B -2.500000  2.500000 -2.500000\n",
        "C  2.500000 -2.500000  2.500000\n",
        "```\n",
        "\n",
        "### 7. Grouping and Aggregating with Descriptive Statistics\n",
        "• **Definition**: You can combine grouping and descriptive statistics to summarize data based on categories.\n",
        "• **Method**:\n",
        "  - Use `groupby()` followed by `describe()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Grouping and generating descriptive statistics\n",
        "grouped_descriptive = df.groupby('Category')['Values'].describe()\n",
        "print(grouped_descriptive)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "          count  mean       std   min   25%   50%   75%   max\n",
        "Category                                                      \n",
        "A          3.0  30.0  20.000000  10.0  25.0  30.0  45.0  50.0\n",
        "B          3.0  40.0  20.000000  20.0  30.0  40.0  50.0  60.0\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Pivot Tables and Cross Validation**\n",
        "\n",
        "* Pivot tables and cross-validation are important concepts in data analysis and machine learning. In Pandas, pivot tables allow you to summarize and reorganize data, while cross-validation is a technique used to assess the performance of machine learning models.\n",
        "\n",
        "### 1. Pivot Tables in Pandas\n",
        "• **Definition**: A pivot table is a data processing tool that allows you to summarize and reorganize data in a DataFrame. It enables you to aggregate data based on one or more keys and display the results in a tabular format.\n",
        "• **Method**:\n",
        "  - `pivot_table()`: Creates a pivot table from a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Sales': [100, 200, 150, 250]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table\n",
        "pivot_table = df.pivot_table(values='Sales', index='Date', columns='Category', aggfunc='sum', fill_value=0)\n",
        "print(pivot_table)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category         A    B\n",
        "Date                   \n",
        "2023-01-01    100  200\n",
        "2023-01-02    150  250\n",
        "```\n",
        "\n",
        "### 2. Pivot Table with Multiple Aggregation Functions\n",
        "• **Definition**: You can apply multiple aggregation functions to summarize data in a pivot table.\n",
        "• **Method**:\n",
        "  - Use the `aggfunc` parameter to specify a list of functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a pivot table with multiple aggregation functions\n",
        "pivot_table_multi = df.pivot_table(values='Sales', index='Date', columns='Category', aggfunc=[sum, 'mean'], fill_value=0)\n",
        "print(pivot_table_multi)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "           sum         mean       \n",
        "Category     A    B     A    B\n",
        "Date                             \n",
        "2023-01-01  100  200  100.0  200.0\n",
        "2023-01-02  150  250  150.0  250.0\n",
        "```\n",
        "\n",
        "### 3. Cross-Validation in Pandas\n",
        "• **Definition**: Cross-validation is a technique used to evaluate the performance of a machine learning model by partitioning the data into subsets. The model is trained on some subsets and tested on others to ensure it generalizes well to unseen data.\n",
        "• **Method**:\n",
        "  - Use `KFold` or `StratifiedKFold` from `sklearn.model_selection` to create cross-validation splits.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'Feature2': [10, 20, 30, 40, 50, 60],\n",
        "    'Target': [0, 1, 0, 1, 0, 1]\n",
        "}\n",
        "df_cv = pd.DataFrame(data)\n",
        "\n",
        "# Defining features and target\n",
        "X = df_cv[['Feature1', 'Feature2']]\n",
        "y = df_cv['Target']\n",
        "\n",
        "# Setting up KFold cross-validation\n",
        "kf = KFold(n_splits=3)\n",
        "\n",
        "# Performing cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "TRAIN: [2 3 4 5] TEST: [0 1]\n",
        "TRAIN: [0 1 4 5] TEST: [2 3]\n",
        "TRAIN: [0 1 2 3] TEST: [4 5]\n",
        "```\n",
        "\n",
        "### 4. Stratified Cross-Validation\n",
        "• **Definition**: Stratified cross-validation ensures that each fold has the same proportion of classes as the entire dataset, which is particularly useful for imbalanced datasets.\n",
        "• **Method**:\n",
        "  - Use `StratifiedKFold` from `sklearn.model_selection`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Setting up StratifiedKFold cross-validation\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "\n",
        "# Performing stratified cross-validation\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "TRAIN: [0 1 2 3] TEST: [4 5]\n",
        "TRAIN: [0 1 2 4 5] TEST: [3]\n",
        "TRAIN: [0 1 3 4 5] TEST: [2]\n",
        "```\n",
        "\n",
        "### 5. Evaluating Model Performance\n",
        "• **Definition**: After performing cross-validation, you can evaluate the model's performance using metrics such as accuracy, precision, recall, and F1-score.\n",
        "• **Method**:\n",
        "  - Use metrics from `sklearn.metrics`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Cross-validation evaluation\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    \n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Accuracy: 1.0\n",
        "Accuracy: 1.0\n",
        "Accuracy: 1.0\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Reshaping Data (Melt , Stack, Unstack)**\n",
        "\n",
        "* Reshaping data in Pandas is essential for transforming data into a format that is more suitable for analysis or visualization. The `melt`, `stack`, and `unstack` functions are powerful tools for reshaping DataFrames.\n",
        "\n",
        "### 1. Melt\n",
        "• **Definition**: The `melt` function is used to transform a DataFrame from a wide format to a long format. It unpivots the DataFrame, turning columns into rows.\n",
        "• **Method**:\n",
        "  - `melt()`: Takes a DataFrame and returns a new DataFrame in long format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Date': ['2023-01-01', '2023-01-02'],\n",
        "    'Sales_A': [100, 150],\n",
        "    'Sales_B': [200, 250]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Melting the DataFrame\n",
        "melted_df = pd.melt(df, id_vars=['Date'], value_vars=['Sales_A', 'Sales_B'],\n",
        "                    var_name='Category', value_name='Sales')\n",
        "print(melted_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "         Date   Category  Sales\n",
        "0  2023-01-01  Sales_A    100\n",
        "1  2023-01-02  Sales_A    150\n",
        "2  2023-01-01  Sales_B    200\n",
        "3  2023-01-02  Sales_B    250\n",
        "```\n",
        "\n",
        "### 2. Stack\n",
        "• **Definition**: The `stack` function is used to pivot the columns of a DataFrame into the index, effectively converting a DataFrame from wide to long format. It stacks the columns into a single column.\n",
        "• **Method**:\n",
        "  - `stack()`: Stacks the columns of a DataFrame into a Series.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame\n",
        "data_stack = {\n",
        "    'Date': ['2023-01-01', '2023-01-02'],\n",
        "    'Sales_A': [100, 150],\n",
        "    'Sales_B': [200, 250]\n",
        "}\n",
        "df_stack = pd.DataFrame(data_stack).set_index('Date')\n",
        "\n",
        "# Stacking the DataFrame\n",
        "stacked_df = df_stack.stack()\n",
        "print(stacked_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Date          \n",
        "2023-01-01  Sales_A    100\n",
        "            Sales_B    200\n",
        "2023-01-02  Sales_A    150\n",
        "            Sales_B    250\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 3. Unstack\n",
        "• **Definition**: The `unstack` function is the inverse of `stack`. It pivots the innermost level of the index (or a specified level) into columns, converting a long format DataFrame back to a wide format.\n",
        "• **Method**:\n",
        "  - `unstack()`: Converts the innermost index level to columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Unstacking the stacked DataFrame\n",
        "unstacked_df = stacked_df.unstack()\n",
        "print(unstacked_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category      Sales_A  Sales_B\n",
        "Date                          \n",
        "2023-01-01      100      200\n",
        "2023-01-02      150      250\n",
        "```\n",
        "\n",
        "### 4. Reshaping with MultiIndex\n",
        "• **Definition**: You can create a MultiIndex DataFrame and use `stack` and `unstack` to reshape data with multiple levels of indexing.\n",
        "• **Example**:\n",
        "```python\n",
        "# Sample DataFrame with MultiIndex\n",
        "data_multi = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Sales': [100, 200, 150, 250]\n",
        "}\n",
        "df_multi = pd.DataFrame(data_multi)\n",
        "\n",
        "# Setting MultiIndex\n",
        "df_multi.set_index(['Date', 'Category'], inplace=True)\n",
        "\n",
        "# Stacking and unstacking with MultiIndex\n",
        "stacked_multi = df_multi.stack()\n",
        "print(stacked_multi)\n",
        "\n",
        "unstacked_multi = stacked_multi.unstack()\n",
        "print(unstacked_multi)\n",
        "```\n",
        "**Output (Stacked)**:\n",
        "```\n",
        "Date        Category\n",
        "2023-01-01 A          100\n",
        "            B          200\n",
        "2023-01-02 A          150\n",
        "            B          250\n",
        "dtype: int64\n",
        "```\n",
        "**Output (Unstacked)**:\n",
        "```\n",
        "Category      A    B\n",
        "Date                \n",
        "2023-01-01  100  200\n",
        "2023-01-02  150  250\n",
        "```\n",
        "\n",
        "### 5. Using `pivot` for Reshaping\n",
        "• **Definition**: The `pivot` function is another way to reshape data, similar to `pivot_table`, but it does not allow for aggregation.\n",
        "• **Method**:\n",
        "  - `pivot()`: Reshapes data based on unique values from specified columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame\n",
        "data_pivot = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Sales': [100, 200, 150, 250]\n",
        "}\n",
        "df_pivot = pd.DataFrame(data_pivot)\n",
        "\n",
        "# Pivoting the DataFrame\n",
        "pivoted_df = df_pivot.pivot(index='Date', columns='Category', values='Sales')\n",
        "print(pivoted_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category        A    B\n",
        "Date                  \n",
        "2023-01-01  100.0  200.0\n",
        "2023-01-02  150.0  250.0\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Time Series Data**\n",
        "\n",
        "* Time series data is a sequence of data points indexed in time order, often used for analyzing trends, seasonal patterns, and forecasting.\n",
        "* Pandas provides powerful tools for working with time series data, making it easy to manipulate, analyze, and visualize temporal data.\n",
        "\n",
        "### 1. Creating Time Series Data\n",
        "• **Definition**: You can create a time series DataFrame by using a date range or by converting a column to datetime format.\n",
        "• **Method**:\n",
        "  - `pd.date_range()`: Generates a range of dates.\n",
        "  - `pd.to_datetime()`: Converts a column to datetime format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a date range\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "\n",
        "# Creating a DataFrame with time series data\n",
        "df = pd.DataFrame(date_rng, columns=['date'])\n",
        "df['data'] = range(1, len(df) + 1)\n",
        "df.set_index('date', inplace=True)\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01     1\n",
        "2023-01-02     2\n",
        "2023-01-03     3\n",
        "2023-01-04     4\n",
        "2023-01-05     5\n",
        "2023-01-06     6\n",
        "2023-01-07     7\n",
        "2023-01-08     8\n",
        "2023-01-09     9\n",
        "2023-01-10    10\n",
        "```\n",
        "\n",
        "### 2. Indexing and Selecting Time Series Data\n",
        "• **Definition**: You can index and select data based on date ranges or specific timestamps.\n",
        "• **Method**:\n",
        "  - Use the DataFrame index to filter data.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Selecting data for a specific date\n",
        "selected_data = df.loc['2023-01-05']\n",
        "print(selected_data)\n",
        "\n",
        "# Selecting data for a date range\n",
        "range_data = df['2023-01-03':'2023-01-07']\n",
        "print(range_data)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "data    5\n",
        "Name: 2023-01-05 00:00:00, dtype: int64\n",
        "```\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-03     3\n",
        "2023-01-04     4\n",
        "2023-01-05     5\n",
        "2023-01-06     6\n",
        "2023-01-07     7\n",
        "```\n",
        "\n",
        "### 3. Resampling Time Series Data\n",
        "• **Definition**: Resampling is the process of changing the frequency of your time series data, either by upsampling (increasing frequency) or downsampling (decreasing frequency).\n",
        "• **Method**:\n",
        "  - `resample()`: Used to change the frequency of the time series data.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Resampling to a different frequency (e.g., weekly)\n",
        "weekly_data = df.resample('W').sum()\n",
        "print(weekly_data)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01     1\n",
        "2023-01-08    28\n",
        "2023-01-15    10\n",
        "```\n",
        "\n",
        "### 4. Time Series Operations\n",
        "• **Definition**: You can perform various operations on time series data, such as shifting, rolling windows, and calculating differences.\n",
        "• **Methods**:\n",
        "  - `shift()`: Shifts the data by a specified number of periods.\n",
        "  - `rolling()`: Provides rolling window calculations.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Shifting data\n",
        "shifted_data = df.shift(1)\n",
        "print(shifted_data)\n",
        "\n",
        "# Rolling window calculation (e.g., 3-day moving average)\n",
        "rolling_avg = df.rolling(window=3).mean()\n",
        "print(rolling_avg)\n",
        "```\n",
        "**Output (Shifted)**:\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01   NaN\n",
        "2023-01-02   1.0\n",
        "2023-01-03   2.0\n",
        "2023-01-04   3.0\n",
        "2023-01-05   4.0\n",
        "2023-01-06   5.0\n",
        "2023-01-07   6.0\n",
        "2023-01-08   7.0\n",
        "2023-01-09   8.0\n",
        "2023-01-10   9.0\n",
        "```\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01   NaN\n",
        "2023-01-02   NaN\n",
        "2023-01-03   2.0\n",
        "2023-01-04   3.0\n",
        "2023-01-05   4.0\n",
        "2023-01-06   5.0\n",
        "2023-01-07   6.0\n",
        "2023-01-08   7.0\n",
        "2023-01-09   8.0\n",
        "2023-01-10   9.0\n",
        "```\n",
        "\n",
        "### 5. Time Series Visualization\n",
        "• **Definition**: Visualizing time series data helps in understanding trends and patterns over time.\n",
        "• **Method**:\n",
        "  - Use Matplotlib or Pandas built-in plotting functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the time series data\n",
        "df.plot(figsize=(10, 5))\n",
        "plt.title('Time Series Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Data')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "### 6. Handling Missing Data in Time Series\n",
        "• **Definition**: Time series data often contains missing values, which can be handled using various methods.\n",
        "• **Methods**:\n",
        "  - `fillna()`: Fill missing values.\n",
        "  - `interpolate()`: Interpolate missing values.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Introducing missing values\n",
        "df_missing = df.copy()\n",
        "df_missing.loc['2023-01-03'] = None\n",
        "\n",
        "# Filling missing values\n",
        "filled_data = df_missing.fillna(method='ffill')\n",
        "print(filled_data)\n",
        "\n",
        "# Interpolating missing values\n",
        "interpolated_data = df_missing.interpolate()\n",
        "print(interpolated_data)\n",
        "```\n",
        "**Output (Filled)**:\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01   1.0\n",
        "2023-01-02   2.0\n",
        "2023-01-03   2.0\n",
        "2023-01-04   4.0\n",
        "2023-01-05   5.0\n",
        "2023-01-06   6.0\n",
        "2023-01-07   7.0\n",
        "2023-01-08   8.0\n",
        "2023-01-09   9.0\n",
        "2023-01-10  10.0\n",
        "```\n",
        "```\n",
        "            data\n",
        "date             \n",
        "2023-01-01   1.0\n",
        "2023-01-02   2.0\n",
        "2023-01-03   2.5\n",
        "2023-01-04   4.0\n",
        "2023-01-05   5.0\n",
        "2023-01-06   6.0\n",
        "2023-01-07   7.0\n",
        "2023-01-08   8.0\n",
        "2023-01-09   9.0\n",
        "2023-01-10  10.0\n",
        "```\n",
        "\n",
        "### 7. Time Zone Handling\n",
        "• **Definition**: Time series data can include time zone information, which is important for accurate analysis.\n",
        "• **Method**:\n",
        "  - `tz_localize()`: Localizes naive datetime to a specific time zone.\n",
        "  - `tz_convert()`: Converts time zone-aware datetime to another time zone.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Localizing to a specific time zone\n",
        "df_tz = df.tz_localize('UTC')\n",
        "print(df_tz)\n",
        "\n",
        "# Converting to another time zone\n",
        "df_tz_converted = df_tz.tz_convert('America/New_York')\n",
        "print(df_tz_converted)\n",
        "```\n",
        "**Output (Localized)**:\n",
        "```\n",
        "                     data\n",
        "date                     \n",
        "2023-01-01 00:00:00+00:00   1\n",
        "2023-01-02 00:00:00+00:00   2\n",
        "2023-01-03 00:00:00+00:00   3\n",
        "2023-01-04 00:00:00+00:00   4\n",
        "2023-01-05 00:00:00+00:00   5\n",
        "2023-01-06 00:00:00+00:00   6\n",
        "2023-01-07 00:00:00+00:00   7\n",
        "2023-01-08 00:00:00+00:00   8\n",
        "2023-01-09 00:00:00+00:00   9\n",
        "2023-01-10 00:00:00+00:00  10\n",
        "```\n",
        "```\n",
        "                     data\n",
        "date                     \n",
        "2022-12-31 19:00:00-05:00   1\n",
        "2023-01-01 19:00:00-05:00   2\n",
        "2023-01-02 19:00:00-05:00   3\n",
        "2023-01-03 19:00:00-05:00   4\n",
        "2023-01-04 19:00:00-05:00   5\n",
        "2023-01-05 19:00:00-05:00   6\n",
        "2023-01-06 19:00:00-05:00   7\n",
        "2023-01-07 19:00:00-05:00   8\n",
        "2023-01-08 19:00:00-05:00   9\n",
        "2023-01-09 19:00:00-05:00  10\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "## **Working with Dates and Times**\n",
        "\n",
        "* Working with dates and times in Pandas is essential for time series analysis and data manipulation.\n",
        "* Pandas provides a variety of functions and methods to handle date and time data effectively.\n",
        "\n",
        "### 1. Creating Date and Time Objects\n",
        "• **Definition**: You can create date and time objects using `pd.to_datetime()` or by generating a date range with `pd.date_range()`.\n",
        "• **Method**:\n",
        "  - `pd.to_datetime()`: Converts a string or a list of strings to datetime objects.\n",
        "  - `pd.date_range()`: Generates a range of dates.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a single datetime object\n",
        "date_single = pd.to_datetime('2023-01-01')\n",
        "print(date_single)\n",
        "\n",
        "# Creating a range of dates\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "print(date_rng)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "2023-01-01 00:00:00\n",
        "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
        "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
        "               '2023-01-09', '2023-01-10'],\n",
        "              dtype='datetime64[ns]', freq='D')\n",
        "```\n",
        "\n",
        "### 2. Converting Strings to Datetime\n",
        "• **Definition**: You can convert strings in various formats to datetime objects using `pd.to_datetime()`.\n",
        "• **Method**:\n",
        "  - `pd.to_datetime()`: Automatically infers the format or you can specify the format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Converting a string to datetime\n",
        "date_str = '2023-01-01 12:30:45'\n",
        "date_converted = pd.to_datetime(date_str)\n",
        "print(date_converted)\n",
        "\n",
        "# Converting a list of strings to datetime\n",
        "date_list = ['2023-01-01', '2023-01-02', '2023-01-03']\n",
        "date_converted_list = pd.to_datetime(date_list)\n",
        "print(date_converted_list)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "2023-01-01 12:30:45\n",
        "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03'], dtype='datetime64[ns]', freq=None)\n",
        "```\n",
        "\n",
        "### 3. Extracting Date and Time Components\n",
        "• **Definition**: You can extract specific components (year, month, day, hour, minute, second) from datetime objects.\n",
        "• **Method**:\n",
        "  - Use the `.dt` accessor to access date and time properties.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with datetime index\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-05', freq='D')\n",
        "df = pd.DataFrame(date_rng, columns=['date'])\n",
        "df['data'] = range(1, len(df) + 1)\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "# Extracting components\n",
        "df['year'] = df.index.year\n",
        "df['month'] = df.index.month\n",
        "df['day'] = df.index.day\n",
        "df['hour'] = df.index.hour\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            data  year  month  day  hour\n",
        "date                                     \n",
        "2023-01-01     1  2023      1    1     0\n",
        "2023-01-02     2  2023      1    2     0\n",
        "2023-01-03     3  2023      1    3     0\n",
        "2023-01-04     4  2023      1    4     0\n",
        "2023-01-05     5  2023      1    5     0\n",
        "```\n",
        "\n",
        "### 4. Date Arithmetic\n",
        "• **Definition**: You can perform arithmetic operations on datetime objects, such as adding or subtracting time intervals.\n",
        "• **Method**:\n",
        "  - Use `pd.Timedelta` to represent time durations.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Adding days to a datetime\n",
        "df['date_plus_3_days'] = df.index + pd.Timedelta(days=3)\n",
        "print(df)\n",
        "\n",
        "# Subtracting days from a datetime\n",
        "df['date_minus_2_days'] = df.index - pd.Timedelta(days=2)\n",
        "print(df)\n",
        "```\n",
        "**Output (Adding Days)**:\n",
        "```\n",
        "            data  year  month  day  hour date_plus_3_days\n",
        "date                                                    \n",
        "2023-01-01     1  2023      1    1     0       2023-01-04\n",
        "2023-01-02     2  2023      1    2     0       2023-01-05\n",
        "2023-01-03     3  2023      1    3     0       2023-01-06\n",
        "2023-01-04     4  2023      1    4     0       2023-01-07\n",
        "2023-01-05     5  2023      1    5     0       2023-01-08\n",
        "```\n",
        "**Output (Subtracting Days)**:\n",
        "```\n",
        "            data  year  month  day  hour date_plus_3_days date_minus_2_days\n",
        "date                                                                             \n",
        "2023-01-01     1  2023      1    1     0       2023-01-04       2022-12-30\n",
        "2023-01-02     2  2023      1    2     0       2023-01-05       2022-12-31\n",
        "2023-01-03     3  2023      1    3     0       2023-01-06       2023-01-01\n",
        "2023-01-04     4  2023      1    4     0       2023-01-07       2023-01-02\n",
        "2023-01-05     5  2023      1    5     0       2023-01-08       2023-01-03\n",
        "```\n",
        "\n",
        "### 5. Time Zone Handling\n",
        "• **Definition**: You can localize naive datetime objects to a specific time zone and convert between time zones.\n",
        "• **Method**:\n",
        "  - `tz_localize()`: Localizes naive datetime to a specific time zone.\n",
        "  - `tz_convert()`: Converts time zone-aware datetime to another time zone.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Localizing to a specific time zone\n",
        "df_tz = df.tz_localize('UTC')\n",
        "print(df_tz)\n",
        "\n",
        "# Converting to another time zone\n",
        "df_tz_converted = df_tz.tz_convert('America/New_York')\n",
        "print(df_tz_converted)\n",
        "```\n",
        "**Output (Localized)**:\n",
        "```\n",
        "                     data  year  month  day  hour date_plus_3_days date_minus_2_days\n",
        "date                                                                             \n",
        "2023-01-01 00:00:00+00:00     1  2023      1    1     0       2023-01-04       2022-12-30\n",
        "2023-01-02 00:00:00+00:00     2  2023      1    2     0       2023-01-05       2022-12-31\n",
        "2023-01-03 00:00:00+00:00     3  2023      1    3     0       2023-01-06       2023-01-01\n",
        "2023-01-04 00:00:00+00:00     4  2023      1    4     0       2023-01-07       2023-01-02\n",
        "2023-01-05 00:00:00+00:00     5  2023      1    5     0       2023-01-08       2023-01-03\n",
        "```\n",
        "```\n",
        "                     data  year  month  day  hour date_plus_3_days date_minus_2_days\n",
        "date                                                                             \n",
        "2022-12-31 19:00:00-05:00     1  2023      1    1     0       2023-01-04       2022-12-30\n",
        "2023-01-01 19:00:00-05:00     2  2023      1    2     0       2023-01-05       2022-12-31\n",
        "2023-01-02 19:00:00-05:00     3  2023      1    3     0       2023-01-06       2023-01-01\n",
        "2023-01-03 19:00:00-05:00     4  2023      1    4     0       2023-01-07       2023-01-02\n",
        "2023-01-04 19:00:00-05:00     5  2023      1    5     0       2023-01-08       2023-01-03\n",
        "```\n",
        "\n",
        "### 6. Working with Timedelta\n",
        "• **Definition**: Timedelta represents the difference between two dates or times.\n",
        "• **Method**:\n",
        "  - `pd.Timedelta()`: Represents a duration of time.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a Timedelta\n",
        "delta = pd.Timedelta(days=5, hours=3)\n",
        "print(delta)\n",
        "\n",
        "# Adding Timedelta to a datetime\n",
        "new_date = date_single + delta\n",
        "print(new_date)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "5 days 03:00:00\n",
        "2023-01-06 03:00:00\n",
        "```\n",
        "\n",
        "### 7. Date Range Generation\n",
        "• **Definition**: You can generate a range of dates with specific frequencies.\n",
        "• **Method**:\n",
        "  - `pd.date_range()`: Generates a range of dates with specified frequency.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Generating a date range with different frequencies\n",
        "daily_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "weekly_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='W')\n",
        "print(daily_rng)\n",
        "print(weekly_rng)\n",
        "```\n",
        "**Output (Daily)**:\n",
        "```\n",
        "DatetimeIndex(['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04',\n",
        "               '2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08',\n",
        "               '2023-01-09', '2023-01-10'],\n",
        "              dtype='datetime64[ns]', freq='D')\n",
        "```\n",
        "**Output (Weekly)**:\n",
        "```\n",
        "DatetimeIndex(['2023-01-01', '2023-01-08'], dtype='datetime64[ns]', freq='W-SUN')\n",
        "```\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Window Functions (Rolling , Expanding)**\n",
        "\n",
        "* Window functions in Pandas, such as rolling and expanding, are powerful tools for performing calculations over a specified window of data.\n",
        "* These functions allow you to analyze trends, calculate moving averages, and perform cumulative calculations.\n",
        "\n",
        "\n",
        "### 1. Rolling Window Functions\n",
        "• **Definition**: Rolling window functions allow you to perform calculations over a fixed-size window of data that moves along the time series or DataFrame. Common operations include calculating the mean, sum, or standard deviation over the window.\n",
        "• **Method**:\n",
        "  - `rolling()`: Creates a rolling window object.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Date': pd.date_range(start='2023-01-01', periods=10, freq='D'),\n",
        "    'Values': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df.set_index('Date', inplace=True)\n",
        "\n",
        "# Calculating a rolling mean with a window size of 3\n",
        "rolling_mean = df['Values'].rolling(window=3).mean()\n",
        "print(rolling_mean)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Date\n",
        "2023-01-01     NaN\n",
        "2023-01-02     NaN\n",
        "2023-01-03    20.0\n",
        "2023-01-04    30.0\n",
        "2023-01-05    40.0\n",
        "2023-01-06    50.0\n",
        "2023-01-07    60.0\n",
        "2023-01-08    70.0\n",
        "2023-01-09    80.0\n",
        "2023-01-10    90.0\n",
        "Name: Values, dtype: float64\n",
        "```\n",
        "\n",
        "### 2. Rolling Window with Different Functions\n",
        "• **Definition**: You can apply various aggregation functions to the rolling window, such as sum, min, max, and standard deviation.\n",
        "• **Method**:\n",
        "  - Use the `agg()` method to apply multiple functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Calculating rolling sum and standard deviation\n",
        "rolling_sum = df['Values'].rolling(window=3).sum()\n",
        "rolling_std = df['Values'].rolling(window=3).std()\n",
        "\n",
        "# Combining results into a DataFrame\n",
        "rolling_results = pd.DataFrame({\n",
        "    'Rolling Mean': rolling_mean,\n",
        "    'Rolling Sum': rolling_sum,\n",
        "    'Rolling Std': rolling_std\n",
        "})\n",
        "print(rolling_results)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            Rolling Mean  Rolling Sum  Rolling Std\n",
        "Date                                                  \n",
        "2023-01-01            NaN          NaN           NaN\n",
        "2023-01-02            NaN          NaN           NaN\n",
        "2023-01-03           20.0         60.0           NaN\n",
        "2023-01-04           30.0         90.0      10.000000\n",
        "2023-01-05           40.0        120.0      10.000000\n",
        "2023-01-06           50.0        150.0      10.000000\n",
        "2023-01-07           60.0        180.0      10.000000\n",
        "2023-01-08           70.0        210.0      10.000000\n",
        "2023-01-09           80.0        240.0      10.000000\n",
        "2023-01-10           90.0        270.0      10.000000\n",
        "```\n",
        "\n",
        "### 3. Expanding Window Functions\n",
        "• **Definition**: Expanding window functions allow you to perform calculations over all data points up to the current point. This is useful for cumulative calculations.\n",
        "• **Method**:\n",
        "  - `expanding()`: Creates an expanding window object.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Calculating expanding mean\n",
        "expanding_mean = df['Values'].expanding().mean()\n",
        "print(expanding_mean)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Date\n",
        "2023-01-01     10.0\n",
        "2023-01-02     15.0\n",
        "2023-01-03     20.0\n",
        "2023-01-04     25.0\n",
        "2023-01-05     30.0\n",
        "2023-01-06     35.0\n",
        "2023-01-07     40.0\n",
        "2023-01-08     45.0\n",
        "2023-01-09     50.0\n",
        "2023-01-10     55.0\n",
        "Name: Values, dtype: float64\n",
        "```\n",
        "\n",
        "### 4. Expanding Window with Different Functions\n",
        "• **Definition**: Similar to rolling windows, you can apply various aggregation functions to the expanding window.\n",
        "• **Method**:\n",
        "  - Use the `agg()` method to apply multiple functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Calculating expanding sum and standard deviation\n",
        "expanding_sum = df['Values'].expanding().sum()\n",
        "expanding_std = df['Values'].expanding().std()\n",
        "\n",
        "# Combining results into a DataFrame\n",
        "expanding_results = pd.DataFrame({\n",
        "    'Expanding Mean': expanding_mean,\n",
        "    'Expanding Sum': expanding_sum,\n",
        "    'Expanding Std': expanding_std\n",
        "})\n",
        "print(expanding_results)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "            Expanding Mean  Expanding Sum  Expanding Std\n",
        "Date                                                      \n",
        "2023-01-01            10.0           10.0             NaN\n",
        "2023-01-02            15.0           30.0             NaN\n",
        "2023-01-03            20.0           60.0             NaN\n",
        "2023-01-04            25.0          100.0        15.811388\n",
        "2023-01-05            30.0          150.0        18.708286\n",
        "2023-01-06            35.0          210.0        21.633308\n",
        "2023-01-07            40.0          280.0        24.000000\n",
        "2023-01-08            45.0          360.0        26.832815\n",
        "2023-01-09            50.0          450.0        29.700000\n",
        "2023-01-10            55.0          550.0        32.000000\n",
        "```\n",
        "\n",
        "### 5. Customizing Window Functions\n",
        "• **Definition**: You can customize the behavior of rolling and expanding windows by specifying parameters such as minimum periods and center alignment.\n",
        "• **Method**:\n",
        "  - Use parameters like `min_periods` and `center`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Rolling mean with minimum periods\n",
        "rolling_mean_min_periods = df['Values'].rolling(window=3, min_periods=1).mean()\n",
        "print(rolling_mean_min_periods)\n",
        "\n",
        "# Rolling mean with center alignment\n",
        "rolling_mean_centered = df['Values'].rolling(window=3, center=True).mean()\n",
        "print(rolling_mean_centered)\n",
        "```\n",
        "**Output (Min Periods)**:\n",
        "```\n",
        "Date\n",
        "2023-01-01    10.0\n",
        "2023-01-02    15.0\n",
        "2023-01-03    20.0\n",
        "2023-01-04    30.0\n",
        "2023-01-05    40.0\n",
        "2023-01-06    50.0\n",
        "2023-01-07    60.0\n",
        "2023-01-08    70.0\n",
        "2023-01-09    80.0\n",
        "2023-01-10    90.0\n",
        "Name: Values, dtype: float64\n",
        "```\n",
        "```\n",
        "Date\n",
        "2023-01-01    15.0\n",
        "2023-01-02    20.0\n",
        "2023-01-03    30.0\n",
        "2023-01-04    40.0\n",
        "2023-01-05    50.0\n",
        "2023-01-06    60.0\n",
        "2023-01-07    70.0\n",
        "2023-01-08    80.0\n",
        "2023-01-09    90.0\n",
        "2023-01-10    100.0\n",
        "Name: Values, dtype: float64\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Handling Text Data**\n",
        "\n",
        "* Handling text data in Pandas is essential for data cleaning, preprocessing, and analysis.\n",
        "* Pandas provides a variety of functions and methods to manipulate and analyze text data efficiently.\n",
        "\n",
        "### 1. Creating a DataFrame with Text Data\n",
        "• **Definition**: You can create a DataFrame that contains text data, which can be manipulated and analyzed.\n",
        "• **Method**:\n",
        "  - Use a dictionary or a list of lists to create a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with text data\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Occupation': ['Engineer', 'Doctor', 'Artist', 'Chef'],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City\n",
        "0    Alice   Engineer     New York\n",
        "1      Bob     Doctor  Los Angeles\n",
        "2  Charlie     Artist      Chicago\n",
        "3    David       Chef      Houston\n",
        "```\n",
        "\n",
        "### 2. String Methods in Pandas\n",
        "• **Definition**: Pandas provides a set of string methods that can be applied to Series containing text data.\n",
        "• **Method**:\n",
        "  - Use the `.str` accessor to access string methods.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Converting text to lowercase\n",
        "df['Occupation'] = df['Occupation'].str.lower()\n",
        "print(df)\n",
        "\n",
        "# Checking if a string contains a substring\n",
        "df['Is_Engineer'] = df['Occupation'].str.contains('engineer')\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City\n",
        "0    Alice   engineer     New York\n",
        "1      Bob     doctor  Los Angeles\n",
        "2  Charlie     artist      Chicago\n",
        "3    David       chef      Houston\n",
        "```\n",
        "```\n",
        "      Name Occupation         City  Is_Engineer\n",
        "0    Alice   engineer     New York         True\n",
        "1      Bob     doctor  Los Angeles        False\n",
        "2  Charlie     artist      Chicago        False\n",
        "3    David       chef      Houston        False\n",
        "```\n",
        "\n",
        "### 3. String Manipulation\n",
        "• **Definition**: You can perform various string manipulations, such as splitting, joining, replacing, and stripping whitespace.\n",
        "• **Methods**:\n",
        "  - `str.split()`: Splits strings into lists.\n",
        "  - `str.join()`: Joins lists into strings.\n",
        "  - `str.replace()`: Replaces substrings.\n",
        "  - `str.strip()`: Removes leading and trailing whitespace.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Splitting a string into a list\n",
        "df['City_Split'] = df['City'].str.split(' ')\n",
        "print(df)\n",
        "\n",
        "# Joining a list into a string\n",
        "df['City_Joined'] = df['City_Split'].str.join(', ')\n",
        "print(df)\n",
        "\n",
        "# Replacing substrings\n",
        "df['City'] = df['City'].str.replace('New York', 'NYC')\n",
        "print(df)\n",
        "\n",
        "# Stripping whitespace\n",
        "df['City'] = df['City'].str.strip()\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City       City_Split\n",
        "0    Alice   engineer     New York         [New, York]\n",
        "1      Bob     doctor  Los Angeles     [Los, Angeles]\n",
        "2  Charlie     artist      Chicago          [Chicago]\n",
        "3    David       chef      Houston          [Houston]\n",
        "```\n",
        "```\n",
        "      Name Occupation         City       City_Split          City_Joined\n",
        "0    Alice   engineer         NYC         [New, York]              New, York\n",
        "1      Bob     doctor  Los Angeles     [Los, Angeles]        Los, Angeles\n",
        "2  Charlie     artist      Chicago          [Chicago]              Chicago\n",
        "3    David       chef      Houston          [Houston]              Houston\n",
        "```\n",
        "```\n",
        "      Name Occupation         City       City_Split          City_Joined\n",
        "0    Alice   engineer         NYC         [NYC]              NYC\n",
        "1      Bob     doctor  Los Angeles     [Los, Angeles]        Los, Angeles\n",
        "2  Charlie     artist      Chicago          [Chicago]              Chicago\n",
        "3    David       chef      Houston          [Houston]              Houston\n",
        "```\n",
        "\n",
        "### 4. Text Data Analysis\n",
        "• **Definition**: You can analyze text data to extract insights, such as counting occurrences of words or characters.\n",
        "• **Method**:\n",
        "  - Use string methods to perform analysis.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Counting the number of characters in each occupation\n",
        "df['Occupation_Length'] = df['Occupation'].str.len()\n",
        "print(df)\n",
        "\n",
        "# Counting occurrences of a specific character\n",
        "df['A_Count'] = df['Name'].str.count('a')\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length\n",
        "0    Alice   engineer         NYC                 7\n",
        "1      Bob     doctor  Los Angeles                 6\n",
        "2  Charlie     artist      Chicago                 6\n",
        "3    David       chef      Houston                 4\n",
        "```\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length  A_Count\n",
        "0    Alice   engineer         NYC                 7       1\n",
        "1      Bob     doctor  Los Angeles                 6       0\n",
        "2  Charlie     artist      Chicago                 6       1\n",
        "3    David       chef      Houston                 4       1\n",
        "```\n",
        "\n",
        "### 5. Handling Missing Values in Text Data\n",
        "• **Definition**: You can handle missing values in text data using methods like `fillna()` or `replace()`.\n",
        "• **Method**:\n",
        "  - Use `fillna()` to replace missing values.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Introducing missing values\n",
        "df.loc[1, 'Occupation'] = None\n",
        "\n",
        "# Filling missing values with a default value\n",
        "df['Occupation'] = df['Occupation'].fillna('Unknown')\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length  A_Count\n",
        "0    Alice   engineer         NYC                 7       1\n",
        "1      Bob     Unknown  Los Angeles                 7       0\n",
        "2  Charlie     artist      Chicago                 6       1\n",
        "3    David       chef      Houston                 4       1\n",
        "```\n",
        "\n",
        "### 6. Regular Expressions with Text Data\n",
        "• **Definition**: You can use regular expressions (regex) to perform complex string matching and manipulation.\n",
        "• **Method**:\n",
        "  - Use `str.contains()`, `str.match()`, and `str.replace()` with regex.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Checking if the occupation contains the letter 'a'\n",
        "df['Contains_A'] = df['Occupation'].str.contains('a', case=False)\n",
        "print(df)\n",
        "\n",
        "# Replacing occupations that contain 'a' with 'Artist'\n",
        "df['Occupation'] = df['Occupation'].str.replace(r'.*a.*', 'Artist', regex=True)\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length  A_Count  Contains_A\n",
        "0    Alice   engineer         NYC                 7       1         True\n",
        "1      Bob     Unknown  Los Angeles                 7       0        False\n",
        "2  Charlie     artist      Chicago                 6       1         True\n",
        "3    David       chef      Houston                 4       1        False\n",
        "```\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length  A_Count  Contains_A\n",
        "0    Alice     Artist         NYC                 7       1         True\n",
        "1      Bob     Artist  Los Angeles                 7       0        False\n",
        "2  Charlie     Artist      Chicago                 6       1         True\n",
        "3    David       chef      Houston                 4       1        False\n",
        "```\n",
        "\n",
        "### 7. Concatenating and Joining Text Data\n",
        "• **Definition**: You can concatenate or join text data from different columns or DataFrames.\n",
        "• **Method**:\n",
        "  - Use `str.cat()` to concatenate strings.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Concatenating Name and Occupation\n",
        "df['Name_Occupation'] = df['Name'] + ' is a ' + df['Occupation']\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name Occupation         City  Occupation_Length  A_Count  Contains_A              Name_Occupation\n",
        "0    Alice     Artist         NYC                 7       1         True           Alice is a Artist\n",
        "1      Bob     Artist  Los Angeles                 7       0        False      Bob is a Artist\n",
        "2  Charlie     Artist      Chicago                 6       1         True      Charlie is a Artist\n",
        "3    David       chef      Houston                 4       1        False           David is a chef\n",
        "```\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Advanced Indexing and MultiIndex**\n",
        "\n",
        "* Advanced indexing and MultiIndex in Pandas are powerful features that allow for more complex data manipulation and analysis. * They enable you to work with hierarchical data structures and perform sophisticated data selection and aggregation.\n",
        "\n",
        "### 1. Basic Indexing in Pandas\n",
        "• **Definition**: Basic indexing allows you to select rows and columns from a DataFrame using labels or integer positions.\n",
        "• **Methods**:\n",
        "  - `.loc[]`: Label-based indexing.\n",
        "  - `.iloc[]`: Integer position-based indexing.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [4, 5, 6],\n",
        "    'C': [7, 8, 9]\n",
        "}\n",
        "df = pd.DataFrame(data, index=['row1', 'row2', 'row3'])\n",
        "\n",
        "# Basic indexing\n",
        "print(df.loc['row1'])  # Using label\n",
        "print(df.iloc[0])      # Using integer position\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "A    1\n",
        "B    4\n",
        "C    7\n",
        "Name: row1, dtype: int64\n",
        "```\n",
        "```\n",
        "A    1\n",
        "B    4\n",
        "C    7\n",
        "Name: row1, dtype: int64\n",
        "```\n",
        "\n",
        "### 2. Advanced Indexing with Boolean Arrays\n",
        "• **Definition**: You can use boolean arrays to filter data based on conditions.\n",
        "• **Method**:\n",
        "  - Use boolean conditions to create a mask.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filtering rows based on a condition\n",
        "filtered_df = df[df['A'] > 1]\n",
        "print(filtered_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "       A  B  C\n",
        "row2  2  5  8\n",
        "row3  3  6  9\n",
        "```\n",
        "\n",
        "### 3. Setting and Resetting Index\n",
        "• **Definition**: You can set a specific column as the index of a DataFrame or reset the index to the default integer index.\n",
        "• **Methods**:\n",
        "  - `set_index()`: Sets a column as the index.\n",
        "  - `reset_index()`: Resets the index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Setting a column as the index\n",
        "df_set = df.set_index('A')\n",
        "print(df_set)\n",
        "\n",
        "# Resetting the index\n",
        "df_reset = df_set.reset_index()\n",
        "print(df_reset)\n",
        "```\n",
        "**Output (Set Index)**:\n",
        "```\n",
        "     B  C\n",
        "A        \n",
        "1  4  7\n",
        "2  5  8\n",
        "3  6  9\n",
        "```\n",
        "**Output (Reset Index)**:\n",
        "```\n",
        "   A  B  C\n",
        "0  1  4  7\n",
        "1  2  5  8\n",
        "2  3  6  9\n",
        "```\n",
        "\n",
        "### 4. MultiIndex\n",
        "• **Definition**: MultiIndex allows you to create a hierarchical index for a DataFrame, enabling more complex data structures and easier data manipulation.\n",
        "• **Method**:\n",
        "  - Use `pd.MultiIndex.from_tuples()` or `pd.MultiIndex.from_product()` to create a MultiIndex.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a MultiIndex\n",
        "arrays = [\n",
        "    ['A', 'A', 'B', 'B'],\n",
        "    ['one', 'two', 'one', 'two']\n",
        "]\n",
        "index = pd.MultiIndex.from_arrays(arrays, names=('letter', 'number'))\n",
        "\n",
        "# Creating a DataFrame with MultiIndex\n",
        "df_multi = pd.DataFrame({'value': [1, 2, 3, 4]}, index=index)\n",
        "print(df_multi)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "              value\n",
        "letter number       \n",
        "A      one        1\n",
        "       two        2\n",
        "B      one        3\n",
        "       two        4\n",
        "```\n",
        "\n",
        "### 5. Accessing Data with MultiIndex\n",
        "• **Definition**: You can access data in a MultiIndex DataFrame using tuples or the `.loc[]` method.\n",
        "• **Method**:\n",
        "  - Use tuples to specify the index levels.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Accessing data using MultiIndex\n",
        "print(df_multi.loc['A'])          # Access all rows for 'A'\n",
        "print(df_multi.loc[('A', 'one')]) # Access specific row\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "              value\n",
        "number             \n",
        "one             1\n",
        "two             2\n",
        "```\n",
        "```\n",
        "value    1\n",
        "Name: (A, one), dtype: int64\n",
        "```\n",
        "\n",
        "### 6. Slicing with MultiIndex\n",
        "• **Definition**: You can slice MultiIndex DataFrames to access a range of data.\n",
        "• **Method**:\n",
        "  - Use `.loc[]` with slices.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Slicing MultiIndex DataFrame\n",
        "print(df_multi.loc['A':'B'])  # Slicing by the first level\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "              value\n",
        "letter number       \n",
        "A      one        1\n",
        "       two        2\n",
        "B      one        3\n",
        "       two        4\n",
        "```\n",
        "\n",
        "### 7. Swapping and Stacking/Unstacking MultiIndex\n",
        "• **Definition**: You can swap levels of a MultiIndex or stack/unstack the DataFrame to change its shape.\n",
        "• **Methods**:\n",
        "  - `swaplevel()`: Swaps levels in a MultiIndex.\n",
        "  - `stack()`: Stacks the columns into the index.\n",
        "  - `unstack()`: Unstacks the index into columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Swapping levels\n",
        "df_swapped = df_multi.swaplevel()\n",
        "print(df_swapped)\n",
        "\n",
        "# Stacking and unstacking\n",
        "df_stacked = df_multi.unstack()\n",
        "print(df_stacked)\n",
        "```\n",
        "**Output (Swapped Levels)**:\n",
        "```\n",
        "              value\n",
        "number letter       \n",
        "one             1\n",
        "two             2\n",
        "one             3\n",
        "two             4\n",
        "```\n",
        "**Output (Unstacked)**:\n",
        "```\n",
        "        value       \n",
        "number      one two\n",
        "letter             \n",
        "A            1   2\n",
        "B            3   4\n",
        "```\n",
        "\n",
        "### 8. Resetting MultiIndex\n",
        "• **Definition**: You can reset a MultiIndex to convert it back to regular columns.\n",
        "• **Method**:\n",
        "  - `reset_index()`: Resets the index of a MultiIndex DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Resetting MultiIndex\n",
        "df_reset_multi = df_multi.reset_index()\n",
        "print(df_reset_multi)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "  letter number  value\n",
        "0      A    one      1\n",
        "1      A    two      2\n",
        "2      B    one      3\n",
        "3      B    two      4\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Data Visualization**\n",
        "\n",
        "* Data visualization is a crucial aspect of data analysis, allowing you to communicate insights and patterns effectively.\n",
        "* Pandas provides built-in capabilities for visualizing data using Matplotlib and Seaborn, making it easy to create a variety of plots directly from DataFrames.\n",
        "\n",
        "### 1. Basic Plotting with Pandas\n",
        "• **Definition**: Pandas integrates with Matplotlib to provide simple plotting capabilities directly from DataFrames and Series.\n",
        "• **Method**:\n",
        "  - Use the `.plot()` method on DataFrames and Series.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Year': [2018, 2019, 2020, 2021, 2022],\n",
        "    'Sales': [150, 200, 250, 300, 350]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Basic line plot\n",
        "df.plot(x='Year', y='Sales', kind='line', title='Sales Over Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sales')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A line plot showing sales over the years.\n",
        "\n",
        "### 2. Different Plot Types\n",
        "• **Definition**: Pandas supports various plot types, including line, bar, histogram, box, and scatter plots.\n",
        "• **Method**:\n",
        "  - Specify the `kind` parameter in the `.plot()` method.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Bar plot\n",
        "df.plot(x='Year', y='Sales', kind='bar', title='Sales by Year')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sales')\n",
        "plt.show()\n",
        "\n",
        "# Histogram\n",
        "df['Sales'].plot(kind='hist', bins=5, title='Sales Distribution')\n",
        "plt.xlabel('Sales')\n",
        "plt.show()\n",
        "\n",
        "# Box plot\n",
        "df.plot(kind='box', title='Sales Box Plot')\n",
        "plt.show()\n",
        "```\n",
        "**Output**:\n",
        "• A bar plot showing sales by year.\n",
        "• A histogram showing the distribution of sales.\n",
        "• A box plot showing the summary statistics of sales.\n",
        "\n",
        "### 3. Customizing Plots\n",
        "• **Definition**: You can customize plots by modifying titles, labels, colors, and styles.\n",
        "• **Method**:\n",
        "  - Use parameters in the `.plot()` method and Matplotlib functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Customizing a line plot\n",
        "df.plot(x='Year', y='Sales', kind='line', color='orange', marker='o', linestyle='--', title='Sales Over Years')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Sales')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A customized line plot with specific colors and styles.\n",
        "\n",
        "### 4. Subplots\n",
        "• **Definition**: You can create multiple plots in a single figure using subplots.\n",
        "• **Method**:\n",
        "  - Use the `subplot()` function from Matplotlib.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating subplots\n",
        "fig, axs = plt.subplots(2, 1, figsize=(8, 8))\n",
        "\n",
        "# Line plot\n",
        "df.plot(x='Year', y='Sales', kind='line', ax=axs[0], title='Sales Over Years')\n",
        "axs[0].set_ylabel('Sales')\n",
        "\n",
        "# Bar plot\n",
        "df.plot(x='Year', y='Sales', kind='bar', ax=axs[1], title='Sales by Year')\n",
        "axs[1].set_ylabel('Sales')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A figure with two subplots: a line plot and a bar plot.\n",
        "\n",
        "### 5. Scatter Plots\n",
        "• **Definition**: Scatter plots are useful for visualizing the relationship between two numerical variables.\n",
        "• **Method**:\n",
        "  - Use the `scatter()` method.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with additional data\n",
        "data = {\n",
        "    'Year': [2018, 2019, 2020, 2021, 2022],\n",
        "    'Sales': [150, 200, 250, 300, 350],\n",
        "    'Profit': [30, 50, 70, 90, 110]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Scatter plot\n",
        "df.plot.scatter(x='Sales', y='Profit', title='Sales vs Profit', color='green')\n",
        "plt.xlabel('Sales')\n",
        "plt.ylabel('Profit')\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A scatter plot showing the relationship between sales and profit.\n",
        "\n",
        "### 6. Time Series Plotting\n",
        "• **Definition**: Time series data can be visualized using line plots to show trends over time.\n",
        "• **Method**:\n",
        "  - Use the `.plot()` method on a DataFrame with a datetime index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample time series data\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D')\n",
        "df_time = pd.DataFrame(date_rng, columns=['date'])\n",
        "df_time['data'] = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "df_time.set_index('date', inplace=True)\n",
        "\n",
        "# Time series plot\n",
        "df_time.plot(title='Time Series Data', figsize=(10, 5))\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Data')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A line plot showing the time series data.\n",
        "\n",
        "### 7. Using Seaborn for Enhanced Visualizations\n",
        "• **Definition**: Seaborn is a statistical data visualization library built on top of Matplotlib that provides a high-level interface for drawing attractive and informative statistical graphics.\n",
        "• **Method**:\n",
        "  - Use Seaborn functions to create various plots.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import seaborn as sns\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40, 50, 60]\n",
        "}\n",
        "df_seaborn = pd.DataFrame(data)\n",
        "\n",
        "# Box plot using Seaborn\n",
        "sns.boxplot(x='Category', y='Values', data=df_seaborn)\n",
        "plt.title('Box Plot of Values by Category')\n",
        "plt.show()\n",
        "\n",
        "# Bar plot using Seaborn\n",
        "sns.barplot(x='Category', y='Values', data=df_seaborn)\n",
        "plt.title('Bar Plot of Values by Category')\n",
        "plt.show()\n",
        "```\n",
        "**Output**:\n",
        "• A box plot showing the distribution of values by category.\n",
        "• A bar plot showing the average values by category.\n",
        "\n",
        "### 8. Saving Plots\n",
        "• **Definition**: You can save your plots to files in various formats (e.g., PNG, PDF).\n",
        "• **Method**:\n",
        "  - Use the `savefig()` function from Matplotlib.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Saving a plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "df_time.plot(title='Time Series Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Data')\n",
        "plt.grid()\n",
        "plt.savefig('time_series_plot.png')  # Save as PNG\n",
        "plt.show()\n",
        "```\n",
        "**Output**: The plot is saved as a PNG file named `time_series_plot.png`.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Performance Optimization (Vectorization , Memory Usage)**\n",
        "\n",
        "Performance optimization in Pandas is crucial for efficiently handling large datasets and ensuring that data manipulation and analysis tasks are executed quickly. Two key aspects of performance optimization in Pandas are vectorization and memory usage management. Below are the key topics related to performance optimization in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Vectorization\n",
        "• **Definition**: Vectorization refers to the process of applying operations to entire arrays or Series instead of using loops. This takes advantage of low-level optimizations and is generally much faster than iterating through elements one by one.\n",
        "• **Method**:\n",
        "  - Use built-in Pandas functions and operations that operate on entire Series or DataFrames.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Sample DataFrame\n",
        "n = 10**6  # 1 million rows\n",
        "df = pd.DataFrame({\n",
        "    'A': np.random.rand(n),\n",
        "    'B': np.random.rand(n)\n",
        "})\n",
        "\n",
        "# Vectorized operation\n",
        "start_time = time.time()\n",
        "df['C'] = df['A'] + df['B']  # Vectorized addition\n",
        "end_time = time.time()\n",
        "print(f\"Vectorized operation time: {end_time - start_time:.5f} seconds\")\n",
        "```\n",
        "**Output**: The time taken for the vectorized operation will be printed.\n",
        "\n",
        "### 2. Avoiding Loops\n",
        "• **Definition**: Avoid using Python loops (e.g., `for` loops) for operations on DataFrames, as they are significantly slower than vectorized operations.\n",
        "• **Method**:\n",
        "  - Use Pandas built-in functions and methods instead of iterating through rows.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Non-vectorized operation using a loop\n",
        "start_time = time.time()\n",
        "df['D'] = 0\n",
        "for i in range(len(df)):\n",
        "    df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n",
        "end_time = time.time()\n",
        "print(f\"Non-vectorized operation time: {end_time - start_time:.5f} seconds\")\n",
        "```\n",
        "**Output**: The time taken for the non-vectorized operation will be printed, and it will be significantly longer than the vectorized operation.\n",
        "\n",
        "### 3. Using NumPy for Performance\n",
        "• **Definition**: NumPy is a powerful library for numerical computations in Python. Using NumPy functions can enhance performance when working with numerical data.\n",
        "• **Method**:\n",
        "  - Convert Pandas DataFrames or Series to NumPy arrays for faster computations.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Using NumPy for calculations\n",
        "start_time = time.time()\n",
        "array_A = df['A'].to_numpy()\n",
        "array_B = df['B'].to_numpy()\n",
        "df['E'] = array_A * array_B  # Using NumPy for element-wise multiplication\n",
        "end_time = time.time()\n",
        "print(f\"NumPy operation time: {end_time - start_time:.5f} seconds\")\n",
        "```\n",
        "**Output**: The time taken for the NumPy operation will be printed.\n",
        "\n",
        "### 4. Memory Usage Optimization\n",
        "• **Definition**: Managing memory usage is essential when working with large datasets. Optimizing data types can significantly reduce memory consumption.\n",
        "• **Method**:\n",
        "  - Use appropriate data types for columns (e.g., `category`, `float32`, `int8`).\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Checking memory usage\n",
        "print(df.info(memory_usage='deep'))\n",
        "\n",
        "# Optimizing data types\n",
        "df['A'] = df['A'].astype('float32')  # Change to float32\n",
        "df['B'] = df['B'].astype('float32')  # Change to float32\n",
        "df['C'] = df['C'].astype('float32')  # Change to float32\n",
        "\n",
        "# Checking memory usage after optimization\n",
        "print(df.info(memory_usage='deep'))\n",
        "```\n",
        "**Output**: The memory usage before and after optimization will be printed, showing a reduction in memory consumption.\n",
        "\n",
        "### 5. Using `query()` for Filtering\n",
        "• **Definition**: The `query()` method allows for efficient filtering of DataFrames using a query string, which can be faster than traditional boolean indexing.\n",
        "• **Method**:\n",
        "  - Use `query()` to filter rows based on conditions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filtering using query\n",
        "start_time = time.time()\n",
        "filtered_df = df.query('A > 0.5 and B < 0.5')\n",
        "end_time = time.time()\n",
        "print(f\"Query operation time: {end_time - start_time:.5f} seconds\")\n",
        "```\n",
        "**Output**: The time taken for the query operation will be printed.\n",
        "\n",
        "### 6. Using `apply()` Efficiently\n",
        "• **Definition**: The `apply()` method can be used for applying functions along the axis of a DataFrame. However, it can be slower than vectorized operations.\n",
        "• **Method**:\n",
        "  - Use `apply()` only when necessary and prefer vectorized functions when possible.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Using apply (less efficient)\n",
        "start_time = time.time()\n",
        "df['F'] = df['A'].apply(lambda x: x * 2)  # Using apply\n",
        "end_time = time.time()\n",
        "print(f\"Apply operation time: {end_time - start_time:.5f} seconds\")\n",
        "```\n",
        "**Output**: The time taken for the apply operation will be printed, and it will be longer than the vectorized operations.\n",
        "\n",
        "### 7. Profiling and Benchmarking\n",
        "• **Definition**: Profiling helps identify bottlenecks in your code, allowing you to optimize performance effectively.\n",
        "• **Method**:\n",
        "  - Use libraries like `line_profiler` or `memory_profiler` to analyze performance.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Example of profiling (requires installation of line_profiler)\n",
        "# Use the following command in the terminal to install:\n",
        "# pip install line_profiler\n",
        "\n",
        "# @profile\n",
        "def example_function():\n",
        "    df['G'] = df['A'] + df['B']  # Example operation\n",
        "\n",
        "# Call the function to profile\n",
        "example_function()\n",
        "```\n",
        "**Output**: Profiling results will show the time taken for each line of code.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Exporting and Importing Data**\n",
        "\n",
        "* Exporting and importing data in Pandas is essential for data analysis workflows, allowing you to read data from various file formats and save processed data back to files.\n",
        "* Pandas provides built-in functions to handle a wide range of data formats, including CSV, Excel, JSON, SQL databases, and more.\n",
        "\n",
        "### 1. Importing Data\n",
        "\n",
        "#### 1.1 Importing CSV Files\n",
        "• **Definition**: CSV (Comma-Separated Values) is a common file format for storing tabular data.\n",
        "• **Method**:\n",
        "  - Use `pd.read_csv()` to read CSV files into a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Importing a CSV file\n",
        "df_csv = pd.read_csv('data.csv')\n",
        "print(df_csv.head())\n",
        "```\n",
        "\n",
        "#### 1.2 Importing Excel Files\n",
        "• **Definition**: Excel files are widely used for data storage and analysis.\n",
        "• **Method**:\n",
        "  - Use `pd.read_excel()` to read Excel files into a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing an Excel file\n",
        "df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
        "print(df_excel.head())\n",
        "```\n",
        "\n",
        "#### 1.3 Importing JSON Files\n",
        "• **Definition**: JSON (JavaScript Object Notation) is a lightweight data interchange format.\n",
        "• **Method**:\n",
        "  - Use `pd.read_json()` to read JSON files into a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing a JSON file\n",
        "df_json = pd.read_json('data.json')\n",
        "print(df_json.head())\n",
        "```\n",
        "\n",
        "#### 1.4 Importing from SQL Databases\n",
        "• **Definition**: You can read data from SQL databases using SQL queries.\n",
        "• **Method**:\n",
        "  - Use `pd.read_sql()` to read data from a SQL database.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import sqlite3\n",
        "\n",
        "# Connecting to a SQLite database\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Importing data from a SQL table\n",
        "df_sql = pd.read_sql('SELECT * FROM table_name', conn)\n",
        "print(df_sql.head())\n",
        "\n",
        "# Closing the connection\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "### 2. Exporting Data\n",
        "\n",
        "#### 2.1 Exporting to CSV Files\n",
        "• **Definition**: You can save a DataFrame to a CSV file.\n",
        "• **Method**:\n",
        "  - Use `df.to_csv()` to export DataFrames to CSV files.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Exporting DataFrame to a CSV file\n",
        "df_csv.to_csv('output.csv', index=False)  # index=False to avoid writing row indices\n",
        "```\n",
        "\n",
        "#### 2.2 Exporting to Excel Files\n",
        "• **Definition**: You can save a DataFrame to an Excel file.\n",
        "• **Method**:\n",
        "  - Use `df.to_excel()` to export DataFrames to Excel files.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Exporting DataFrame to an Excel file\n",
        "df_excel.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n",
        "```\n",
        "\n",
        "#### 2.3 Exporting to JSON Files\n",
        "• **Definition**: You can save a DataFrame to a JSON file.\n",
        "• **Method**:\n",
        "  - Use `df.to_json()` to export DataFrames to JSON files.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Exporting DataFrame to a JSON file\n",
        "df_json.to_json('output.json', orient='records', lines=True)\n",
        "```\n",
        "\n",
        "#### 2.4 Exporting to SQL Databases\n",
        "• **Definition**: You can save a DataFrame to a SQL database.\n",
        "• **Method**:\n",
        "  - Use `df.to_sql()` to write DataFrames to a SQL table.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Connecting to a SQLite database\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Exporting DataFrame to a SQL table\n",
        "df_sql.to_sql('table_name', conn, if_exists='replace', index=False)\n",
        "\n",
        "# Closing the connection\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "### 3. Handling File Paths\n",
        "• **Definition**: When importing or exporting files, you can specify relative or absolute file paths.\n",
        "• **Method**:\n",
        "  - Use appropriate file paths based on your working directory.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing from a relative path\n",
        "df_relative = pd.read_csv('./data/data.csv')\n",
        "\n",
        "# Exporting to an absolute path\n",
        "df_csv.to_csv('/Users/username/Documents/output.csv', index=False)\n",
        "```\n",
        "\n",
        "### 4. Additional Options\n",
        "• **Definition**: When importing or exporting data, you can specify additional options to customize the process.\n",
        "• **Method**:\n",
        "  - Use parameters like `sep`, `header`, `encoding`, and `na_values` in `read_csv()`, and `index`, `header`, and `sheet_name` in `to_excel()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing a CSV file with custom separator and encoding\n",
        "df_custom = pd.read_csv('data.csv', sep=';', encoding='utf-8')\n",
        "\n",
        "# Exporting to CSV with custom options\n",
        "df_csv.to_csv('output.csv', index=False, header=True, na_rep='NA')\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Handling Duplicates**\n",
        "\n",
        "* Handling duplicates in Pandas is an essential part of data cleaning and preprocessing.\n",
        "* Duplicate entries can lead to inaccurate analysis and insights, so it's important to identify and manage them effectively.\n",
        "\n",
        "### 1. Identifying Duplicates\n",
        "• **Definition**: You can identify duplicate rows in a DataFrame using the `duplicated()` method, which returns a boolean Series indicating whether each row is a duplicate.\n",
        "• **Method**:\n",
        "  - `DataFrame.duplicated()`: Checks for duplicate rows.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with duplicates\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'Alice', 'David', 'Bob'],\n",
        "    'Age': [24, 30, 22, 24, 35, 30],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'New York', 'Houston', 'Los Angeles']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Identifying duplicates\n",
        "duplicates = df.duplicated()\n",
        "print(duplicates)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0    False\n",
        "1    False\n",
        "2    False\n",
        "3     True\n",
        "4    False\n",
        "5     True\n",
        "dtype: bool\n",
        "```\n",
        "\n",
        "### 2. Counting Duplicates\n",
        "• **Definition**: You can count the number of duplicate rows in a DataFrame using the `sum()` function on the boolean Series returned by `duplicated()`.\n",
        "• **Method**:\n",
        "  - Use `sum()` to count duplicates.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Counting duplicate rows\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {duplicate_count}\")\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Number of duplicate rows: 2\n",
        "```\n",
        "\n",
        "### 3. Removing Duplicates\n",
        "• **Definition**: You can remove duplicate rows from a DataFrame using the `drop_duplicates()` method.\n",
        "• **Method**:\n",
        "  - `DataFrame.drop_duplicates()`: Removes duplicate rows.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Removing duplicate rows\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "print(df_no_duplicates)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   22      Chicago\n",
        "4    David   35      Houston\n",
        "```\n",
        "\n",
        "### 4. Removing Duplicates Based on Specific Columns\n",
        "• **Definition**: You can specify certain columns to consider when identifying duplicates.\n",
        "• **Method**:\n",
        "  - Use the `subset` parameter in `drop_duplicates()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Removing duplicates based on the 'Name' column\n",
        "df_no_duplicates_name = df.drop_duplicates(subset='Name')\n",
        "print(df_no_duplicates_name)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   22      Chicago\n",
        "4    David   35      Houston\n",
        "```\n",
        "\n",
        "### 5. Keeping Specific Duplicates\n",
        "• **Definition**: You can choose to keep the first or last occurrence of duplicates when removing them.\n",
        "• **Method**:\n",
        "  - Use the `keep` parameter in `drop_duplicates()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Keeping the last occurrence of duplicates\n",
        "df_keep_last = df.drop_duplicates(keep='last')\n",
        "print(df_keep_last)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "2  Charlie   22      Chicago\n",
        "4    David   35      Houston\n",
        "5      Bob   30  Los Angeles\n",
        "```\n",
        "\n",
        "### 6. Resetting Index After Removing Duplicates\n",
        "• **Definition**: After removing duplicates, the index may not be sequential. You can reset the index using `reset_index()`.\n",
        "• **Method**:\n",
        "  - Use `reset_index(drop=True)` to reset the index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Resetting index after removing duplicates\n",
        "df_reset_index = df_no_duplicates.reset_index(drop=True)\n",
        "print(df_reset_index)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   22      Chicago\n",
        "3    David   35      Houston\n",
        "```\n",
        "\n",
        "### 7. Finding Duplicate Rows with Specific Conditions\n",
        "• **Definition**: You can find duplicates based on specific conditions using boolean indexing.\n",
        "• **Method**:\n",
        "  - Combine `duplicated()` with boolean indexing.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Finding duplicates with specific conditions\n",
        "duplicates_condition = df[df.duplicated(subset=['Name', 'City'], keep=False)]\n",
        "print(duplicates_condition)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "3    Alice   24     New York\n",
        "1      Bob   30  Los Angeles\n",
        "5      Bob   30  Los Angeles\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Applying functions (apply , map)**\n",
        "\n",
        "* In Pandas, applying functions to DataFrames and Series is a common operation that allows for flexible data manipulation and transformation. The `apply()` and `map()` methods are two powerful tools for applying functions to data.\n",
        "\n",
        "### 1. Using `apply()`\n",
        "• **Definition**: The `apply()` method allows you to apply a function along an axis of the DataFrame (rows or columns) or to a Series. It can be used for both element-wise operations and aggregations.\n",
        "• **Method**:\n",
        "  - `DataFrame.apply(func, axis=0)`: Applies a function along the specified axis (0 for columns, 1 for rows).\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3],\n",
        "    'B': [4, 5, 6],\n",
        "    'C': [7, 8, 9]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Applying a function to each column (default axis=0)\n",
        "column_sum = df.apply(sum)\n",
        "print(column_sum)\n",
        "\n",
        "# Applying a function to each row (axis=1)\n",
        "row_sum = df.apply(sum, axis=1)\n",
        "print(row_sum)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "A    6\n",
        "B    15\n",
        "C    24\n",
        "dtype: int64\n",
        "```\n",
        "```\n",
        "0    12\n",
        "1    15\n",
        "2    18\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 2. Applying Custom Functions\n",
        "• **Definition**: You can define and apply custom functions using `apply()`.\n",
        "• **Method**:\n",
        "  - Pass a custom function to `apply()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Custom function to calculate the range\n",
        "def calculate_range(x):\n",
        "    return x.max() - x.min()\n",
        "\n",
        "# Applying the custom function to each column\n",
        "range_result = df.apply(calculate_range)\n",
        "print(range_result)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "A    2\n",
        "B    2\n",
        "C    2\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 3. Using `map()`\n",
        "• **Definition**: The `map()` method is used primarily with Series to apply a function or mapping correspondence to each element. It is particularly useful for element-wise transformations.\n",
        "• **Method**:\n",
        "  - `Series.map(func)`: Applies a function to each element in the Series.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample Series\n",
        "s = pd.Series([1, 2, 3, 4])\n",
        "\n",
        "# Using map to apply a function\n",
        "squared = s.map(lambda x: x ** 2)\n",
        "print(squared)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 4. Mapping with Dictionaries\n",
        "• **Definition**: You can use `map()` with a dictionary to replace values in a Series based on a mapping.\n",
        "• **Method**:\n",
        "  - Pass a dictionary to `map()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample Series with categorical data\n",
        "s_categories = pd.Series(['cat', 'dog', 'cat', 'bird'])\n",
        "\n",
        "# Mapping categories to numerical values\n",
        "category_mapping = {'cat': 1, 'dog': 2, 'bird': 3}\n",
        "mapped_values = s_categories.map(category_mapping)\n",
        "print(mapped_values)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0    1.0\n",
        "1    2.0\n",
        "2    1.0\n",
        "3    3.0\n",
        "dtype: float64\n",
        "```\n",
        "\n",
        "### 5. Differences Between `apply()` and `map()`\n",
        "• **Definition**: While both `apply()` and `map()` are used to apply functions, they have different use cases:\n",
        "  - `apply()`: Can be used on both DataFrames and Series, and can apply functions along rows or columns.\n",
        "  - `map()`: Primarily used with Series for element-wise operations and transformations.\n",
        "\n",
        "### 6. Performance Considerations\n",
        "• **Definition**: Vectorized operations (using built-in functions) are generally faster than using `apply()` or `map()`. When possible, prefer using vectorized operations for better performance.\n",
        "• **Method**:\n",
        "  - Use built-in Pandas functions for operations instead of `apply()` or `map()` when applicable.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Vectorized operation for squaring\n",
        "vectorized_squared = s ** 2\n",
        "print(vectorized_squared)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0     1\n",
        "1     4\n",
        "2     9\n",
        "3    16\n",
        "dtype: int64\n",
        "```\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Categorical Data**\n",
        "\n",
        "* Categorical data in Pandas is a data type that represents a limited, fixed number of possible values (categories). This type of data is useful for representing qualitative data, such as labels, categories, or groups.\n",
        "* Categorical data can lead to more efficient memory usage and faster computations compared to using regular object types.\n",
        "\n",
        "### 1. Creating Categorical Data\n",
        "• **Definition**: You can create categorical data using the `Categorical` data type in Pandas.\n",
        "• **Method**:\n",
        "  - Use `pd.Categorical()` or specify the `dtype='category'` when creating a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame with categorical data\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Gender': ['Female', 'Male', 'Male', 'Male'],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Converting 'Gender' column to categorical\n",
        "df['Gender'] = pd.Categorical(df['Gender'])\n",
        "print(df['Gender'].dtype)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "category\n",
        "```\n",
        "\n",
        "### 2. Specifying Categories\n",
        "• **Definition**: You can specify the categories explicitly when creating a categorical variable.\n",
        "• **Method**:\n",
        "  - Use the `categories` parameter in `pd.Categorical()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Specifying categories\n",
        "df['Gender'] = pd.Categorical(df['Gender'], categories=['Male', 'Female'], ordered=True)\n",
        "print(df['Gender'])\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0      Female\n",
        "1        Male\n",
        "2        Male\n",
        "3        Male\n",
        "dtype: category\n",
        "Categories (2, object): ['Male' < 'Female']\n",
        "```\n",
        "\n",
        "### 3. Benefits of Categorical Data\n",
        "• **Definition**: Categorical data can lead to more efficient memory usage and faster computations, especially when dealing with large datasets.\n",
        "• **Method**:\n",
        "  - Use `df.info()` to compare memory usage.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Original DataFrame\n",
        "print(df.info(memory_usage='deep'))\n",
        "\n",
        "# Converting 'City' column to categorical\n",
        "df['City'] = pd.Categorical(df['City'])\n",
        "print(df.info(memory_usage='deep'))\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 4 entries, 0 to 3\n",
        "Data columns (total 3 columns):\n",
        " #   Column  Non-Null Count  Dtype  \n",
        "---  ------  --------------  -----  \n",
        " 0   Name    4 non-null      object\n",
        " 1   Gender  4 non-null      category\n",
        " 2   City    4 non-null      object\n",
        "dtypes: category(1), object(2)\n",
        "memory usage: 1.1 KB\n",
        "```\n",
        "```\n",
        "<class 'pandas.core.frame.DataFrame'>\n",
        "RangeIndex: 4 entries, 0 to 3\n",
        "Data columns (total 3 columns):\n",
        " #   Column  Non-Null Count  Dtype   \n",
        "---  ------  --------------  -----   \n",
        " 0   Name    4 non-null      object  \n",
        " 1   Gender  4 non-null      category\n",
        " 2   City    4 non-null      category\n",
        "dtypes: category(2), object(1)\n",
        "memory usage: 1.0 KB\n",
        "```\n",
        "\n",
        "### 4. Operations on Categorical Data\n",
        "• **Definition**: You can perform various operations on categorical data, such as sorting, filtering, and grouping.\n",
        "• **Method**:\n",
        "  - Use standard DataFrame operations.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sorting by categorical data\n",
        "df_sorted = df.sort_values(by='Gender')\n",
        "print(df_sorted)\n",
        "\n",
        "# Grouping by categorical data\n",
        "grouped = df.groupby('Gender').size()\n",
        "print(grouped)\n",
        "```\n",
        "**Output (Sorted)**:\n",
        "```\n",
        "      Name  Gender         City\n",
        "0    Alice  Female     New York\n",
        "1      Bob    Male  Los Angeles\n",
        "2  Charlie    Male      Chicago\n",
        "3    David    Male      Houston\n",
        "```\n",
        "```\n",
        "Gender\n",
        "Female    1\n",
        "Male      3\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 5. Encoding Categorical Data\n",
        "• **Definition**: Categorical data can be encoded into numerical values for machine learning models.\n",
        "• **Method**:\n",
        "  - Use `pd.get_dummies()` for one-hot encoding or `cat.codes` for label encoding.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# One-hot encoding\n",
        "df_encoded = pd.get_dummies(df, columns=['Gender'])\n",
        "print(df_encoded)\n",
        "\n",
        "# Label encoding\n",
        "df['Gender_Code'] = df['Gender'].cat.codes\n",
        "print(df)\n",
        "```\n",
        "**Output (One-Hot Encoding)**:\n",
        "```\n",
        "      Name         City  Gender_Female  Gender_Male\n",
        "0    Alice     New York               1             0\n",
        "1      Bob  Los Angeles               0             1\n",
        "2  Charlie      Chicago               0             1\n",
        "3    David      Houston               0             1\n",
        "```\n",
        "```\n",
        "      Name  Gender         City  Gender_Code\n",
        "0    Alice  Female     New York            1\n",
        "1      Bob    Male  Los Angeles            0\n",
        "2  Charlie    Male      Chicago            0\n",
        "3    David    Male      Houston            0\n",
        "```\n",
        "\n",
        "### 6. Handling Missing Values in Categorical Data\n",
        "• **Definition**: You can handle missing values in categorical data using methods like `fillna()` or `replace()`.\n",
        "• **Method**:\n",
        "  - Use `fillna()` to replace missing values.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Introducing missing values\n",
        "df.loc[1, 'Gender'] = None\n",
        "\n",
        "# Filling missing values with a specific category\n",
        "df['Gender'] = df['Gender'].fillna('Unknown')\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Gender         City\n",
        "0    Alice  Female     New York\n",
        "1      Bob  Unknown  Los Angeles\n",
        "2  Charlie    Male      Chicago\n",
        "3    David    Male      Houston\n",
        "```\n",
        "\n",
        "### 7. Plotting Categorical Data\n",
        "• **Definition**: You can visualize categorical data using bar plots or count plots.\n",
        "• **Method**:\n",
        "  - Use Matplotlib or Seaborn for visualization.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bar plot of gender counts\n",
        "sns.countplot(x='Gender', data=df)\n",
        "plt.title('Count of Genders')\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A bar plot showing the count of each gender category.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Working with JSON and HTML Data**\n",
        "\n",
        "* Pandas provides robust functionality for working with JSON and HTML data, allowing you to easily read, manipulate, and analyze data from these formats.\n",
        "\n",
        "### Working with JSON Data\n",
        "\n",
        "#### 1. Importing JSON Data\n",
        "• **Definition**: JSON (JavaScript Object Notation) is a lightweight data interchange format that is easy to read and write for humans and machines.\n",
        "• **Method**:\n",
        "  - Use `pd.read_json()` to read JSON data into a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample JSON data as a string\n",
        "json_data = '''\n",
        "[\n",
        "    {\"Name\": \"Alice\", \"Age\": 24, \"City\": \"New York\"},\n",
        "    {\"Name\": \"Bob\", \"Age\": 30, \"City\": \"Los Angeles\"},\n",
        "    {\"Name\": \"Charlie\", \"Age\": 22, \"City\": \"Chicago\"}\n",
        "]\n",
        "'''\n",
        "\n",
        "# Importing JSON data\n",
        "df_json = pd.read_json(json_data)\n",
        "print(df_json)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "0    Alice   24     New York\n",
        "1      Bob   30  Los Angeles\n",
        "2  Charlie   22      Chicago\n",
        "```\n",
        "\n",
        "#### 2. Importing JSON from a File\n",
        "• **Definition**: You can also read JSON data from a file.\n",
        "• **Method**:\n",
        "  - Use `pd.read_json()` with a file path.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Assuming 'data.json' contains valid JSON data\n",
        "df_json_file = pd.read_json('data.json')\n",
        "print(df_json_file)\n",
        "```\n",
        "\n",
        "#### 3. Exporting Data to JSON\n",
        "• **Definition**: You can save a DataFrame to a JSON file.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_json()` to export DataFrames to JSON format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Exporting DataFrame to a JSON file\n",
        "df_json.to_json('output.json', orient='records', lines=True)\n",
        "```\n",
        "\n",
        "### Working with HTML Data\n",
        "\n",
        "#### 1. Importing HTML Data\n",
        "• **Definition**: HTML (HyperText Markup Language) is the standard markup language for documents designed to be displayed in a web browser. Pandas can read tables from HTML pages.\n",
        "• **Method**:\n",
        "  - Use `pd.read_html()` to read HTML tables into a list of DataFrames.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing HTML data from a URL\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\n",
        "dfs = pd.read_html(url)\n",
        "\n",
        "# Displaying the first DataFrame (the first table on the page)\n",
        "df_html = dfs[0]\n",
        "print(df_html.head())\n",
        "```\n",
        "**Output**: The first few rows of the DataFrame containing population data.\n",
        "\n",
        "#### 2. Importing HTML from a Local File\n",
        "• **Definition**: You can also read HTML tables from a local HTML file.\n",
        "• **Method**:\n",
        "  - Use `pd.read_html()` with a file path.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Assuming 'data.html' contains valid HTML tables\n",
        "dfs_local = pd.read_html('data.html')\n",
        "\n",
        "# Displaying the first DataFrame\n",
        "df_html_local = dfs_local[0]\n",
        "print(df_html_local.head())\n",
        "```\n",
        "\n",
        "#### 3. Exporting Data to HTML\n",
        "• **Definition**: You can save a DataFrame to an HTML file.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_html()` to export DataFrames to HTML format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Exporting DataFrame to an HTML file\n",
        "df_json.to_html('output.html', index=False)\n",
        "```\n",
        "\n",
        "### 4. Handling Nested JSON Data\n",
        "• **Definition**: JSON data can often be nested, requiring additional processing to flatten it into a DataFrame.\n",
        "• **Method**:\n",
        "  - Use the `json_normalize()` function from Pandas.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample nested JSON data\n",
        "nested_json = '''\n",
        "[\n",
        "    {\"Name\": \"Alice\", \"Info\": {\"Age\": 24, \"City\": \"New York\"}},\n",
        "    {\"Name\": \"Bob\", \"Info\": {\"Age\": 30, \"City\": \"Los Angeles\"}},\n",
        "    {\"Name\": \"Charlie\", \"Info\": {\"Age\": 22, \"City\": \"Chicago\"}}\n",
        "]\n",
        "'''\n",
        "\n",
        "# Importing nested JSON data\n",
        "data = pd.read_json(nested_json)\n",
        "\n",
        "# Normalizing the nested JSON\n",
        "df_normalized = pd.json_normalize(data.to_dict(orient='records'))\n",
        "print(df_normalized)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Info.Age         Info.City\n",
        "0    Alice       24          New York\n",
        "1      Bob       30      Los Angeles\n",
        "2  Charlie       22          Chicago\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Working with Large Dataset**\n",
        "\n",
        "* Working with large datasets in Pandas can be challenging due to memory constraints and performance issues. However, Pandas provides several techniques and best practices to efficiently handle large datasets.\n",
        "\n",
        "### 1. Reading Large Datasets\n",
        "\n",
        "#### 1.1 Using `chunksize`\n",
        "• **Definition**: When reading large files, you can use the `chunksize` parameter to read the data in smaller chunks, which helps manage memory usage.\n",
        "• **Method**:\n",
        "  - Use `pd.read_csv()` or other read functions with the `chunksize` parameter.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Reading a large CSV file in chunks\n",
        "chunk_size = 10000  # Number of rows per chunk\n",
        "chunks = pd.read_csv('large_data.csv', chunksize=chunk_size)\n",
        "\n",
        "# Processing each chunk\n",
        "for chunk in chunks:\n",
        "    # Perform operations on each chunk\n",
        "    print(chunk.head())\n",
        "```\n",
        "\n",
        "### 2. Optimizing Data Types\n",
        "• **Definition**: Using appropriate data types can significantly reduce memory usage. For example, using `float32` instead of `float64` or `category` for categorical data.\n",
        "• **Method**:\n",
        "  - Use `astype()` to convert data types.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with large numeric values\n",
        "data = {\n",
        "    'A': [1.0, 2.0, 3.0] * 10**6,\n",
        "    'B': ['cat', 'dog', 'bird'] * 10**6\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Optimizing data types\n",
        "df['A'] = df['A'].astype('float32')  # Change to float32\n",
        "df['B'] = df['B'].astype('category')  # Change to category\n",
        "print(df.info(memory_usage='deep'))\n",
        "```\n",
        "\n",
        "### 3. Using `dask` for Out-of-Core Computation\n",
        "• **Definition**: Dask is a parallel computing library that integrates with Pandas and allows you to work with larger-than-memory datasets by breaking them into smaller chunks.\n",
        "• **Method**:\n",
        "  - Use `dask.dataframe` to create a Dask DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Reading a large CSV file with Dask\n",
        "ddf = dd.read_csv('large_data.csv')\n",
        "\n",
        "# Perform operations on Dask DataFrame\n",
        "result = ddf.groupby('column_name').mean().compute()  # Use compute() to get the result\n",
        "print(result)\n",
        "```\n",
        "\n",
        "### 4. Filtering Data Efficiently\n",
        "• **Definition**: When working with large datasets, filtering data efficiently can help reduce the size of the DataFrame and improve performance.\n",
        "• **Method**:\n",
        "  - Use boolean indexing to filter rows.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Filtering rows based on a condition\n",
        "filtered_df = df[df['A'] > 1.5]\n",
        "print(filtered_df)\n",
        "```\n",
        "\n",
        "### 5. Using `query()` for Efficient Filtering\n",
        "• **Definition**: The `query()` method allows for efficient filtering of DataFrames using a query string, which can be faster than traditional boolean indexing.\n",
        "• **Method**:\n",
        "  - Use `query()` to filter rows based on conditions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Using query to filter data\n",
        "filtered_query = df.query('A > 1.5')\n",
        "print(filtered_query)\n",
        "```\n",
        "\n",
        "### 6. Aggregating Data Efficiently\n",
        "• **Definition**: When working with large datasets, aggregating data can help summarize information and reduce the size of the DataFrame.\n",
        "• **Method**:\n",
        "  - Use `groupby()` and aggregation functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Aggregating data\n",
        "aggregated_data = df.groupby('B').mean()\n",
        "print(aggregated_data)\n",
        "```\n",
        "\n",
        "### 7. Writing Large Datasets\n",
        "• **Definition**: When exporting large datasets, you can use the `chunksize` parameter to write data in smaller chunks, which helps manage memory usage.\n",
        "• **Method**:\n",
        "  - Use `to_csv()` or other write functions with the `chunksize` parameter.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Writing a large DataFrame to CSV in chunks\n",
        "df.to_csv('output_large_data.csv', index=False, chunksize=10000)\n",
        "```\n",
        "\n",
        "### 8. Profiling Memory Usage\n",
        "• **Definition**: Profiling memory usage helps identify bottlenecks and optimize performance when working with large datasets.\n",
        "• **Method**:\n",
        "  - Use the `memory_usage()` method to check memory consumption.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Checking memory usage\n",
        "print(df.memory_usage(deep=True))\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **DataFrame Transformations**\n",
        "\n",
        "* DataFrame transformations in Pandas refer to the various methods and techniques used to modify, reshape, or manipulate data within a DataFrame.\n",
        "* These transformations can include operations such as filtering, aggregating, pivoting, melting, and applying functions.\n",
        "\n",
        "### 1. Filtering Data\n",
        "• **Definition**: Filtering allows you to select specific rows from a DataFrame based on certain conditions.\n",
        "• **Method**:\n",
        "  - Use boolean indexing to filter rows.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [24, 30, 22, 35],\n",
        "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Filtering rows where Age is greater than 25\n",
        "filtered_df = df[df['Age'] > 25]\n",
        "print(filtered_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "    Name  Age         City\n",
        "1    Bob   30  Los Angeles\n",
        "3  David   35      Houston\n",
        "```\n",
        "\n",
        "### 2. Adding New Columns\n",
        "• **Definition**: You can add new columns to a DataFrame based on existing data or calculations.\n",
        "• **Method**:\n",
        "  - Assign a new Series or calculation to a new column name.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Adding a new column for age in months\n",
        "df['Age_in_Months'] = df['Age'] * 12\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City  Age_in_Months\n",
        "0    Alice   24     New York             288\n",
        "1      Bob   30  Los Angeles             360\n",
        "2  Charlie   22      Chicago             264\n",
        "3    David   35      Houston             420\n",
        "```\n",
        "\n",
        "### 3. Dropping Columns\n",
        "• **Definition**: You can remove columns from a DataFrame that are no longer needed.\n",
        "• **Method**:\n",
        "  - Use `drop()` to remove specified columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Dropping the 'City' column\n",
        "df_dropped = df.drop(columns=['City'])\n",
        "print(df_dropped)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age  Age_in_Months\n",
        "0    Alice   24             288\n",
        "1      Bob   30             360\n",
        "2  Charlie   22             264\n",
        "3    David   35             420\n",
        "```\n",
        "\n",
        "### 4. Renaming Columns\n",
        "• **Definition**: You can rename columns in a DataFrame for better clarity or consistency.\n",
        "• **Method**:\n",
        "  - Use `rename()` to change column names.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Renaming columns\n",
        "df_renamed = df.rename(columns={'Age': 'Years', 'City': 'Location'})\n",
        "print(df_renamed)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Years     Location  Age_in_Months\n",
        "0    Alice     24     New York             288\n",
        "1      Bob     30  Los Angeles             360\n",
        "2  Charlie     22      Chicago             264\n",
        "3    David     35      Houston             420\n",
        "```\n",
        "\n",
        "### 5. Aggregating Data\n",
        "• **Definition**: Aggregation involves summarizing data, such as calculating the mean, sum, or count for groups of data.\n",
        "• **Method**:\n",
        "  - Use `groupby()` followed by an aggregation function.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Aggregating data by city\n",
        "data_agg = df.groupby('City')['Age'].mean()\n",
        "print(data_agg)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "City\n",
        "Chicago        22.0\n",
        "Houston        35.0\n",
        "Los Angeles    30.0\n",
        "New York       24.0\n",
        "Name: Age, dtype: float64\n",
        "```\n",
        "\n",
        "### 6. Pivoting Data\n",
        "• **Definition**: Pivoting allows you to reshape data by turning unique values from one column into separate columns.\n",
        "• **Method**:\n",
        "  - Use `pivot_table()` to create a pivot table.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame for pivoting\n",
        "data_pivot = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40]\n",
        "}\n",
        "df_pivot = pd.DataFrame(data_pivot)\n",
        "\n",
        "# Creating a pivot table\n",
        "pivot_table = df_pivot.pivot_table(values='Values', index='Date', columns='Category', aggfunc='sum', fill_value=0)\n",
        "print(pivot_table)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category         A   B\n",
        "Date                  \n",
        "2023-01-01     10  20\n",
        "2023-01-02     30  40\n",
        "```\n",
        "\n",
        "### 7. Melting Data\n",
        "• **Definition**: Melting transforms a DataFrame from wide format to long format, unpivoting the DataFrame.\n",
        "• **Method**:\n",
        "  - Use `melt()` to reshape the DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Melting the pivot table back to long format\n",
        "melted_df = pd.melt(pivot_table.reset_index(), id_vars='Date', value_vars=['A', 'B'])\n",
        "print(melted_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "         Date Category  Values\n",
        "0  2023-01-01        A      10\n",
        "1  2023-01-01        B      20\n",
        "2  2023-01-02        A      30\n",
        "3  2023-01-02        B      40\n",
        "```\n",
        "\n",
        "### 8. Applying Functions\n",
        "• **Definition**: You can apply custom functions to DataFrames or Series using `apply()` or `map()`.\n",
        "• **Method**:\n",
        "  - Use `apply()` for row-wise or column-wise operations.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Applying a function to calculate the square of values in 'Values' column\n",
        "df_pivot['Values_Squared'] = df_pivot['Values'].apply(lambda x: x ** 2)\n",
        "print(df_pivot)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category         A   B  Values_Squared\n",
        "Date                                      \n",
        "2023-01-01     10  20              100\n",
        "2023-01-02     30  40            900\n",
        "```\n",
        "\n",
        "### 9. Sorting Data\n",
        "• **Definition**: You can sort a DataFrame by one or more columns.\n",
        "• **Method**:\n",
        "  - Use `sort_values()` to sort the DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sorting by 'Age'\n",
        "df_sorted = df.sort_values(by='Age', ascending=False)\n",
        "print(df_sorted)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "      Name  Age         City\n",
        "3    David   35      Houston\n",
        "1      Bob   30  Los Angeles\n",
        "0    Alice   24     New York\n",
        "2  Charlie   22      Chicago\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Handling Outliers**\n",
        "\n",
        "Handling outliers in Pandas is an important aspect of data preprocessing and cleaning. Outliers can skew your analysis and lead to misleading results, so it's essential to identify and manage them appropriately. Below are key topics related to handling outliers in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Identifying Outliers\n",
        "• **Definition**: Outliers are data points that differ significantly from other observations. They can be identified using statistical methods such as the Z-score or the Interquartile Range (IQR).\n",
        "• **Method**:\n",
        "  - Use Z-score or IQR to detect outliers.\n",
        "\n",
        "**Example using IQR**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Values': [10, 12, 12, 13, 12, 14, 15, 100, 12, 13, 14, 15]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating IQR\n",
        "Q1 = df['Values'].quantile(0.25)\n",
        "Q3 = df['Values'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Defining bounds for outliers\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identifying outliers\n",
        "outliers = df[(df['Values'] < lower_bound) | (df['Values'] > upper_bound)]\n",
        "print(\"Outliers:\")\n",
        "print(outliers)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Outliers:\n",
        "   Values\n",
        "7     100\n",
        "```\n",
        "\n",
        "### 2. Visualizing Outliers\n",
        "• **Definition**: Visualizing data can help identify outliers more intuitively.\n",
        "• **Method**:\n",
        "  - Use box plots or scatter plots to visualize outliers.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Box plot to visualize outliers\n",
        "sns.boxplot(x=df['Values'])\n",
        "plt.title('Box Plot of Values')\n",
        "plt.show()\n",
        "```\n",
        "**Output**: A box plot showing the distribution of values and highlighting outliers.\n",
        "\n",
        "### 3. Handling Outliers\n",
        "• **Definition**: Once identified, you can handle outliers in several ways, including removal, capping, or transformation.\n",
        "• **Methods**:\n",
        "  - **Removal**: Simply drop the outlier rows.\n",
        "  - **Capping**: Replace outliers with a specified threshold.\n",
        "  - **Transformation**: Apply transformations to reduce the impact of outliers.\n",
        "\n",
        "**Example of Removal**:\n",
        "```python\n",
        "# Removing outliers\n",
        "df_no_outliers = df[(df['Values'] >= lower_bound) & (df['Values'] <= upper_bound)]\n",
        "print(\"DataFrame after removing outliers:\")\n",
        "print(df_no_outliers)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "DataFrame after removing outliers:\n",
        "   Values\n",
        "0      10\n",
        "1      12\n",
        "2      12\n",
        "3      13\n",
        "4      12\n",
        "5      14\n",
        "6      15\n",
        "8      12\n",
        "9      13\n",
        "10     14\n",
        "11     15\n",
        "```\n",
        "\n",
        "**Example of Capping**:\n",
        "```python\n",
        "# Capping outliers\n",
        "df['Capped_Values'] = df['Values'].clip(lower=lower_bound, upper=upper_bound)\n",
        "print(\"DataFrame after capping outliers:\")\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   Values  Capped_Values\n",
        "0      10             10\n",
        "1      12             12\n",
        "2      12             12\n",
        "3      13             13\n",
        "4      12             12\n",
        "5      14             14\n",
        "6      15             15\n",
        "7     100             15\n",
        "8      12             12\n",
        "9      13             13\n",
        "10     14             14\n",
        "11     15             15\n",
        "```\n",
        "\n",
        "### 4. Transforming Data\n",
        "• **Definition**: Applying transformations such as logarithmic or square root transformations can help reduce the impact of outliers.\n",
        "• **Method**:\n",
        "  - Use mathematical transformations to modify the data.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Applying a logarithmic transformation\n",
        "df['Log_Values'] = df['Values'].apply(lambda x: np.log(x) if x > 0 else 0)\n",
        "print(\"DataFrame after logarithmic transformation:\")\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   Values  Log_Values\n",
        "0      10     2.302585\n",
        "1      12     2.484907\n",
        "2      12     2.484907\n",
        "3      13     2.564949\n",
        "4      12     2.484907\n",
        "5      14     2.639057\n",
        "6      15     2.708050\n",
        "7     100     4.605170\n",
        "8      12     2.484907\n",
        "9      13     2.564949\n",
        "10     14     2.639057\n",
        "11     15     2.708050\n",
        "```\n",
        "\n",
        "### 5. Summary Statistics Without Outliers\n",
        "• **Definition**: You can calculate summary statistics while excluding outliers to get a better understanding of the central tendency and dispersion of the data.\n",
        "• **Method**:\n",
        "  - Use the `describe()` method on the DataFrame without outliers.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Summary statistics without outliers\n",
        "summary_stats = df_no_outliers.describe()\n",
        "print(\"Summary statistics without outliers:\")\n",
        "print(summary_stats)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "       Values\n",
        "count  10.000000\n",
        "mean   12.800000\n",
        "std     1.516575\n",
        "min    10.000000\n",
        "25%    12.000000\n",
        "50%    12.500000\n",
        "75%    13.500000\n",
        "max    15.000000\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Pivot and Unpivot Data**\n",
        "\n",
        "* Pivoting and unpivoting (or melting) data in Pandas are essential techniques for reshaping data to facilitate analysis and visualization.\n",
        "* These operations allow you to transform data from a wide format to a long format and vice versa.\n",
        "\n",
        "### 1. Pivoting Data\n",
        "• **Definition**: Pivoting transforms a DataFrame from a long format to a wide format by turning unique values from one column into separate columns.\n",
        "• **Method**:\n",
        "  - Use `pivot()` or `pivot_table()` to create a pivot table.\n",
        "\n",
        "#### 1.1 Using `pivot()`\n",
        "• **Definition**: The `pivot()` method is used to reshape data based on unique values from specified columns.\n",
        "• **Method**:\n",
        "  - `DataFrame.pivot(index, columns, values)`: Reshapes the DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table\n",
        "pivot_table = df.pivot(index='Date', columns='Category', values='Values')\n",
        "print(pivot_table)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category         A   B\n",
        "Date                  \n",
        "2023-01-01     10  20\n",
        "2023-01-02     30  40\n",
        "```\n",
        "\n",
        "#### 1.2 Using `pivot_table()`\n",
        "• **Definition**: The `pivot_table()` method is more flexible than `pivot()` and allows for aggregation of values.\n",
        "• **Method**:\n",
        "  - `DataFrame.pivot_table(index, columns, values, aggfunc)`: Creates a pivot table with aggregation.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with duplicate entries\n",
        "data = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Values': [10, 20, 30, 40]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table with aggregation\n",
        "pivot_table_agg = df.pivot_table(index='Date', columns='Category', values='Values', aggfunc='sum', fill_value=0)\n",
        "print(pivot_table_agg)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Category         A   B\n",
        "Date                  \n",
        "2023-01-01     10  20\n",
        "2023-01-02     30  40\n",
        "```\n",
        "\n",
        "### 2. Unpivoting Data (Melting)\n",
        "• **Definition**: Unpivoting (or melting) transforms a DataFrame from a wide format to a long format by turning columns into rows.\n",
        "• **Method**:\n",
        "  - Use `melt()` to reshape the DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample pivot table DataFrame\n",
        "pivot_data = {\n",
        "    'Date': ['2023-01-01', '2023-01-02'],\n",
        "    'A': [10, 30],\n",
        "    'B': [20, 40]\n",
        "}\n",
        "df_pivot = pd.DataFrame(pivot_data)\n",
        "\n",
        "# Melting the DataFrame back to long format\n",
        "melted_df = pd.melt(df_pivot, id_vars='Date', value_vars=['A', 'B'], var_name='Category', value_name='Values')\n",
        "print(melted_df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "         Date Category  Values\n",
        "0  2023-01-01        A      10\n",
        "1  2023-01-02        A      30\n",
        "2  2023-01-01        B      20\n",
        "3  2023-01-02        B      40\n",
        "```\n",
        "\n",
        "### 3. Using `melt()` with Additional Parameters\n",
        "• **Definition**: You can specify additional parameters in `melt()` to customize the transformation.\n",
        "• **Method**:\n",
        "  - Use `var_name` and `value_name` to rename the resulting columns.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Melting with custom column names\n",
        "melted_custom = pd.melt(df_pivot, id_vars='Date', var_name='Category', value_name='Value')\n",
        "print(melted_custom)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "         Date Category  Value\n",
        "0  2023-01-01        A     10\n",
        "1  2023-01-02        A     30\n",
        "2  2023-01-01        B     20\n",
        "3  2023-01-02        B     40\n",
        "```\n",
        "\n",
        "### 4. Pivoting with Multiple Indexes\n",
        "• **Definition**: You can create a pivot table with multiple index levels for more complex data structures.\n",
        "• **Method**:\n",
        "  - Use lists for the `index` parameter in `pivot_table()`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Sample DataFrame with multiple categories\n",
        "data_multi = {\n",
        "    'Date': ['2023-01-01', '2023-01-01', '2023-01-02', '2023-01-02'],\n",
        "    'Category': ['A', 'B', 'A', 'B'],\n",
        "    'Subcategory': ['X', 'Y', 'X', 'Y'],\n",
        "    'Values': [10, 20, 30, 40]\n",
        "}\n",
        "df_multi = pd.DataFrame(data_multi)\n",
        "\n",
        "# Creating a pivot table with multiple indexes\n",
        "pivot_multi = df_multi.pivot_table(index=['Date', 'Category'], columns='Subcategory', values='Values', aggfunc='sum', fill_value=0)\n",
        "print(pivot_multi)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Subcategory              X   Y\n",
        "Date       Category          \n",
        "2023-01-01 A         10   0\n",
        "           B          0  20\n",
        "2023-01-02 A         30   0\n",
        "           B          0  40\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Time Zone Handling**\n",
        "\n",
        "Handling time zones in Pandas is crucial for working with time series data that spans multiple time zones or requires accurate time representation. Pandas provides robust functionality for localizing, converting, and manipulating time zone-aware datetime objects. Below are key topics related to time zone handling in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Creating Time Zone-Aware Datetime Objects\n",
        "• **Definition**: You can create datetime objects that are aware of time zones using the `pd.to_datetime()` function or by localizing naive datetime objects.\n",
        "• **Method**:\n",
        "  - Use `pd.to_datetime()` with the `utc` parameter or `tz_localize()` to set a time zone.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a naive datetime object\n",
        "naive_datetime = pd.to_datetime('2023-01-01 12:00:00')\n",
        "print(\"Naive datetime:\", naive_datetime)\n",
        "\n",
        "# Localizing to UTC\n",
        "utc_datetime = naive_datetime.tz_localize('UTC')\n",
        "print(\"UTC datetime:\", utc_datetime)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Naive datetime: 2023-01-01 12:00:00\n",
        "UTC datetime: 2023-01-01 12:00:00+00:00\n",
        "```\n",
        "\n",
        "### 2. Converting Time Zones\n",
        "• **Definition**: You can convert time zone-aware datetime objects from one time zone to another using the `tz_convert()` method.\n",
        "• **Method**:\n",
        "  - Use `tz_convert()` to change the time zone of a datetime object.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Converting UTC to Eastern Time (US)\n",
        "eastern_datetime = utc_datetime.tz_convert('America/New_York')\n",
        "print(\"Eastern Time:\", eastern_datetime)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Eastern Time: 2023-01-01 07:00:00-05:00\n",
        "```\n",
        "\n",
        "### 3. Creating Time Series with Time Zones\n",
        "• **Definition**: You can create a time series with a specific time zone using `pd.date_range()` and the `tz` parameter.\n",
        "• **Method**:\n",
        "  - Use `pd.date_range()` with the `tz` parameter to create a time series.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a time series with a specific time zone\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D', tz='UTC')\n",
        "print(date_rng)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "DatetimeIndex(['2023-01-01 00:00:00+00:00', '2023-01-02 00:00:00+00:00',\n",
        "               '2023-01-03 00:00:00+00:00', '2023-01-04 00:00:00+00:00',\n",
        "               '2023-01-05 00:00:00+00:00', '2023-01-06 00:00:00+00:00',\n",
        "               '2023-01-07 00:00:00+00:00', '2023-01-08 00:00:00+00:00',\n",
        "               '2023-01-09 00:00:00+00:00', '2023-01-10 00:00:00+00:00'],\n",
        "              dtype='datetime64[ns, UTC]', freq='D')\n",
        "```\n",
        "\n",
        "### 4. Handling Daylight Saving Time (DST)\n",
        "• **Definition**: Time zones may have daylight saving time adjustments, which can affect time calculations.\n",
        "• **Method**:\n",
        "  - Use time zone-aware datetime objects to handle DST automatically.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a time series with DST\n",
        "date_rng_dst = pd.date_range(start='2023-03-01', end='2023-03-15', freq='D', tz='America/New_York')\n",
        "print(date_rng_dst)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "DatetimeIndex(['2023-03-01 00:00:00-05:00', '2023-03-02 00:00:00-05:00',\n",
        "               '2023-03-03 00:00:00-05:00', '2023-03-04 00:00:00-05:00',\n",
        "               '2023-03-05 00:00:00-05:00', '2023-03-06 00:00:00-05:00',\n",
        "               '2023-03-07 00:00:00-05:00', '2023-03-08 00:00:00-05:00',\n",
        "               '2023-03-09 00:00:00-05:00', '2023-03-10 00:00:00-05:00',\n",
        "               '2023-03-11 00:00:00-05:00', '2023-03-12 00:00:00-04:00',\n",
        "               '2023-03-13 00:00:00-04:00', '2023-03-14 00:00:00-04:00',\n",
        "               '2023-03-15 00:00:00-04:00'],\n",
        "              dtype='datetime64[ns, America/New_York]', freq='D')\n",
        "```\n",
        "\n",
        "### 5. Converting Between Time Zones\n",
        "• **Definition**: You can convert a time series from one time zone to another while preserving the local time.\n",
        "• **Method**:\n",
        "  - Use `tz_convert()` to change the time zone.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Converting from Eastern Time to Pacific Time\n",
        "pacific_time = date_rng_dst.tz_convert('America/Los_Angeles')\n",
        "print(pacific_time)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "DatetimeIndex(['2023-02-28 22:00:00-08:00', '2023-03-01 22:00:00-08:00',\n",
        "               '2023-03-02 22:00:00-08:00', '2023-03-03 22:00:00-08:00',\n",
        "               '2023-03-04 22:00:00-08:00', '2023-03-05 22:00:00-08:00',\n",
        "               '2023-03-06 22:00:00-08:00', '2023-03-07 22:00:00-08:00',\n",
        "               '2023-03-08 22:00:00-08:00', '2023-03-09 22:00:00-08:00',\n",
        "               '2023-03-10 22:00:00-08:00', '2023-03-11 22:00:00-07:00',\n",
        "               '2023-03-12 22:00:00-07:00', '2023-03-13 22:00:00-07:00',\n",
        "               '2023-03-14 22:00:00-07:00'],\n",
        "              dtype='datetime64[ns, America/Los_Angeles]', freq='D')\n",
        "```\n",
        "\n",
        "### 6. Localizing Naive Datetime Objects\n",
        "• **Definition**: You can convert naive datetime objects (without time zone information) to time zone-aware datetime objects.\n",
        "• **Method**:\n",
        "  - Use `tz_localize()` to set the time zone.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a naive datetime object\n",
        "naive_datetime = pd.to_datetime('2023-01-01 12:00:00')\n",
        "\n",
        "# Localizing to a specific time zone\n",
        "localized_datetime = naive_datetime.tz_localize('UTC')\n",
        "print(localized_datetime)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "2023-01-01 12:00:00+00:00\n",
        "```\n",
        "\n",
        "### 7. Handling Time Zone-Aware DataFrames\n",
        "• **Definition**: You can create DataFrames with time zone-aware datetime indices, allowing for easier manipulation of time series data.\n",
        "• **Method**:\n",
        "  - Use `pd.date_range()` with the `tz` parameter to create a time zone-aware index.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a DataFrame with a time zone-aware index\n",
        "date_rng = pd.date_range(start='2023-01-01', end='2023-01-10', freq='D', tz='UTC')\n",
        "df_time_zone = pd.DataFrame({'data': range(len(date_rng))}, index=date_rng)\n",
        "print(df_time_zone)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "                     data\n",
        "2023-01-01 00:00:00+00:00     0\n",
        "2023-01-02 00:00:00+00:00     1\n",
        "2023-01-03 00:00:00+00:00     2\n",
        "2023-01-04 00:00:00+00:00     3\n",
        "2023-01-05 00:00:00+00:00     4\n",
        "2023-01-06 00:00:00+00:00     5\n",
        "2023-01-07 00:00:00+00:00     6\n",
        "2023-01-08 00:00:00+00:00     7\n",
        "2023-01-09 00:00:00+00:00     8\n",
        "2023-01-10 00:00:00+00:00     9\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Sparse Data structures**\n",
        "\n",
        "Sparse data structures in Pandas are designed to efficiently store and manipulate data that contains a significant number of missing or zero values. This is particularly useful in scenarios where memory efficiency is crucial, such as in large datasets with many missing entries. Pandas provides the `SparseDataFrame` and `SparseSeries` classes to handle such data. Below are key topics related to sparse data structures in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Introduction to Sparse Data\n",
        "• **Definition**: Sparse data refers to datasets where most of the elements are zero or missing. Storing such data in a dense format can lead to inefficient memory usage.\n",
        "• **Use Cases**: Sparse data structures are commonly used in fields like natural language processing (NLP), recommendation systems, and any domain where data is often missing or zero.\n",
        "\n",
        "### 2. Creating Sparse DataFrames\n",
        "• **Definition**: You can create a sparse DataFrame using the `pd.SparseDataFrame` class or by specifying the `sparse=True` parameter when creating a DataFrame.\n",
        "• **Method**:\n",
        "  - Use `pd.SparseDataFrame()` or `pd.DataFrame()` with `sparse=True`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Creating a dense DataFrame\n",
        "data = {\n",
        "    'A': [1, 0, 0, 4],\n",
        "    'B': [0, 0, 3, 0],\n",
        "    'C': [0, 2, 0, 0]\n",
        "}\n",
        "df_dense = pd.DataFrame(data)\n",
        "\n",
        "# Creating a Sparse DataFrame\n",
        "df_sparse = pd.DataFrame(data, dtype='Sparse[int]')\n",
        "print(df_sparse)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A     B     C\n",
        "0  1.0   NaN   NaN\n",
        "1  NaN   NaN   2.0\n",
        "2  NaN   3.0   NaN\n",
        "3  4.0   NaN   NaN\n",
        "```\n",
        "\n",
        "### 3. Working with Sparse DataFrames\n",
        "• **Definition**: Sparse DataFrames allow you to perform standard DataFrame operations while efficiently managing memory.\n",
        "• **Method**:\n",
        "  - Use standard DataFrame methods on sparse DataFrames.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Performing operations on Sparse DataFrame\n",
        "df_sparse['D'] = df_sparse['A'] + df_sparse['B']\n",
        "print(df_sparse)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A     B     C    D\n",
        "0  1.0   NaN   NaN  1.0\n",
        "1  NaN   NaN   2.0  NaN\n",
        "2  NaN   3.0   NaN  3.0\n",
        "3  4.0   NaN   NaN  4.0\n",
        "```\n",
        "\n",
        "### 4. Converting to Sparse Format\n",
        "• **Definition**: You can convert an existing dense DataFrame to a sparse format using the `to_sparse()` method.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_sparse()` to convert to a sparse DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Converting a dense DataFrame to sparse\n",
        "df_dense_sparse = df_dense.astype('Sparse[int]')\n",
        "print(df_dense_sparse)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "     A     B     C\n",
        "0  1.0   NaN   NaN\n",
        "1  NaN   NaN   NaN\n",
        "2  NaN   3.0   NaN\n",
        "3  4.0   NaN   NaN\n",
        "```\n",
        "\n",
        "### 5. Sparse Series\n",
        "• **Definition**: Similar to Sparse DataFrames, you can create Sparse Series to handle one-dimensional sparse data.\n",
        "• **Method**:\n",
        "  - Use `pd.Series()` with `dtype='Sparse'`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Creating a Sparse Series\n",
        "sparse_series = pd.Series([1, 0, 0, 4], dtype='Sparse[int]')\n",
        "print(sparse_series)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "0    1\n",
        "1    NaN\n",
        "2    NaN\n",
        "3    4\n",
        "dtype: Sparse[int64, 0]\n",
        "```\n",
        "\n",
        "### 6. Memory Usage of Sparse DataFrames\n",
        "• **Definition**: Sparse DataFrames can significantly reduce memory usage compared to dense DataFrames, especially when dealing with large datasets with many missing values.\n",
        "• **Method**:\n",
        "  - Use `memory_usage()` to compare memory usage.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Checking memory usage\n",
        "print(\"Dense DataFrame memory usage:\")\n",
        "print(df_dense.memory_usage(deep=True))\n",
        "\n",
        "print(\"Sparse DataFrame memory usage:\")\n",
        "print(df_sparse.memory_usage(deep=True))\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "Dense DataFrame memory usage:\n",
        "Index    128\n",
        "A       32\n",
        "B       32\n",
        "C       32\n",
        "dtype: int64\n",
        "Sparse DataFrame memory usage:\n",
        "Index    128\n",
        "A       32\n",
        "B       32\n",
        "C       32\n",
        "D       32\n",
        "dtype: int64\n",
        "```\n",
        "\n",
        "### 7. Performance Considerations\n",
        "• **Definition**: While sparse data structures can save memory, they may have performance trade-offs for certain operations compared to dense structures.\n",
        "• **Method**:\n",
        "  - Use sparse structures when you have a significant number of missing values, but be aware of potential performance impacts.\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Advanced Input/Output Functions**\n",
        "\n",
        "Pandas provides a variety of advanced input/output (I/O) functions that allow you to read from and write to different file formats and data sources. These functions enable you to work with structured data efficiently, whether it's from local files, databases, or web sources. Below are key topics related to advanced I/O functions in Pandas, along with definitions, use cases, and examples.\n",
        "\n",
        "### 1. Reading and Writing CSV Files\n",
        "\n",
        "#### 1.1 Reading CSV Files with Options\n",
        "• **Definition**: You can read CSV files with various options to handle different formats and delimiters.\n",
        "• **Method**:\n",
        "  - Use `pd.read_csv()` with parameters like `sep`, `header`, `na_values`, and `dtype`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "# Reading a CSV file with custom options\n",
        "df_csv = pd.read_csv('data.csv', sep=',', header=0, na_values=['NA', 'N/A'], dtype={'column_name': 'float64'})\n",
        "print(df_csv.head())\n",
        "```\n",
        "\n",
        "#### 1.2 Writing CSV Files with Options\n",
        "• **Definition**: You can write DataFrames to CSV files with options to customize the output format.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_csv()` with parameters like `index`, `header`, and `na_rep`.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Writing DataFrame to a CSV file\n",
        "df_csv.to_csv('output.csv', index=False, header=True, na_rep='Missing')\n",
        "```\n",
        "\n",
        "### 2. Reading and Writing Excel Files\n",
        "\n",
        "#### 2.1 Reading Excel Files\n",
        "• **Definition**: You can read Excel files with multiple sheets and specify which sheet to read.\n",
        "• **Method**:\n",
        "  - Use `pd.read_excel()` with the `sheet_name` parameter.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Reading an Excel file\n",
        "df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
        "print(df_excel.head())\n",
        "```\n",
        "\n",
        "#### 2.2 Writing Excel Files\n",
        "• **Definition**: You can write DataFrames to Excel files, including multiple sheets.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_excel()` with the `sheet_name` parameter.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Writing DataFrame to an Excel file\n",
        "df_excel.to_excel('output.xlsx', sheet_name='Sheet1', index=False)\n",
        "```\n",
        "\n",
        "### 3. Reading and Writing JSON Files\n",
        "\n",
        "#### 3.1 Reading JSON Files\n",
        "• **Definition**: You can read JSON files into a DataFrame, handling nested structures if necessary.\n",
        "• **Method**:\n",
        "  - Use `pd.read_json()` with parameters to specify the format.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Reading a JSON file\n",
        "df_json = pd.read_json('data.json')\n",
        "print(df_json.head())\n",
        "```\n",
        "\n",
        "#### 3.2 Writing JSON Files\n",
        "• **Definition**: You can write DataFrames to JSON format, specifying the orientation.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_json()` with the `orient` parameter.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Writing DataFrame to a JSON file\n",
        "df_json.to_json('output.json', orient='records', lines=True)\n",
        "```\n",
        "\n",
        "### 4. Reading and Writing SQL Databases\n",
        "\n",
        "#### 4.1 Reading from SQL Databases\n",
        "• **Definition**: You can read data from SQL databases using SQL queries.\n",
        "• **Method**:\n",
        "  - Use `pd.read_sql()` to execute a query and return a DataFrame.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import sqlite3\n",
        "\n",
        "# Connecting to a SQLite database\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Reading data from a SQL table\n",
        "df_sql = pd.read_sql('SELECT * FROM table_name', conn)\n",
        "print(df_sql.head())\n",
        "\n",
        "# Closing the connection\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "#### 4.2 Writing to SQL Databases\n",
        "• **Definition**: You can write DataFrames to SQL tables.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_sql()` to write data to a specified table.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Connecting to a SQLite database\n",
        "conn = sqlite3.connect('database.db')\n",
        "\n",
        "# Writing DataFrame to a SQL table\n",
        "df_sql.to_sql('table_name', conn, if_exists='replace', index=False)\n",
        "\n",
        "# Closing the connection\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "### 5. Reading and Writing HTML Data\n",
        "\n",
        "#### 5.1 Reading HTML Tables\n",
        "• **Definition**: You can read tables from HTML pages into DataFrames.\n",
        "• **Method**:\n",
        "  - Use `pd.read_html()` to extract tables from HTML.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Reading HTML tables from a URL\n",
        "url = 'https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population'\n",
        "dfs = pd.read_html(url)\n",
        "\n",
        "# Displaying the first DataFrame (the first table on the page)\n",
        "df_html = dfs[0]\n",
        "print(df_html.head())\n",
        "```\n",
        "\n",
        "#### 5.2 Writing DataFrames to HTML\n",
        "• **Definition**: You can write DataFrames to HTML format.\n",
        "• **Method**:\n",
        "  - Use `DataFrame.to_html()` to export DataFrames to HTML.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Writing DataFrame to an HTML file\n",
        "df_html.to_html('output.html', index=False)\n",
        "```\n",
        "\n",
        "### 6. Handling Compression\n",
        "• **Definition**: You can read and write compressed files (e.g., gzip, zip) directly using Pandas.\n",
        "• **Method**:\n",
        "  - Use the `compression` parameter in read/write functions.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Reading a compressed CSV file\n",
        "df_compressed = pd.read_csv('data.csv.gz', compression='gzip')\n",
        "print(df_compressed.head())\n",
        "\n",
        "# Writing a DataFrame to a compressed CSV file\n",
        "df_compressed.to_csv('output.csv.gz', index=False, compression='gzip')\n",
        "```\n",
        "\n",
        "### 7. Handling File Paths\n",
        "• **Definition**: When importing or exporting files, you can specify relative or absolute file paths.\n",
        "• **Method**:\n",
        "  - Use appropriate file paths based on your working directory.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Importing from a relative path\n",
        "df_relative = pd.read_csv('./data/data.csv')\n",
        "\n",
        "# Exporting to an absolute path\n",
        "df_relative.to_csv('/Users/username/Documents/output.csv', index=False)\n",
        "```\n",
        "\n",
        "---\n",
        "---\n",
        "---\n",
        "\n",
        "### **Parallel Processing**\n",
        "\n",
        "* Parallel processing in Pandas can significantly enhance performance when working with large datasets by utilizing multiple CPU cores to perform computations concurrently. While Pandas itself does not natively support parallel processing, there are several techniques and libraries that can be used to achieve parallelism.\n",
        "\n",
        "### 1. Using Dask for Parallel Processing\n",
        "• **Definition**: Dask is a flexible parallel computing library for analytics that integrates seamlessly with Pandas. It allows you to work with larger-than-memory datasets and perform computations in parallel.\n",
        "• **Method**:\n",
        "  - Use `dask.dataframe` to create Dask DataFrames that mimic Pandas DataFrames but operate in parallel.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# Creating a Dask DataFrame from a CSV file\n",
        "ddf = dd.read_csv('large_data.csv')\n",
        "\n",
        "# Performing operations on Dask DataFrame\n",
        "result = ddf.groupby('column_name').mean().compute()  # Use compute() to get the result\n",
        "print(result)\n",
        "```\n",
        "\n",
        "### 2. Using Joblib for Parallel Processing\n",
        "• **Definition**: Joblib is a library that provides tools for lightweight pipelining in Python. It can be used to parallelize operations using the `Parallel` and `delayed` functions.\n",
        "• **Method**:\n",
        "  - Use `joblib.Parallel` to execute functions in parallel.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "from joblib import Parallel, delayed\n",
        "import pandas as pd\n",
        "\n",
        "# Sample function to apply\n",
        "def process_row(row):\n",
        "    return row['A'] * 2  # Example operation\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Using Joblib to process rows in parallel\n",
        "results = Parallel(n_jobs=-1)(delayed(process_row)(row) for index, row in df.iterrows())\n",
        "df['Processed'] = results\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   A   B  Processed\n",
        "0  1  10          2\n",
        "1  2  20          4\n",
        "2  3  30          6\n",
        "3  4  40          8\n",
        "4  5  50         10\n",
        "```\n",
        "\n",
        "### 3. Using Multiprocessing\n",
        "• **Definition**: The `multiprocessing` module in Python allows you to create multiple processes, each running in its own Python interpreter. This can be used to parallelize operations on DataFrames.\n",
        "• **Method**:\n",
        "  - Use `multiprocessing.Pool` to distribute tasks across multiple processes.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "import pandas as pd\n",
        "from multiprocessing import Pool\n",
        "\n",
        "# Sample function to apply\n",
        "def process_row(row):\n",
        "    return row['A'] * 2  # Example operation\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Using multiprocessing to process rows in parallel\n",
        "with Pool(processes=4) as pool:\n",
        "    results = pool.map(process_row, [row for index, row in df.iterrows()])\n",
        "\n",
        "df['Processed'] = results\n",
        "print(df)\n",
        "```\n",
        "**Output**:\n",
        "```\n",
        "   A   B  Processed\n",
        "0  1  10          2\n",
        "1  2  20          4\n",
        "2  3  30          6\n",
        "3  4  40          8\n",
        "4  5  50         10\n",
        "```\n",
        "\n",
        "### 4. Using Modin for Parallel DataFrame Operations\n",
        "• **Definition**: Modin is a library that provides a drop-in replacement for Pandas, allowing you to speed up your Pandas operations by using all available CPU cores.\n",
        "• **Method**:\n",
        "  - Install Modin and use it as a replacement for Pandas.\n",
        "\n",
        "**Example**:\n",
        "```python\n",
        "# Install Modin using pip\n",
        "# !pip install modin[ray]  # Uncomment to install\n",
        "\n",
        "import modin.pandas as mpd\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [10, 20, 30, 40, 50]\n",
        "}\n",
        "df_modin = mpd.DataFrame(data)\n",
        "\n",
        "# Performing operations in parallel\n",
        "df_modin['Processed'] = df_modin['A'] * 2\n",
        "print(df_modin)\n",
        "```\n",
        "\n",
        "### 5. Performance Considerations\n",
        "• **Definition**: While parallel processing can significantly speed up computations, it may introduce overhead due to process management and data serialization. It's important to assess whether the performance gain justifies the overhead.\n",
        "• **Method**:\n",
        "  - Use profiling tools to measure performance and identify bottlenecks.\n",
        "\n",
        "---\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "l7G_4V9LZ5vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n"
      ],
      "metadata": {
        "id": "wR2q1Njw9WOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B2z0dt0t3GwQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}