{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.1. Vectorized operation time: 0.00326 seconds\n",
      "\n",
      "2.1. (Corrected) Vectorized operation time: 0.00305 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/hhtzrw4n6kl1cymh7srrsy1c0000gn/T/ipykernel_34741/976495924.py:32: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n",
      "/var/folders/5l/hhtzrw4n6kl1cymh7srrsy1c0000gn/T/ipykernel_34741/976495924.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n",
      "/var/folders/5l/hhtzrw4n6kl1cymh7srrsy1c0000gn/T/ipykernel_34741/976495924.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '1.231824243072145' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.1. Non-vectorized operation time: 5.70325 seconds\n",
      "\n",
      "3.1. NumPy operation time: 0.00217 seconds\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   A       1000000 non-null  float64\n",
      " 1   B       1000000 non-null  float64\n",
      " 2   C       1000000 non-null  float64\n",
      " 3   D       1000000 non-null  float64\n",
      " 4   E       1000000 non-null  float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 38.1 MB\n",
      "\n",
      "4.1. Memory usage before optimization:\n",
      " None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   A       1000000 non-null  float32\n",
      " 1   B       1000000 non-null  float32\n",
      " 2   C       1000000 non-null  float32\n",
      " 3   D       1000000 non-null  float32\n",
      " 4   E       1000000 non-null  float32\n",
      "dtypes: float32(5)\n",
      "memory usage: 19.1 MB\n",
      "\n",
      "4.1. Memory usage after optimization:\n",
      " None\n",
      "\n",
      "5.1. Query operation time: 0.01230 seconds\n",
      "\n",
      "6.1. Apply operation time: 0.11001 seconds\n",
      "\n",
      "7.1. Profiling example (run from command line with line_profiler):\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 1. Vectorization\n",
    "# 1.1. Built-in Pandas functions and operations\n",
    "n = 10**6  # 1 million rows\n",
    "df = pd.DataFrame({\n",
    "    'A': np.random.rand(n),\n",
    "    'B': np.random.rand(n)\n",
    "})\n",
    "\n",
    "start_time = time.time()\n",
    "df['C'] = df['A'] + df['B']  # Vectorized addition\n",
    "end_time = time.time()\n",
    "print(f\"\\n1.1. Vectorized operation time: {end_time - start_time:.5f} seconds\")\n",
    "# Expected Output: The time taken for the vectorized operation will be printed.\n",
    "\n",
    "# 2. Avoiding Loops\n",
    "# 2.1. Pandas built-in functions and methods\n",
    "start_time = time.time()\n",
    "# df['D'] = 0  # Initialize outside the loop if needed, but not necessary for just timing\n",
    "# for i in range(len(df)): # This is slow, avoid!\n",
    "#     df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n",
    "df['D'] = df['A'] * 2 # Vectorized approach, much faster\n",
    "end_time = time.time()\n",
    "print(f\"\\n2.1. (Corrected) Vectorized operation time: {end_time - start_time:.5f} seconds\")  # Corrected to reflect vectorized time\n",
    "\n",
    "start_time = time.time()\n",
    "df['D'] = 0  # Initialize outside the loop if needed, but not necessary for just timing\n",
    "for i in range(len(df)): # This is slow, avoid!\n",
    "    df['D'][i] = df['A'][i] * 2  # Non-vectorized multiplication\n",
    "end_time = time.time()\n",
    "print(f\"\\n2.1. Non-vectorized operation time: {end_time - start_time:.5f} seconds\")\n",
    "# Expected Output: The time taken for the non-vectorized operation will be printed, and it will be significantly longer than the vectorized operation.\n",
    "\n",
    "# 3. Using NumPy for Performance\n",
    "# 3.1. Converting to NumPy arrays\n",
    "start_time = time.time()\n",
    "array_A = df['A'].to_numpy()\n",
    "array_B = df['B'].to_numpy()\n",
    "df['E'] = array_A * array_B  # Using NumPy for element-wise multiplication\n",
    "end_time = time.time()\n",
    "print(f\"\\n3.1. NumPy operation time: {end_time - start_time:.5f} seconds\")\n",
    "# Expected Output: The time taken for the NumPy operation will be printed.\n",
    "\n",
    "# 4. Memory Usage Optimization\n",
    "# 4.1. Appropriate data types\n",
    "print(\"\\n4.1. Memory usage before optimization:\\n\", df.info(memory_usage='deep'))\n",
    "# Expected Output: The memory usage before optimization will be printed.\n",
    "\n",
    "df['A'] = df['A'].astype('float32')  # Change to float32\n",
    "df['B'] = df['B'].astype('float32')  # Change to float32\n",
    "df['C'] = df['C'].astype('float32')  # Change to float32\n",
    "df['D'] = df['D'].astype('float32')  # Change to float32\n",
    "df['E'] = df['E'].astype('float32')  # Change to float32\n",
    "\n",
    "\n",
    "print(\"\\n4.1. Memory usage after optimization:\\n\", df.info(memory_usage='deep'))\n",
    "# Expected Output: The memory usage after optimization will be printed, showing a reduction in memory consumption.\n",
    "\n",
    "# 5. Using query() for Filtering\n",
    "# 5.1. query() method\n",
    "start_time = time.time()\n",
    "filtered_df = df.query('A > 0.5 and B < 0.5')\n",
    "end_time = time.time()\n",
    "print(f\"\\n5.1. Query operation time: {end_time - start_time:.5f} seconds\")\n",
    "# Expected Output: The time taken for the query operation will be printed.\n",
    "\n",
    "# 6. Using apply() Efficiently\n",
    "# 6.1. apply() method\n",
    "start_time = time.time()\n",
    "df['F'] = df['A'].apply(lambda x: x * 2)  # Using apply\n",
    "end_time = time.time()\n",
    "print(f\"\\n6.1. Apply operation time: {end_time - start_time:.5f} seconds\")\n",
    "# Expected Output: The time taken for the apply operation will be printed, and it will be longer than the vectorized operations.\n",
    "\n",
    "# 7. Profiling and Benchmarking\n",
    "# 7.1. line_profiler, memory_profiler (Example with line_profiler - install with: pip install line_profiler)\n",
    "# To use line_profiler:\n",
    "# 1. Decorate the function you want to profile with @profile (you'll need to enable the line_profiler extension in your environment).\n",
    "# 2. Save the code as a .py file (e.g., performance_test.py).\n",
    "# 3. Run it from the command line using: kernprof -l -v performance_test.py  (This creates a performance_test.lprof file)\n",
    "# 4. Then view the results with: python -m line_profiler performance_test.py.lprof\n",
    "\n",
    "# @profile  # Uncomment to profile. Make sure to install line_profiler\n",
    "def example_function():\n",
    "    df['G'] = df['A'] + df['B']  # Example operation\n",
    "    df['H'] = df['A'] * df['B']\n",
    "\n",
    "# example_function() # Uncomment to run the function for profiling\n",
    "\n",
    "print(\"\\n7.1. Profiling example (run from command line with line_profiler):\\n\") # Note on how to run it\n",
    "# Expected Output: Profiling results will show the time taken for each line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnPoolWorker-26:\n",
      "Process SpawnPoolWorker-29:\n",
      "Process SpawnPoolWorker-28:\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_row' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "AttributeError: Can't get attribute 'process_row' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_row' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_row' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "           ^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/multiprocessing/queues.py\", line 389, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'process_row' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pool:  \u001b[38;5;66;03m# You can adjust the number of processes\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(process_row, df\u001b[38;5;241m.\u001b[39miterrows())\n\u001b[1;32m     23\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     25\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m results  \u001b[38;5;66;03m# Assign the results back to the DataFrame\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, mapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def process_row(row_tuple):\n",
    "    index, row = row_tuple\n",
    "    try:\n",
    "        return row['A'] * 2\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing row {index}: {e}\")\n",
    "        return None  # Or some other sentinel value (e.g., np.nan)\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4, 5],\n",
    "    'B': [10, 20, 30, 40, 50]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "start_time = time.time()\n",
    "with Pool(processes=4) as pool:  # You can adjust the number of processes\n",
    "    results = pool.map(process_row, df.iterrows())\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "df['Processed'] = results  # Assign the results back to the DataFrame\n",
    "\n",
    "print(f\"\\nMultiprocessing operation time: {end_time - start_time:.5f} seconds\")\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Example with a larger DataFrame to demonstrate performance improvement:\n",
    "import numpy as np\n",
    "\n",
    "n = 100000  # Example size; adjust as needed\n",
    "df_large = pd.DataFrame({'A': np.random.rand(n), 'B': np.random.rand(n)})\n",
    "\n",
    "start_time = time.time()\n",
    "with Pool(processes=4) as pool:\n",
    "    results_large = pool.map(process_row, df_large.iterrows())\n",
    "end_time = time.time()\n",
    "\n",
    "df_large['Processed'] = results_large\n",
    "print(f\"\\nMultiprocessing operation time (large DataFrame): {end_time - start_time:.5f} seconds\")\n",
    "\n",
    "\n",
    "# Example of a vectorized approach (for comparison):\n",
    "start_time_vec = time.time()\n",
    "df_large['Processed_vec'] = df_large['A'] * 2  # Vectorized operation\n",
    "end_time_vec = time.time()\n",
    "\n",
    "print(f\"\\nVectorized operation time (large DataFrame): {end_time_vec - start_time_vec:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
