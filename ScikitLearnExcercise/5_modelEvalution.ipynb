{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Metrics:\n",
      "MAE: 0.0000, MSE: 0.0000, R²: 1.0000\n",
      "Classification Metrics:\n",
      "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1: 1.0000, ROC-AUC: 1.0000\n",
      "Confusion Matrix:\n",
      "[[27  0]\n",
      " [ 0 33]]\n",
      "Clustering Metrics:\n",
      "Silhouette Score: 0.8480, Calinski-Harabasz Score: 5196.2951\n",
      "Best Parameters (GridSearchCV): {'max_depth': 20, 'n_estimators': 10}\n",
      "Best Parameters (RandomizedSearchCV): {'n_estimators': 40, 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN, OPTICS, AgglomerativeClustering\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.datasets import make_blobs, make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, silhouette_score, calinski_harabasz_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Generate sample regression data\n",
    "X_reg, y_reg = make_blobs(n_samples=300, centers=1, cluster_std=1.0, random_state=42)\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train regression model\n",
    "regressor = LinearRegression().fit(X_reg_train, y_reg_train)\n",
    "y_pred_reg = regressor.predict(X_reg_test)\n",
    "\n",
    "# 5.1. Metrics\n",
    "# Regression Metrics\n",
    "mae = mean_absolute_error(y_reg_test, y_pred_reg)  # Mean Absolute Error\n",
    "mse = mean_squared_error(y_reg_test, y_pred_reg)  # Mean Squared Error\n",
    "r2 = r2_score(y_reg_test, y_pred_reg)  # R-squared\n",
    "print(f\"Regression Metrics:\\nMAE: {mae:.4f}, MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "\n",
    "# Generate sample classification data\n",
    "X_clf, y_clf = make_classification(n_samples=300, n_features=5, random_state=42)\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(X_clf, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classification model\n",
    "classifier = RandomForestClassifier().fit(X_clf_train, y_clf_train)\n",
    "y_pred_clf = classifier.predict(X_clf_test)\n",
    "y_pred_proba = classifier.predict_proba(X_clf_test)[:, 1]\n",
    "\n",
    "# Classification Metrics\n",
    "accuracy = accuracy_score(y_clf_test, y_pred_clf)  # Accuracy\n",
    "precision = precision_score(y_clf_test, y_pred_clf)  # Precision\n",
    "recall = recall_score(y_clf_test, y_pred_clf)  # Recall\n",
    "f1 = f1_score(y_clf_test, y_pred_clf)  # F1 Score\n",
    "roc_auc = roc_auc_score(y_clf_test, y_pred_proba)  # ROC-AUC\n",
    "conf_matrix = confusion_matrix(y_clf_test, y_pred_clf)  # Confusion Matrix\n",
    "print(f\"Classification Metrics:\\nAccuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# Generate clustering data\n",
    "X_clust, _ = make_blobs(n_samples=300, centers=3, cluster_std=1.0, random_state=42)\n",
    "clustering_model = KMeans(n_clusters=3, random_state=42).fit(X_clust)\n",
    "labels = clustering_model.labels_\n",
    "\n",
    "# Clustering Metrics\n",
    "silhouette = silhouette_score(X_clust, labels)  # Silhouette Score\n",
    "calinski = calinski_harabasz_score(X_clust, labels)  # Calinski-Harabasz Score\n",
    "\n",
    "print(f\"Clustering Metrics:\\nSilhouette Score: {silhouette:.4f}, Calinski-Harabasz Score: {calinski:.4f}\")\n",
    "\n",
    "# 5.2. Hyperparameter Optimization\n",
    "# Grid Search\n",
    "param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5).fit(X_clf_train, y_clf_train)\n",
    "print(f\"Best Parameters (GridSearchCV): {grid_search.best_params_}\")\n",
    "\n",
    "# Randomized Search\n",
    "param_dist = {'n_estimators': np.arange(10, 100, 10), 'max_depth': [None, 10, 20]}\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_dist, n_iter=5, cv=5, random_state=42).fit(X_clf_train, y_clf_train)\n",
    "print(f\"Best Parameters (RandomizedSearchCV): {random_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
